{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6897b2e-29f0-435c-98ac-cdc89ae0b32a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Training re-run</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c4d6be3-33b0-418d-bc3c-51fc13e15d0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['ENV'] = 'prod'\n",
    "os.environ['REGION'] = 'apse1'\n",
    "os.environ['TENANT'] =\"in\"\n",
    "os.environ['RECO_S3_BUCKET'] = \"p13n-reco-offline-prod\"\n",
    "os.environ['COUNTRY_KEY']= \"in\"\n",
    "os.environ['AWS_REGION']= \"ap-southeast-1\"\n",
    "os.environ['USE_REAL_CMS3']= \"True\"\n",
    "os.environ['RECO_CREDENTIAL']= \"-----BEGINRSAPRIVATEKEY-----\\nMGICAQACEQCdHOlGnxIMWCMzjK2JAg37AgMBAAECEGOIwGTEO9vd3X9+jyiF4NECCQnoqDakDgSm2QIID9sadWN0XvMCCQLiqPkgVKSuIQIIDCAsWM+pJB8CCQG0jbIGCNX9MA==\\n-----ENDRSAPRIVATEKEY-----\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7d3ded2-0f2d-4a5e-937f-5db62c8d9c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 16:18:39.053695: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2026-02-03 16:18:39.053723: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:dynamic_embedding.GraphKeys has already been deprecated. The Variable will not be added to collections because it does not actully own any value, but only a holder of tables, which may lead to import_meta_graph failed since non-valued object has been added to collection. If you need to use `tf.compat.v1.train.Saver` and access all Variables from collection, you could manually add it to the collection by tf.compat.v1.add_to_collections(names, var) instead.\n",
      "WARNING: env TENANT is not set, use the default value apse1-0\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tfv1 = tf.compat.v1\n",
    "tfv1.disable_v2_behavior()\n",
    "\n",
    "import os\n",
    "import pyarrow\n",
    "\n",
    "from common.time_utils import get_dates_list_forwards\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_recommenders_addons as tfra\n",
    "\n",
    "import numpy as np\n",
    "import s3fs\n",
    "from common.s3_utils import upload_folder, upload_file\n",
    "\n",
    "from common.config.utils import data_path, tenant_countries, model_path\n",
    "from common.config import TENANT\n",
    "\n",
    "from common.s3_utils import is_s3_path_success\n",
    "from model.trainer import Trainer, ValData, LearningRateScheduler\n",
    "from model.losses import masked_binary_entropy_loss\n",
    "from model.metrics import MaskedAUC\n",
    "from tpfy.tf_model.tpfy_model_v3_mtl import TpfyModelV3, TpfyMtlModelConfig\n",
    "from tpfy.common import TpfyDataPath\n",
    "import tpfy.tf_model.exporter_v3_mtl as exporter\n",
    "from tpfy.etl.schema import TpfyMtlDatasetSchema\n",
    "from model.parquet_dataset import TFParquetDataset, _get_dataset_columns\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "\n",
    "S3_TPFY_MODEL_EXPORT = model_path(TpfyDataPath.S3_TPFY_MODEL_EXPORT, TENANT)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TpfyTrainConfig:\n",
    "    repeat: int\n",
    "    eval_freq: int\n",
    "    eval_steps: int\n",
    "    step_unit: int\n",
    "    max_step: int\n",
    "    batch_size: int\n",
    "\n",
    "    learning_rate: float\n",
    "    lr_decay: bool\n",
    "    lr_decay_start: int\n",
    "    min_lr: float\n",
    "    weight_decay: float\n",
    "\n",
    "    enable_random_watch: bool\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TpfyConfig:\n",
    "    train: TpfyTrainConfig\n",
    "    model: TpfyMtlModelConfig\n",
    "\n",
    "\n",
    "_dataset_column_names = [col.name for col in _get_dataset_columns(TpfyMtlDatasetSchema)]\n",
    "\n",
    "TASK_COL_INDEX = _dataset_column_names.index(\"task\")\n",
    "\n",
    "\n",
    "def filter_random_watch_factory():\n",
    "    def _fn(imm_row):\n",
    "        task = imm_row[TASK_COL_INDEX]\n",
    "        if task[0] == 0:\n",
    "            return [imm_row]\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    return _fn\n",
    "\n",
    "\n",
    "def init_local(args, countries) -> TpfyConfig:\n",
    "    name = f\"tpfy/tpfy_config/mtl-{TENANT}.yaml\"\n",
    "\n",
    "    if not os.path.exists(name):\n",
    "        raise Exception(f\"conf file {name} missing\")\n",
    "\n",
    "    if args.conf:\n",
    "        cli_conf_dotlist = [p for p in args.conf.split(\",\") if len(p) > 0]\n",
    "    else:\n",
    "        cli_conf_dotlist = []\n",
    "\n",
    "    conf: TpfyConfig = OmegaConf.merge(\n",
    "        OmegaConf.structured(TpfyConfig),\n",
    "        OmegaConf.load(name),\n",
    "        OmegaConf.from_dotlist(cli_conf_dotlist),\n",
    "    )\n",
    "\n",
    "    if args.lr:\n",
    "        conf.train.learning_rate = args.lr\n",
    "\n",
    "    if args.eval_freq is not None:\n",
    "        conf.train.eval_freq = args.eval_freq\n",
    "\n",
    "    if args.batch_size:\n",
    "        conf.train.batch_size = args.batch_size\n",
    "\n",
    "    if args.max_epoch:\n",
    "        conf.train.max_step = args.max_epoch\n",
    "\n",
    "    if args.repeat:\n",
    "        conf.train.repeat = args.repeat\n",
    "\n",
    "    return conf\n",
    "\n",
    "\n",
    "def assert_label_shape(tensor):\n",
    "    assert len(tensor.shape) == 2\n",
    "    assert tensor.shape[1].value == 1\n",
    "\n",
    "\n",
    "def partition_columns(values):\n",
    "    schema = TpfyMtlDatasetSchema\n",
    "    num_features = len(schema.features)\n",
    "    num_labels = len(schema.labels)\n",
    "    num_metadata = len(schema.metadata)\n",
    "    offset = 0\n",
    "    features = schema.make_feature_tuple(\n",
    "        values[offset : offset + num_features]\n",
    "    )._asdict()\n",
    "    offset += num_features\n",
    "\n",
    "    labels = schema.make_label_tuple(values[offset : offset + num_labels])\n",
    "    offset += num_labels\n",
    "\n",
    "    metadata = schema.make_metadata_tuple(\n",
    "        values[offset : offset + num_metadata]\n",
    "    )._asdict()\n",
    "    return features, labels, metadata\n",
    "\n",
    "\n",
    "def make_example_mtl(*tensors):\n",
    "    features, original_labels, metadata = partition_columns(tensors)\n",
    "\n",
    "    task = features[\"task\"]\n",
    "    click = tf.cast(original_labels.click, tf.float32)\n",
    "    watch = tf.cast(original_labels.watch, tf.float32)\n",
    "    paywall_view = tf.cast(original_labels.paywall_view, tf.float32)\n",
    "    add_watchlist = tf.cast(original_labels.add_watchlist, tf.float32)\n",
    "\n",
    "    click = tf.where(tf.equal(task, 0), click, -1.0)\n",
    "    random_watch = tf.where(tf.equal(task, 1), watch, -1.0)\n",
    "\n",
    "    is_postclick = tf.greater(click, 0)\n",
    "    watch = tf.where(is_postclick, watch, -1.0)\n",
    "    paywall_view = tf.where(is_postclick, paywall_view, -1.0)\n",
    "    add_watchlist = tf.where(is_postclick, add_watchlist, -1.0)\n",
    "\n",
    "    assert_label_shape(click)\n",
    "    assert_label_shape(watch)\n",
    "    assert_label_shape(random_watch)\n",
    "\n",
    "    labels = {\n",
    "        \"click\": click,\n",
    "        \"watch\": watch,\n",
    "        \"add_watchlist\": add_watchlist,\n",
    "        \"paywall_view\": paywall_view,\n",
    "        \"random_watch\": random_watch,\n",
    "    }\n",
    "\n",
    "    return features, labels, metadata\n",
    "\n",
    "\n",
    "def create_exp_lr_schedule_callback(decay_start, min_lr, alpha, verbose=False):\n",
    "    def lr_schedule(epoch, current_lr):\n",
    "        if epoch < decay_start:\n",
    "            return current_lr\n",
    "        else:\n",
    "            lr = current_lr * alpha\n",
    "            if lr < min_lr:\n",
    "                return min_lr\n",
    "            else:\n",
    "                return lr\n",
    "\n",
    "    return LearningRateScheduler(lr_schedule, verbose=verbose)\n",
    "\n",
    "\n",
    "class TpfyCustomTrainer(Trainer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: TpfyModelV3,\n",
    "        session,\n",
    "        model_name,\n",
    "        plain_weights,\n",
    "        clear_nn,\n",
    "        weight_decay,\n",
    "        countries,\n",
    "    ):\n",
    "        super().__init__(model=model, model_name=model_name, session=session)\n",
    "        self.plain_weights = plain_weights\n",
    "        self.clear_nn = clear_nn\n",
    "        self.weight_decay = weight_decay\n",
    "        self.countries = countries\n",
    "\n",
    "        assert isinstance(model, TpfyModelV3)\n",
    "\n",
    "    def on_train_start(self):\n",
    "        print(\"on train start\")\n",
    "        if self.plain_weights is not None:\n",
    "            print(\"restore model weights\")\n",
    "\n",
    "            plain_weights = self.plain_weights\n",
    "            restore_ops = self.model.restore_plain_weights_ops(\n",
    "                plain_weights, clear_nn=self.clear_nn\n",
    "            )\n",
    "            self.session.run(restore_ops)\n",
    "            print(\"done\")\n",
    "\n",
    "    def build_train_step(self, tape, loss):\n",
    "        if not self.weight_decay:\n",
    "            trainable_vars = self.model.trainable_variables\n",
    "            gradients = tape.gradient(loss, trainable_vars)\n",
    "            train_step = self.model.optimizer.apply_gradients(\n",
    "                zip(gradients, trainable_vars)\n",
    "            )\n",
    "            return train_step\n",
    "        else:\n",
    "            print(\"build weight decay\")\n",
    "            trainable_variables = self.model.get_all_trainable_variables()\n",
    "            print(\"trainable\", [v.name for v in trainable_variables])\n",
    "            decayed_variables = [v for v in trainable_variables if \"bias\" not in v.name]\n",
    "\n",
    "            train_step = self.model.optimizer.minimize(\n",
    "                loss,\n",
    "                trainable_variables,\n",
    "                decay_var_list=decayed_variables,\n",
    "                tape=tape,\n",
    "            )\n",
    "            return train_step\n",
    "\n",
    "\n",
    "def run(args):\n",
    "    countries = tenant_countries(args.countries)\n",
    "    hparams = init_local(args, countries)\n",
    "    print(hparams)\n",
    "\n",
    "    variant = args.variant\n",
    "    if variant and not variant.startswith(\"-\"):\n",
    "        variant = \"-\" + variant\n",
    "\n",
    "    train_date = args.date\n",
    "    train_path = data_path(\n",
    "        TpfyDataPath.S3_TPFY_IMPR_V3_AGG_MTL_EXTRACTED_EXAMPLES_VAR, TENANT\n",
    "    ) % (variant, train_date)\n",
    "    print(\"train data\", train_path)\n",
    "    if not is_s3_path_success(train_path):\n",
    "        raise Exception(\"train data not available\")\n",
    "    dataset_schema = TpfyMtlDatasetSchema\n",
    "\n",
    "    train_dataset = TFParquetDataset([train_path], dataset_schema, shuffle_files=True)\n",
    "    train_row_transformer_factory = None\n",
    "\n",
    "    make_example_fn = make_example_mtl\n",
    "\n",
    "    session = tfv1.keras.backend.get_session()\n",
    "\n",
    "    print(\"load dataset objective stat\")\n",
    "    fs = s3fs.S3FileSystem(use_ssl=False)\n",
    "    with fs.open(os.path.join(train_path, \"stats.json\"), \"r\") as f:\n",
    "        stats = json.load(f)\n",
    "    task_weights = stats[\"task_weights\"]\n",
    "\n",
    "    batch_size = hparams.train.batch_size\n",
    "    print(f\"obj stat: batch_size {batch_size}\")\n",
    "\n",
    "    train_tf_dataset = train_dataset.create_parallel_tf_dataset(\n",
    "        batch_size,\n",
    "        args.num_workers,\n",
    "        num_epochs=hparams.train.repeat,\n",
    "        queue_size=16,\n",
    "        v2=True,\n",
    "        row_transformer_factory=train_row_transformer_factory,\n",
    "    ).map(make_example_fn)\n",
    "\n",
    "    print(\"output_shapes\", train_tf_dataset.output_shapes)\n",
    "    print(\"num output\", len(train_tf_dataset.output_shapes))\n",
    "\n",
    "    validation_dataset_dict = {}\n",
    "    val_tenant_or_countries = [TENANT]\n",
    "    for country in val_tenant_or_countries:\n",
    "        for dt in get_dates_list_forwards(args.val_date, args.val_days):\n",
    "            val_dataset = TFParquetDataset(\n",
    "                [\n",
    "                    data_path(\n",
    "                        TpfyDataPath.S3_TPFY_IMPR_V3_DAILY_MTL_EXTRACTED_EXAMPLES,\n",
    "                        country,\n",
    "                    )\n",
    "                    % (variant, dt)\n",
    "                ],\n",
    "                dataset_schema,\n",
    "                shuffle_files=False,\n",
    "            )\n",
    "            validation_dataset_dict[f\"{country}-{dt}\"] = ValData(\n",
    "                val_dataset.create_tf_dataset(batch_size)\n",
    "                .take(hparams.train.eval_steps)\n",
    "                .cache(f\"val_mtl_{country}_{dt}\")\n",
    "                .map(make_example_fn),\n",
    "                active_objectives=[\n",
    "                    \"click\",\n",
    "                    \"watch\",\n",
    "                    \"random_watch\",\n",
    "                    \"paywall_view\",\n",
    "                    \"add_watchlist\",\n",
    "                ],\n",
    "            )\n",
    "\n",
    "    model_name = args.model_name\n",
    "    tpfy_model = TpfyModelV3(\n",
    "        hparams.model,\n",
    "        click_ns=args.click_ns,\n",
    "        enable_random_watch=hparams.train.enable_random_watch,\n",
    "    )\n",
    "\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        weight_decay=float(hparams.train.weight_decay),\n",
    "        learning_rate=hparams.train.learning_rate,\n",
    "        epsilon=1e-4,\n",
    "    )\n",
    "    optimizer = tfra.dynamic_embedding.DynamicEmbeddingOptimizer(optimizer)\n",
    "\n",
    "    if hparams.train.lr_decay:\n",
    "        lr_scheduler = create_exp_lr_schedule_callback(\n",
    "            hparams.train.lr_decay_start,\n",
    "            hparams.train.min_lr,\n",
    "            0.7 ** (1 / 10),\n",
    "            verbose=True,\n",
    "        )\n",
    "    else:\n",
    "        lr_scheduler = None\n",
    "\n",
    "    loss_dict = {\n",
    "        \"click\": masked_binary_entropy_loss(from_logits=True),\n",
    "        \"watch\": masked_binary_entropy_loss(from_logits=True),\n",
    "        \"random_watch\": masked_binary_entropy_loss(from_logits=False),\n",
    "        \"paywall_view\": masked_binary_entropy_loss(from_logits=True),\n",
    "        \"add_watchlist\": masked_binary_entropy_loss(from_logits=True),\n",
    "    }\n",
    "    metric_dict = {\n",
    "        \"click\": MaskedAUC(from_logits=True),\n",
    "        \"watch\": MaskedAUC(from_logits=True),\n",
    "        \"random_watch\": MaskedAUC(from_logits=False),\n",
    "        \"paywall_view\": MaskedAUC(from_logits=True),\n",
    "        \"add_watchlist\": MaskedAUC(from_logits=True),\n",
    "    }\n",
    "\n",
    "    loss_weight_dict = {\n",
    "        \"click\": args.click_weight,\n",
    "        \"watch\": args.watch_weight,\n",
    "        \"random_watch\": 1.0 if hparams.train.enable_random_watch else 0.0,\n",
    "        \"paywall_view\": 1.0,\n",
    "        \"add_watchlist\": 1.0,\n",
    "    }\n",
    "    total_loss_weight = sum(loss_weight_dict.values())\n",
    "    loss_weight_dict = {\n",
    "        obj: w / total_loss_weight for obj, w in loss_weight_dict.items()\n",
    "    }\n",
    "\n",
    "    tpfy_model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss_dict,\n",
    "        metrics=metric_dict,\n",
    "        loss_weights=loss_weight_dict,\n",
    "    )\n",
    "    plain_weights = None\n",
    "    clear_nn = args.clear_nn\n",
    "    if args.reload_s3_model or args.reload_local_model:\n",
    "        if args.reload_s3_model:\n",
    "            filesystem = s3fs.S3FileSystem(use_ssl=False)\n",
    "            model_path = S3_TPFY_MODEL_EXPORT % args.reload_s3_model\n",
    "        else:\n",
    "            filesystem = pyarrow.LocalFileSystem()\n",
    "            model_path = os.path.join(\"export\", args.reload_local_model)\n",
    "\n",
    "        if args.ckpt:\n",
    "            checkpoint = args.ckpt\n",
    "        else:\n",
    "            checkpoint_path = os.path.join(model_path, \"checkpoint\")\n",
    "            print(\"read checkpoint\", checkpoint_path)\n",
    "            with filesystem.open(checkpoint_path, \"r\") as f:\n",
    "                checkpoint = f.read().strip()\n",
    "        weights_path = os.path.join(model_path, checkpoint, \"plain_weights.npz\")\n",
    "        if not filesystem.exists(weights_path):\n",
    "            raise Exception(f\"Model weights {weights_path} unavailable\")\n",
    "        else:\n",
    "            print(f\"Restore from {weights_path}\")\n",
    "            with filesystem.open(weights_path, \"rb\") as f:\n",
    "                plain_weights = {}\n",
    "                for k, v in np.load(f).items():\n",
    "                    plain_weights[k] = v\n",
    "\n",
    "            print(\"plain weights keys\", list(plain_weights.keys()))\n",
    "\n",
    "    trainer = TpfyCustomTrainer(\n",
    "        tpfy_model,\n",
    "        session,\n",
    "        model_name,\n",
    "        plain_weights,\n",
    "        clear_nn=clear_nn,\n",
    "        weight_decay=True,\n",
    "        countries=countries,\n",
    "    )\n",
    "    trained_epochs = trainer.train(\n",
    "        train_tf_dataset,\n",
    "        epochs=hparams.train.max_step,\n",
    "        steps_per_epoch=hparams.train.step_unit,\n",
    "        validation_data_dict=validation_dataset_dict,\n",
    "        validation_steps=None,\n",
    "        validation_freq=hparams.train.eval_freq,\n",
    "        log_dir=\"train/logs/\" + model_name,\n",
    "        lr_scheduler=lr_scheduler,\n",
    "        early_stopping=None,\n",
    "        verbose=args.verbose,\n",
    "        validation_on_start=hparams.train.eval_freq > 0\n",
    "        and (args.reload_local_model or args.reload_s3_model),\n",
    "    )\n",
    "\n",
    "    # WORKAROUND: clear de optimizer state to save memory online\n",
    "    # TODO: remove optimizer entirely\n",
    "    for de_var in tpfy_model.dynamic_embeddings:\n",
    "        print(\"clear optimizer state for embedding variable\", de_var.name)\n",
    "        for i, opt in enumerate([optimizer]):\n",
    "            print(\"opt\", i)\n",
    "            slot_variables = de_var.get_slot_variables(opt)\n",
    "            for slot_variable in slot_variables:\n",
    "                print(\n",
    "                    \"clear\",\n",
    "                    slot_variable.name,\n",
    "                    \"size\",\n",
    "                    session.run(slot_variable.size()),\n",
    "                )\n",
    "                session.run(slot_variable.clear())\n",
    "\n",
    "    warmup_dataset = list(validation_dataset_dict.values())[0].tf_dataset\n",
    "    warmup_it = warmup_dataset.make_one_shot_iterator()\n",
    "    warmup_next = warmup_it.get_next()\n",
    "    warmup_data = []\n",
    "    print(\"get warmup data\")\n",
    "    for i in range(1):\n",
    "        warmup_data.append(session.run(warmup_next))\n",
    "    print(\"warmup data done\")\n",
    "\n",
    "    model_dir = \"export/{}\".format(model_name)\n",
    "    version = int(time.time())\n",
    "    export_path = \"{}/{}\".format(model_dir, version)\n",
    "    print(\"export path\", export_path)\n",
    "    # from IPython import embed\n",
    "    # embed()\n",
    "    exporter.export_tpfy_model(export_path, session, tpfy_model, warmup_data)\n",
    "    checkpoint_path = os.path.join(model_dir, \"checkpoint\")\n",
    "    with open(checkpoint_path, \"w\") as f:\n",
    "        f.write(str(version))\n",
    "\n",
    "    if args.upload:\n",
    "        print(\"upload\")\n",
    "        export_s3_path = S3_TPFY_MODEL_EXPORT % f\"{model_name}/{version}\"\n",
    "        upload_folder(export_s3_path, export_path, set_acl=False)\n",
    "\n",
    "        checkpoint_s3_path = S3_TPFY_MODEL_EXPORT % f\"{model_name}/checkpoint\"\n",
    "        upload_file(checkpoint_s3_path, checkpoint_path, set_acl=False)\n",
    "\n",
    "    print(\"done\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"TPFY offline Training.\")\n",
    "    parser.add_argument(\"model_name\", type=str, default=\"tpfy-v3-mtl-r2\")\n",
    "    parser.add_argument(\"date\", type=str, default=\"2026-01-25\")\n",
    "    parser.add_argument(\"val_date\", type=str, default=\"2026-01-25\")\n",
    "    parser.add_argument(\"--conf\", type=str, default=None)\n",
    "    parser.add_argument(\"--max_epoch\", type=int, default=None)\n",
    "    parser.add_argument(\"--val_days\", type=int, default=1)\n",
    "    parser.add_argument(\"--click_ns\", type=float, default=0.08)\n",
    "    parser.add_argument(\"--variant\", type=str, default=\"cms3\")\n",
    "    parser.add_argument(\"--num_workers\", type=int, default=4)\n",
    "    parser.add_argument(\"--repeat\", type=int, default=1)\n",
    "    parser.add_argument(\"--eval_freq\", type=int, default=None)\n",
    "    parser.add_argument(\"--lr\", type=float, default=None)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=None)\n",
    "    parser.add_argument(\"--click_weight\", type=float, default=1)\n",
    "    parser.add_argument(\"--watch_weight\", type=float, default=1)\n",
    "    parser.add_argument(\"--upload\", action=\"store_true\", help=\"uploading model to s3\")\n",
    "    parser.add_argument(\"--reload_local_model\", type=str, default=None)\n",
    "    parser.add_argument(\"--reload_s3_model\", type=str, default=None)\n",
    "    parser.add_argument(\"--clear_nn\", action=\"store_true\")\n",
    "    parser.add_argument(\"--ckpt\", default=None, type=str)\n",
    "    parser.add_argument(\"--verbose\", action=\"store_true\")\n",
    "    parser.add_argument(\n",
    "        \"--countries\",\n",
    "        type=str,\n",
    "        help=\"countries to run, separated with comma. \"\n",
    "        \"default is None. fallback to region countries\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    print(\"Start training\")\n",
    "    # run(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4ed08c0-0577-4eb1-991a-eafb4d583278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Configuration:\n",
      "  Model Name: tpfy-v3-mtl-r2\n",
      "  Training Date: 2026-01-27\n",
      "  Validation Date: 2026-01-28\n",
      "  Variant: cms3\n",
      "  Click NS: 0.08\n",
      "  Num Workers: 4\n",
      "  Reload Model: tpfy-v3-mtl-r2\n",
      "  Upload: False\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    \"\"\"Simple class to hold training arguments (replaces argparse)\"\"\"\n",
    "    def __init__(self):\n",
    "        # Positional arguments\n",
    "        self.model_name = \"tpfy-v3-mtl-r2\"\n",
    "        self.date = \"2026-01-27\"  # Training date\n",
    "        self.val_date = \"2026-01-28\"  # Validation date\n",
    "        \n",
    "        # Optional arguments\n",
    "        self.conf = None\n",
    "        self.max_epoch = None\n",
    "        self.val_days = 1\n",
    "        self.click_ns = 0.08\n",
    "        self.variant = \"cms3\"\n",
    "        self.num_workers = 4\n",
    "        self.repeat = 1\n",
    "        self.eval_freq = None\n",
    "        self.lr = 1e-4\n",
    "        self.batch_size = 16\n",
    "        self.click_weight = 1.0\n",
    "        self.watch_weight = 1.0\n",
    "        self.upload = False  # Set to False if you don't want to upload to S3\n",
    "        self.reload_local_model = None\n",
    "        self.reload_s3_model = \"tpfy-v3-mtl-r2\"  # Set to None if starting fresh\n",
    "        self.clear_nn = False\n",
    "        self.ckpt = None\n",
    "        self.verbose = True\n",
    "        self.countries = None\n",
    "\n",
    "# Create args instance\n",
    "args = Args()\n",
    "\n",
    "# Display configuration\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"  Model Name: {args.model_name}\")\n",
    "print(f\"  Training Date: {args.date}\")\n",
    "print(f\"  Validation Date: {args.val_date}\")\n",
    "print(f\"  Variant: {args.variant}\")\n",
    "print(f\"  Click NS: {args.click_ns}\")\n",
    "print(f\"  Num Workers: {args.num_workers}\")\n",
    "print(f\"  Reload Model: {args.reload_s3_model}\")\n",
    "print(f\"  Upload: {args.upload}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d79382e-f984-4772-97a8-40f42e344a69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': {'repeat': 1, 'eval_freq': 0, 'eval_steps': 500, 'step_unit': 500, 'max_step': 1000, 'batch_size': 16, 'learning_rate': 0.0001, 'lr_decay': False, 'lr_decay_start': 40, 'min_lr': 0.0001, 'weight_decay': 1e-06, 'enable_random_watch': True}, 'model': {'dim': 32, 'middle_dim': 128, 'dnn_units': [256], 'multi_country': False, 'dnn_activation': 'relu', 'init_method': 'xavier_uniform', 'init_value': 0.01, 'dnn_l2': 0.0, 'embedding_l2': 0.0, 'enable_discover_popularity': False, 'enable_hp_feature': True}}\n",
      "train data s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27\n"
     ]
    }
   ],
   "source": [
    "countries = tenant_countries(args.countries)\n",
    "hparams = init_local(args, countries)\n",
    "print(hparams)\n",
    "\n",
    "variant = args.variant\n",
    "if variant and not variant.startswith(\"-\"):\n",
    "    variant = \"-\" + variant\n",
    "\n",
    "train_date = args.date\n",
    "train_path = data_path(\n",
    "    TpfyDataPath.S3_TPFY_IMPR_V3_AGG_MTL_EXTRACTED_EXAMPLES_VAR, TENANT\n",
    ") % (variant, train_date)\n",
    "print(\"train data\", train_path)\n",
    "if not is_s3_path_success(train_path):\n",
    "    raise Exception(\"train data not available\")\n",
    "dataset_schema = TpfyMtlDatasetSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e03c537b-b34c-4d7b-ad73-fd420e8381a0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00136-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2322-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00201-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2293-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00219-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2348-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00182-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2436-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00177-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2319-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00227-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2434-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00241-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2406-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00247-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2292-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00040-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2382-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00090-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2427-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00253-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2355-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00149-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2218-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00098-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2446-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00056-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2300-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00237-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2395-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00211-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2274-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00000-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2420-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00100-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2401-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00162-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2426-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00216-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2236-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00064-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2342-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00027-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2213-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00225-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2449-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00132-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2353-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00026-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2444-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00012-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2452-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00084-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2336-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00156-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2404-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00163-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2341-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00239-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2295-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00147-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2374-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00010-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2239-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00151-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2397-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00066-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2273-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00079-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2346-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00070-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2389-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00150-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2347-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00059-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2242-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00003-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2447-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00018-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2250-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00142-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2345-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00055-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2253-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00223-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2222-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00038-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2388-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00135-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2390-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00051-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2229-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00127-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2268-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00114-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2284-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00153-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2429-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00041-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2438-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00222-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2256-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00175-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2386-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00094-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2260-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00008-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2291-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00089-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2419-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00120-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2443-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00085-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2445-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00068-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2456-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00204-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2335-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00242-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2282-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00185-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2214-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00037-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2354-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00176-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2400-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00173-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2451-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00096-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2313-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00039-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2303-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00203-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2215-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00017-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2225-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00166-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2407-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00058-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2333-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00110-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2267-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00181-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2276-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00095-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2275-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00002-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2327-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00193-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2334-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00129-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2364-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00245-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2453-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00104-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2257-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00168-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2398-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00046-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2372-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00228-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2277-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00099-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2403-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00112-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2391-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00074-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2371-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00192-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2246-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00036-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2464-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00113-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2315-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00116-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2439-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00138-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2324-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00126-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2221-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00121-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2248-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00043-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2465-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00188-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2340-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00022-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2415-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00122-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2317-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00158-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2416-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00226-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2318-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00118-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2343-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00117-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2366-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00178-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2310-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00232-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2301-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00011-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2352-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00154-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2373-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00029-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2219-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00169-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2227-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00047-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2228-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00031-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2337-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00252-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2356-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00139-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2294-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00105-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2411-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00208-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2349-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00152-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2378-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00030-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2376-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00054-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2428-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00200-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2320-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00014-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2226-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00123-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2231-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00091-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2259-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00108-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2297-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00093-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2359-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00145-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2224-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00071-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2258-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00133-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2461-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00196-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2414-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00069-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2417-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00019-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2266-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00155-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2238-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00146-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2281-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00033-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2442-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00244-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2330-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00077-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2394-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00016-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2264-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00053-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2368-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00174-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2448-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00233-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2441-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00189-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2314-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00015-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2323-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00186-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2269-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00229-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2463-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00020-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2252-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00128-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2380-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00078-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2399-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00167-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2279-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00234-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2392-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00130-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2305-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00197-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2280-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00215-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2249-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00067-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2241-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00249-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2254-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00187-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2412-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00088-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2425-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00191-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2455-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00224-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2234-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00159-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2454-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00221-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2212-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00092-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2302-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00205-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2235-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00101-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2424-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00050-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2298-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00161-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2458-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00172-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2369-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00134-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2329-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00004-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2413-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00081-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2460-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00107-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2431-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00097-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2467-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00214-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2410-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00061-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2432-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00131-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2384-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00009-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2383-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00160-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2351-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00179-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2223-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00251-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2306-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00206-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2379-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00164-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2396-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00083-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2325-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00049-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2244-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00144-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2462-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00087-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2263-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00202-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2450-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00045-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2270-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00230-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2409-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00213-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2433-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00063-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2435-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00190-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2418-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00086-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2405-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00165-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2328-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00218-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2233-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00028-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2220-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00143-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2363-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00231-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2312-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00220-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2338-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00021-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2423-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00034-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2350-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00044-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2296-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00180-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2262-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00073-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2272-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00082-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2247-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00195-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2309-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00194-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2344-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00254-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2360-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00023-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2358-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00248-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2240-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00080-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2245-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00001-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2381-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00171-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2289-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00236-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2316-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00052-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2326-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00007-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2216-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00005-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2375-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00102-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2321-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00025-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2457-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00115-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2402-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00250-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2387-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00217-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2288-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00111-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2290-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00065-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2385-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00246-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2237-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00060-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2304-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00075-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2271-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00184-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2255-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00072-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2357-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00103-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2308-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00042-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2332-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00198-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2251-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00240-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2331-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00209-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2243-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00212-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2430-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00255-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2283-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00048-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2361-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00109-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2422-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00210-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2278-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00057-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2286-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00062-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2285-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00006-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2377-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00124-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2287-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00157-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2362-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00170-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2466-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00140-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2311-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00141-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2339-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00148-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2365-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00137-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2261-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00207-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2393-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00106-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2299-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00183-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2265-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00035-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2232-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00125-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2440-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00199-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2459-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00076-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2230-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00243-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2367-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00235-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2421-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00032-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2408-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00119-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2437-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00024-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2370-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00238-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2217-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-01-27/part-00013-tid-1941705305637033386-cb696035-06bd-4c10-985a-8327755d8544-2307-1-c000.snappy.parquet\n",
      "WARNING:tensorflow:From /tmp/ipykernel_45858/335295864.py:6: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n",
      "\n",
      "load dataset objective stat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 16:18:48.694486: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2026-02-03 16:18:48.694507: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2026-02-03 16:18:48.694537: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-11-72-173): /proc/driver/nvidia/version does not exist\n",
      "2026-02-03 16:18:48.694886: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TFParquetDataset([train_path], dataset_schema, shuffle_files=True)\n",
    "train_row_transformer_factory = None\n",
    "\n",
    "make_example_fn = make_example_mtl\n",
    "\n",
    "session = tfv1.keras.backend.get_session()\n",
    "\n",
    "print(\"load dataset objective stat\")\n",
    "fs = s3fs.S3FileSystem(use_ssl=False)\n",
    "with fs.open(os.path.join(train_path, \"stats.json\"), \"r\") as f:\n",
    "    stats = json.load(f)\n",
    "task_weights = stats[\"task_weights\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27fb15ea-6cc3-4be2-a343-53efacd26d9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj stat: batch_size 16\n",
      "WARNING:tensorflow:From /home/ubuntu/vedansh/code/persona-reco-core/offline/src/main/python/model/parquet_dataset.py:234: calling DatasetV1.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From /home/ubuntu/vedansh/code/persona-reco-core/offline/src/main/python/model/parquet_dataset.py:234: calling DatasetV1.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n"
     ]
    }
   ],
   "source": [
    "batch_size = hparams.train.batch_size\n",
    "print(f\"obj stat: batch_size {batch_size}\")\n",
    "\n",
    "train_tf_dataset = train_dataset.create_parallel_tf_dataset(\n",
    "    batch_size,\n",
    "    args.num_workers,\n",
    "    num_epochs=hparams.train.repeat,\n",
    "    queue_size=16,\n",
    "    v2=True,\n",
    "    row_transformer_factory=train_row_transformer_factory,\n",
    ").map(make_example_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5757d0e2-7c60-4804-b17b-a4448e8c909b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_45858/4106899885.py:1: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(dataset)`.\n",
      "output_shapes (OrderedDict([('user_fids', TensorShape([Dimension(None), Dimension(None)])), ('user_weighted_fids', TensorShape([Dimension(None), Dimension(None)])), ('user_weighted_fid_weights', TensorShape([Dimension(None), Dimension(None)])), ('fids', TensorShape([Dimension(None), Dimension(None)])), ('weighted_fids', TensorShape([Dimension(None), Dimension(None)])), ('weighted_fid_weights', TensorShape([Dimension(None), Dimension(None)])), ('sparse_indices', TensorShape([Dimension(None), Dimension(None)])), ('sparse_values', TensorShape([Dimension(None), Dimension(None)])), ('task', TensorShape([Dimension(None), Dimension(1)]))]), {'click': TensorShape([Dimension(None), Dimension(1)]), 'watch': TensorShape([Dimension(None), Dimension(1)]), 'add_watchlist': TensorShape([Dimension(None), Dimension(1)]), 'paywall_view': TensorShape([Dimension(None), Dimension(1)]), 'random_watch': TensorShape([Dimension(None), Dimension(1)])}, OrderedDict([('secs_start_dt', TensorShape([Dimension(None)])), ('flag', TensorShape([Dimension(None)]))]))\n",
      "num output 3\n",
      "files s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-01-28/part-00000-tid-7791822634252461922-585715f6-fb72-40ce-a31a-b2acfe683eff-19370-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-01-28/part-00001-tid-7791822634252461922-585715f6-fb72-40ce-a31a-b2acfe683eff-19374-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-01-28/part-00002-tid-7791822634252461922-585715f6-fb72-40ce-a31a-b2acfe683eff-19347-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-01-28/part-00003-tid-7791822634252461922-585715f6-fb72-40ce-a31a-b2acfe683eff-19344-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-01-28/part-00004-tid-7791822634252461922-585715f6-fb72-40ce-a31a-b2acfe683eff-19357-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-01-28/part-00005-tid-7791822634252461922-585715f6-fb72-40ce-a31a-b2acfe683eff-19375-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-01-28/part-00006-tid-7791822634252461922-585715f6-fb72-40ce-a31a-b2acfe683eff-19355-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-01-28/part-00007-tid-7791822634252461922-585715f6-fb72-40ce-a31a-b2acfe683eff-19356-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-01-28/part-00008-tid-7791822634252461922-585715f6-fb72-40ce-a31a-b2acfe683eff-19360-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-01-28/part-00009-tid-7791822634252461922-585715f6-fb72-40ce-a31a-b2acfe683eff-19359-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-01-28/part-00010-tid-7791822634252461922-585715f6-fb72-40ce-a31a-b2acfe683eff-19371-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-01-28/part-00011-tid-7791822634252461922-585715f6-fb72-40ce-a31a-b2acfe683eff-19365-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-01-28/part-00012-tid-7791822634252461922-585715f6-fb72-40ce-a31a-b2acfe683eff-19364-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-01-28/part-00013-tid-7791822634252461922-585715f6-fb72-40ce-a31a-b2acfe683eff-19361-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-01-28/part-00014-tid-7791822634252461922-585715f6-fb72-40ce-a31a-b2acfe683eff-19362-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-01-28/part-00015-tid-7791822634252461922-585715f6-fb72-40ce-a31a-b2acfe683eff-19373-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-01-28/part-00016-tid-7791822634252461922-585715f6-fb72-40ce-a31a-b2acfe683eff-19372-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-01-28/part-00017-tid-7791822634252461922-585715f6-fb72-40ce-a31a-b2acfe683eff-19353-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-01-28/part-00018-tid-7791822634252461922-585715f6-fb72-40ce-a31a-b2acfe683eff-19345-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-01-28/part-00019-tid-7791822634252461922-585715f6-fb72-40ce-a31a-b2acfe683eff-19363-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-01-28/part-00020-tid-7791822634252461922-585715f6-fb72-40ce-a31a-b2acfe683eff-19350-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-01-28/part-00021-tid-7791822634252461922-585715f6-fb72-40ce-a31a-b2acfe683eff-19368-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-01-28/part-00022-tid-7791822634252461922-585715f6-fb72-40ce-a31a-b2acfe683eff-19354-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-01-28/part-00023-tid-7791822634252461922-585715f6-fb72-40ce-a31a-b2acfe683eff-19369-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-01-28/part-00024-tid-7791822634252461922-585715f6-fb72-40ce-a31a-b2acfe683eff-19352-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-01-28/part-00025-tid-7791822634252461922-585715f6-fb72-40ce-a31a-b2acfe683eff-19348-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-01-28/part-00026-tid-7791822634252461922-585715f6-fb72-40ce-a31a-b2acfe683eff-19358-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-01-28/part-00027-tid-7791822634252461922-585715f6-fb72-40ce-a31a-b2acfe683eff-19351-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-01-28/part-00028-tid-7791822634252461922-585715f6-fb72-40ce-a31a-b2acfe683eff-19349-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-01-28/part-00029-tid-7791822634252461922-585715f6-fb72-40ce-a31a-b2acfe683eff-19366-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-01-28/part-00030-tid-7791822634252461922-585715f6-fb72-40ce-a31a-b2acfe683eff-19346-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-01-28/part-00031-tid-7791822634252461922-585715f6-fb72-40ce-a31a-b2acfe683eff-19367-1-c000.snappy.parquet\n",
      "WARNING:tensorflow:From /home/ubuntu/vedansh/code/persona-reco-core/offline/src/main/python/model/parquet_dataset.py:52: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From /home/ubuntu/vedansh/code/persona-reco-core/offline/src/main/python/model/parquet_dataset.py:52: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n"
     ]
    }
   ],
   "source": [
    "print(\"output_shapes\", train_tf_dataset.output_shapes)\n",
    "print(\"num output\", len(train_tf_dataset.output_shapes))\n",
    "\n",
    "validation_dataset_dict = {}\n",
    "val_tenant_or_countries = [TENANT]\n",
    "for country in val_tenant_or_countries:\n",
    "    for dt in get_dates_list_forwards(args.val_date, args.val_days):\n",
    "        val_dataset = TFParquetDataset(\n",
    "            [\n",
    "                data_path(\n",
    "                    TpfyDataPath.S3_TPFY_IMPR_V3_DAILY_MTL_EXTRACTED_EXAMPLES,\n",
    "                    country,\n",
    "                )\n",
    "                % (variant, dt)\n",
    "            ],\n",
    "            dataset_schema,\n",
    "            shuffle_files=False,\n",
    "        )\n",
    "        validation_dataset_dict[f\"{country}-{dt}\"] = ValData(\n",
    "            val_dataset.create_tf_dataset(batch_size)\n",
    "            .take(hparams.train.eval_steps)\n",
    "            .cache(f\"val_mtl_{country}_{dt}\")\n",
    "            .map(make_example_fn),\n",
    "            active_objectives=[\n",
    "                \"click\",\n",
    "                \"watch\",\n",
    "                \"random_watch\",\n",
    "                \"paywall_view\",\n",
    "                \"add_watchlist\",\n",
    "            ],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e7c5a18-432d-4a98-9331-7617ba89719f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = args.model_name\n",
    "tpfy_model = TpfyModelV3(\n",
    "    hparams.model,\n",
    "    click_ns=args.click_ns,\n",
    "    enable_random_watch=hparams.train.enable_random_watch,\n",
    ")\n",
    "\n",
    "optimizer = tfa.optimizers.AdamW(\n",
    "    weight_decay=float(hparams.train.weight_decay),\n",
    "    learning_rate=hparams.train.learning_rate,\n",
    "    epsilon=1e-4,\n",
    ")\n",
    "optimizer = tfra.dynamic_embedding.DynamicEmbeddingOptimizer(optimizer)\n",
    "\n",
    "if hparams.train.lr_decay:\n",
    "    lr_scheduler = create_exp_lr_schedule_callback(\n",
    "        hparams.train.lr_decay_start,\n",
    "        hparams.train.min_lr,\n",
    "        0.7 ** (1 / 10),\n",
    "        verbose=True,\n",
    "    )\n",
    "else:\n",
    "    lr_scheduler = None\n",
    "\n",
    "loss_dict = {\n",
    "    \"click\": masked_binary_entropy_loss(from_logits=True),\n",
    "    \"watch\": masked_binary_entropy_loss(from_logits=True),\n",
    "    \"random_watch\": masked_binary_entropy_loss(from_logits=False),\n",
    "    \"paywall_view\": masked_binary_entropy_loss(from_logits=True),\n",
    "    \"add_watchlist\": masked_binary_entropy_loss(from_logits=True),\n",
    "}\n",
    "metric_dict = {\n",
    "    \"click\": MaskedAUC(from_logits=True),\n",
    "    \"watch\": MaskedAUC(from_logits=True),\n",
    "    \"random_watch\": MaskedAUC(from_logits=False),\n",
    "    \"paywall_view\": MaskedAUC(from_logits=True),\n",
    "    \"add_watchlist\": MaskedAUC(from_logits=True),\n",
    "}\n",
    "\n",
    "loss_weight_dict = {\n",
    "    \"click\": args.click_weight,\n",
    "    \"watch\": args.watch_weight,\n",
    "    \"random_watch\": 1.0 if hparams.train.enable_random_watch else 0.0,\n",
    "    \"paywall_view\": 1.0,\n",
    "    \"add_watchlist\": 1.0,\n",
    "}\n",
    "total_loss_weight = sum(loss_weight_dict.values())\n",
    "loss_weight_dict = {\n",
    "    obj: w / total_loss_weight for obj, w in loss_weight_dict.items()\n",
    "}\n",
    "\n",
    "tpfy_model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss_dict,\n",
    "    metrics=metric_dict,\n",
    "    loss_weights=loss_weight_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c88bceb-fa6c-4ae4-a3af-75b014013d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read checkpoint s3://p13n-reco-offline-models-prod/models/tpfy/tpfy-v3-mtl-r2/checkpoint\n",
      "Restore from s3://p13n-reco-offline-models-prod/models/tpfy/tpfy-v3-mtl-r2/1770115825/plain_weights.npz\n",
      "plain weights keys ['train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/kernel:0', 'train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/bias:0', 'train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/kernel:0', 'train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/bias:0', 'train/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_full_0:0', 'train/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_compact_0:0', 'train/tpfy_model_v3/deepfm/dnn/dnn_hyb/bias_0:0', 'train/tpfy_model_v3/deepfm/compress_dense/kernel:0', 'train/tpfy_model_v3/deepfm/compress_dense/bias:0', 'train/tpfy_model_v3/deepfm/linear/linear_bias:0', 'train/tpfy_model_v3/deepfm/linear/linear_kernel:0', 'train/tpfy_model_v3/deepfm/mtl_linear/linear_bias:0', 'train/tpfy_model_v3/deepfm/mtl_linear/linear_kernel:0', 'train/tpfy_model_v3/sparse_layer:0', 'train/tpfy_model_v3/click_biases:0', 'train/tpfy_model_v3/watch_biases:0', 'embedding_layer/fids', 'embedding_layer/embeddings']\n"
     ]
    }
   ],
   "source": [
    "plain_weights = None\n",
    "clear_nn = args.clear_nn\n",
    "if args.reload_s3_model or args.reload_local_model:\n",
    "    if args.reload_s3_model:\n",
    "        filesystem = s3fs.S3FileSystem(use_ssl=False)\n",
    "        model_path = S3_TPFY_MODEL_EXPORT % args.reload_s3_model\n",
    "    else:\n",
    "        filesystem = pyarrow.LocalFileSystem()\n",
    "        model_path = os.path.join(\"export\", args.reload_local_model)\n",
    "\n",
    "    if args.ckpt:\n",
    "        checkpoint = args.ckpt\n",
    "    else:\n",
    "        checkpoint_path = os.path.join(model_path, \"checkpoint\")\n",
    "        print(\"read checkpoint\", checkpoint_path)\n",
    "        with filesystem.open(checkpoint_path, \"r\") as f:\n",
    "            checkpoint = f.read().strip()\n",
    "    weights_path = os.path.join(model_path, checkpoint, \"plain_weights.npz\")\n",
    "    if not filesystem.exists(weights_path):\n",
    "        raise Exception(f\"Model weights {weights_path} unavailable\")\n",
    "    else:\n",
    "        print(f\"Restore from {weights_path}\")\n",
    "        with filesystem.open(weights_path, \"rb\") as f:\n",
    "            plain_weights = {}\n",
    "            for k, v in np.load(f).items():\n",
    "                plain_weights[k] = v\n",
    "\n",
    "        print(\"plain weights keys\", list(plain_weights.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78a24e7c-a0e1-4800-8c55-2da47f64b80e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "q Tensor(\"train/tpfy_model_v3/feature_prep/strided_slice_1:0\", shape=(?, 32), dtype=float32)\n",
      "k Tensor(\"train/tpfy_model_v3/feature_prep/watched_content_embedding_unpooled:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"train/tpfy_model_v3/feature_prep/GetSlotFids:1\", shape=(?, ?), dtype=float32)\n",
      "target embedding shape (?, 9, 32)\n",
      "user embedding shape (?, 27, 32)\n",
      "target: Tensor(\"train/tpfy_model_v3/feature_prep/target_feature/target_embeddings:0\", shape=(?, 9, 32), dtype=float32)\n",
      "user: Tensor(\"train/tpfy_model_v3/feature_prep/user_feature/user_embeddings:0\", shape=(?, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/comp_new/add:0\", shape=(?, 32), dtype=float32)\n",
      "fm_user Tensor(\"train/tpfy_model_v3/deepfm/fwfm/concat:0\", shape=(?, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"train/tpfy_model_v3/feature_prep/target_feature/target_embeddings:0\", shape=(?, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"train/tpfy_model_v3/deepfm/fwfm/Reshape:0\", shape=(?, 252), dtype=float32)\n",
      "compress dense out (?, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"train/tpfy_model_v3/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'train/tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"train/tpfy_model_v3/deepfm/sparse_nn/Squeeze:0\", shape=(?, 128), dtype=float32)\n",
      "compress_output Tensor(\"train/tpfy_model_v3/deepfm/Relu:0\", shape=(?, 128), dtype=float32)\n",
      "target_output shape (?, 2)\n",
      "build weight decay\n",
      "trainable ['train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/kernel:0', 'train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/bias:0', 'train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/kernel:0', 'train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/bias:0', 'train/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_full_0:0', 'train/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_compact_0:0', 'train/tpfy_model_v3/deepfm/dnn/dnn_hyb/bias_0:0', 'train/tpfy_model_v3/deepfm/compress_dense/kernel:0', 'train/tpfy_model_v3/deepfm/compress_dense/bias:0', 'train/tpfy_model_v3/deepfm/linear/linear_bias:0', 'train/tpfy_model_v3/deepfm/linear/linear_kernel:0', 'train/tpfy_model_v3/deepfm/mtl_linear/linear_bias:0', 'train/tpfy_model_v3/deepfm/mtl_linear/linear_kernel:0', 'de_lookup/de_lookup:0', 'de_lookup/de_lookup_1:0', 'train/tpfy_model_v3/sparse_layer:0', 'train/tpfy_model_v3/click_biases:0', 'train/tpfy_model_v3/watch_biases:0', 'de_lookup/de_lookup:0', 'de_lookup/de_lookup_1:0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"train/AdamW/gradients/Reshape_105:0\", shape=(?,), dtype=int32), values=Tensor(\"train/AdamW/gradients/Reshape_104:0\", shape=(?, 32), dtype=float32), dense_shape=Tensor(\"train/AdamW/gradients/Cast_11:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"val_in-2026-01-28/tpfy_model_v3/feature_prep/strided_slice:0\", shape=(?, 32), dtype=float32)\n",
      "k Tensor(\"val_in-2026-01-28/tpfy_model_v3/feature_prep/watched_content_embedding_unpooled:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"val_in-2026-01-28/tpfy_model_v3/feature_prep/GetSlotFids:1\", shape=(?, ?), dtype=float32)\n",
      "target embedding shape (?, 9, 32)\n",
      "user embedding shape (?, 27, 32)\n",
      "target: Tensor(\"val_in-2026-01-28/tpfy_model_v3/feature_prep/target_feature/target_embeddings:0\", shape=(?, 9, 32), dtype=float32)\n",
      "user: Tensor(\"val_in-2026-01-28/tpfy_model_v3/feature_prep/user_feature/user_embeddings:0\", shape=(?, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"val_in-2026-01-28/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(?, 32), dtype=float32)\n",
      "fm_user Tensor(\"val_in-2026-01-28/tpfy_model_v3/deepfm/fwfm/concat:0\", shape=(?, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"val_in-2026-01-28/tpfy_model_v3/feature_prep/target_feature/target_embeddings:0\", shape=(?, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"val_in-2026-01-28/tpfy_model_v3/deepfm/fwfm/Reshape:0\", shape=(?, 252), dtype=float32)\n",
      "compress dense out (?, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"val_in-2026-01-28/tpfy_model_v3/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'train/tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"val_in-2026-01-28/tpfy_model_v3/deepfm/sparse_nn/Squeeze:0\", shape=(?, 128), dtype=float32)\n",
      "compress_output Tensor(\"val_in-2026-01-28/tpfy_model_v3/deepfm/Relu:0\", shape=(?, 128), dtype=float32)\n",
      "target_output shape (?, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 16:20:03.350975: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2499995000 Hz\n",
      "2026-02-03 16:20:03.478448: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on train start\n",
      "restore model weights\n",
      "reload source keys\n",
      "train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/kernel:0\n",
      "train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/bias:0\n",
      "train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/kernel:0\n",
      "train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/bias:0\n",
      "train/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_full_0:0\n",
      "train/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_compact_0:0\n",
      "train/tpfy_model_v3/deepfm/dnn/dnn_hyb/bias_0:0\n",
      "train/tpfy_model_v3/deepfm/compress_dense/kernel:0\n",
      "train/tpfy_model_v3/deepfm/compress_dense/bias:0\n",
      "train/tpfy_model_v3/deepfm/linear/linear_bias:0\n",
      "train/tpfy_model_v3/deepfm/linear/linear_kernel:0\n",
      "train/tpfy_model_v3/deepfm/mtl_linear/linear_bias:0\n",
      "train/tpfy_model_v3/deepfm/mtl_linear/linear_kernel:0\n",
      "train/tpfy_model_v3/sparse_layer:0\n",
      "train/tpfy_model_v3/click_biases:0\n",
      "train/tpfy_model_v3/watch_biases:0\n",
      "embedding_layer/fids\n",
      "embedding_layer/embeddings\n",
      "resolve dense parameters\n",
      "resolving train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/kernel:0\n",
      "hit train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/kernel:0\n",
      "restore savable variable train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/kernel:0 <tf.Variable 'train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/kernel:0' shape=(32, 32) dtype=float32>\n",
      "resolving train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/bias:0\n",
      "hit train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/bias:0\n",
      "restore savable variable train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/bias:0 <tf.Variable 'train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/bias:0' shape=(32,) dtype=float32>\n",
      "resolving train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/kernel:0\n",
      "hit train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/kernel:0\n",
      "restore savable variable train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/kernel:0 <tf.Variable 'train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/kernel:0' shape=(32, 32) dtype=float32>\n",
      "resolving train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/bias:0\n",
      "hit train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/bias:0\n",
      "restore savable variable train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/bias:0 <tf.Variable 'train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/bias:0' shape=(32,) dtype=float32>\n",
      "resolving train/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_full_0:0\n",
      "hit train/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_full_0:0\n",
      "restore savable variable train/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_full_0:0 <tf.Variable 'train/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_full_0:0' shape=(320, 256) dtype=float32>\n",
      "resolving train/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_compact_0:0\n",
      "hit train/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_compact_0:0\n",
      "restore savable variable train/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_compact_0:0 <tf.Variable 'train/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_compact_0:0' shape=(864, 256) dtype=float32>\n",
      "resolving train/tpfy_model_v3/deepfm/dnn/dnn_hyb/bias_0:0\n",
      "hit train/tpfy_model_v3/deepfm/dnn/dnn_hyb/bias_0:0\n",
      "restore savable variable train/tpfy_model_v3/deepfm/dnn/dnn_hyb/bias_0:0 <tf.Variable 'train/tpfy_model_v3/deepfm/dnn/dnn_hyb/bias_0:0' shape=(256,) dtype=float32>\n",
      "resolving train/tpfy_model_v3/deepfm/compress_dense/kernel:0\n",
      "hit train/tpfy_model_v3/deepfm/compress_dense/kernel:0\n",
      "restore savable variable train/tpfy_model_v3/deepfm/compress_dense/kernel:0 <tf.Variable 'train/tpfy_model_v3/deepfm/compress_dense/kernel:0' shape=(508, 128) dtype=float32>\n",
      "resolving train/tpfy_model_v3/deepfm/compress_dense/bias:0\n",
      "hit train/tpfy_model_v3/deepfm/compress_dense/bias:0\n",
      "restore savable variable train/tpfy_model_v3/deepfm/compress_dense/bias:0 <tf.Variable 'train/tpfy_model_v3/deepfm/compress_dense/bias:0' shape=(128,) dtype=float32>\n",
      "resolving train/tpfy_model_v3/deepfm/linear/linear_bias:0\n",
      "hit train/tpfy_model_v3/deepfm/linear/linear_bias:0\n",
      "restore savable variable train/tpfy_model_v3/deepfm/linear/linear_bias:0 <tf.Variable 'train/tpfy_model_v3/deepfm/linear/linear_bias:0' shape=(2,) dtype=float32>\n",
      "resolving train/tpfy_model_v3/deepfm/linear/linear_kernel:0\n",
      "hit train/tpfy_model_v3/deepfm/linear/linear_kernel:0\n",
      "restore savable variable train/tpfy_model_v3/deepfm/linear/linear_kernel:0 <tf.Variable 'train/tpfy_model_v3/deepfm/linear/linear_kernel:0' shape=(128, 2) dtype=float32>\n",
      "resolving train/tpfy_model_v3/deepfm/mtl_linear/linear_bias:0\n",
      "hit train/tpfy_model_v3/deepfm/mtl_linear/linear_bias:0\n",
      "restore savable variable train/tpfy_model_v3/deepfm/mtl_linear/linear_bias:0 <tf.Variable 'train/tpfy_model_v3/deepfm/mtl_linear/linear_bias:0' shape=(2,) dtype=float32>\n",
      "resolving train/tpfy_model_v3/deepfm/mtl_linear/linear_kernel:0\n",
      "hit train/tpfy_model_v3/deepfm/mtl_linear/linear_kernel:0\n",
      "restore savable variable train/tpfy_model_v3/deepfm/mtl_linear/linear_kernel:0 <tf.Variable 'train/tpfy_model_v3/deepfm/mtl_linear/linear_kernel:0' shape=(128, 2) dtype=float32>\n",
      "resolving train/tpfy_model_v3/sparse_layer:0\n",
      "hit train/tpfy_model_v3/sparse_layer:0\n",
      "restore savable variable train/tpfy_model_v3/sparse_layer:0 <tf.Variable 'train/tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "resolving train/tpfy_model_v3/click_biases:0\n",
      "hit train/tpfy_model_v3/click_biases:0\n",
      "restore savable variable train/tpfy_model_v3/click_biases:0 <tf.Variable 'train/tpfy_model_v3/click_biases:0' shape=(2,) dtype=float32>\n",
      "resolving train/tpfy_model_v3/watch_biases:0\n",
      "hit train/tpfy_model_v3/watch_biases:0\n",
      "restore savable variable train/tpfy_model_v3/watch_biases:0 <tf.Variable 'train/tpfy_model_v3/watch_biases:0' shape=(2,) dtype=float32>\n",
      "resolving embedding embedding_layer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 16:20:03.745513: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:143] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=32, init_size=8192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "Epoch 0\n",
      "start generator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 16:20:06.005470: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:143] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=32, init_size=8192\n",
      "2026-02-03 16:20:06.006211: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:143] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=32, init_size=8192\n",
      "2026-02-03 16:20:06.007099: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:143] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=32, init_size=8192\n",
      "2026-02-03 16:20:06.008099: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:143] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=32, init_size=8192\n",
      "2026-02-03 16:20:06.608141: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2026-02-03 16:20:06.608174: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2026-02-03 16:20:06.625803: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2026-02-03 16:20:06.625827: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2026-02-03 16:20:06.635398: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2026-02-03 16:20:06.635398: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2026-02-03 16:20:06.635420: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2026-02-03 16:20:06.635421: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From /home/ubuntu/vedansh/code/persona-reco-core/offline/src/main/python/model/parquet_dataset.py:52: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From /home/ubuntu/vedansh/code/persona-reco-core/offline/src/main/python/model/parquet_dataset.py:52: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From /home/ubuntu/vedansh/code/persona-reco-core/offline/src/main/python/model/parquet_dataset.py:52: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From /home/ubuntu/vedansh/code/persona-reco-core/offline/src/main/python/model/parquet_dataset.py:52: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From /home/ubuntu/vedansh/code/persona-reco-core/offline/src/main/python/model/parquet_dataset.py:52: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From /home/ubuntu/vedansh/code/persona-reco-core/offline/src/main/python/model/parquet_dataset.py:52: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From /home/ubuntu/vedansh/code/persona-reco-core/offline/src/main/python/model/parquet_dataset.py:52: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From /home/ubuntu/vedansh/code/persona-reco-core/offline/src/main/python/model/parquet_dataset.py:52: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "2026-02-03 16:20:07.802758: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2026-02-03 16:20:07.802790: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2026-02-03 16:20:07.802813: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-11-72-173): /proc/driver/nvidia/version does not exist\n",
      "2026-02-03 16:20:07.803017: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-02-03 16:20:07.807910: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2026-02-03 16:20:07.807936: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2026-02-03 16:20:07.807950: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-11-72-173): /proc/driver/nvidia/version does not exist\n",
      "2026-02-03 16:20:07.808130: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-02-03 16:20:07.809705: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2499995000 Hz\n",
      "2026-02-03 16:20:07.810680: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2026-02-03 16:20:07.810700: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2026-02-03 16:20:07.810713: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-11-72-173): /proc/driver/nvidia/version does not exist\n",
      "2026-02-03 16:20:07.810937: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-02-03 16:20:07.812606: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2499995000 Hz\n",
      "2026-02-03 16:20:07.819041: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2026-02-03 16:20:07.819060: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2026-02-03 16:20:07.819072: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-11-72-173): /proc/driver/nvidia/version does not exist\n",
      "2026-02-03 16:20:07.819239: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-02-03 16:20:07.822995: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2499995000 Hz\n",
      "2026-02-03 16:20:07.826695: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2499995000 Hz\n",
      "2026-02-03 16:20:07.835007: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2026-02-03 16:20:07.838740: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2026-02-03 16:20:07.847666: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2026-02-03 16:20:07.851560: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpfy-v3-mtl-r2 loss:0.254716, add_watchlist_loss:0.033368, click_loss:0.612241, paywall_view_loss:0.079079, random_watch_loss:0.043880, watch_loss:0.505014, click_masked_auc:0.699140, watch_masked_auc_1:0.767569, random_watch_masked_auc_2:0.994120, paywall_view_masked_auc_3:0.922986, add_watchlist_masked_auc_4:0.710154 ; time 10s\n",
      "Epoch 1\n",
      "tpfy-v3-mtl-r2 loss:0.258322, add_watchlist_loss:0.035631, click_loss:0.616898, paywall_view_loss:0.068068, random_watch_loss:0.047174, watch_loss:0.523840, click_masked_auc:0.689175, watch_masked_auc_1:0.766065, random_watch_masked_auc_2:0.991009, paywall_view_masked_auc_3:0.915290, add_watchlist_masked_auc_4:0.644746 ; time 1s\n",
      "Epoch 2\n",
      "[=======.................................]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_45858/4186824861.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mvalidation_on_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_freq\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload_local_model\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload_s3_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m )\n",
      "\u001b[0;32m~/vedansh/code/persona-reco-core/offline/src/main/python/model/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataset, epochs, steps_per_epoch, validation_data_dict, validation_steps, validation_freq, log_dir, lr_scheduler, early_stopping, verbose, validation_on_start)\u001b[0m\n\u001b[1;32m    514\u001b[0m                             )\n\u001b[1;32m    515\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 968\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    969\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1191\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1192\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1369\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1373\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1360\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1451\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1452\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1453\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1455\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnProcess-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/vedansh/code/persona-reco-core/offline/src/main/python/model/parquet_dataset.py\", line 94, in worker_v2\n",
      "    minibatch = session.run(nxt)\n",
      "  File \"/home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 968, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1191, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1369, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1375, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1360, in _run_fn\n",
      "    target_list, run_metadata)\n",
      "  File \"/home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1453, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <function BaseSession.__del__ at 0x7fe2124f4ef0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 770, in __del__\n",
      "    self.close()\n",
      "  File \"/home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 765, in close\n",
      "    tf_session.TF_CloseSession(self._session)\n",
      "KeyboardInterrupt: \n",
      "Process SpawnProcess-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/vedansh/code/persona-reco-core/offline/src/main/python/model/parquet_dataset.py\", line 95, in worker_v2\n",
      "    args.queue.put(minibatch)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/multiprocessing/queues.py\", line 82, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <function BaseSession.__del__ at 0x7f1a97d0aef0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 770, in __del__\n",
      "    self.close()\n",
      "  File \"/home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 765, in close\n",
      "    tf_session.TF_CloseSession(self._session)\n",
      "KeyboardInterrupt: \n",
      "Process SpawnProcess-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/vedansh/code/persona-reco-core/offline/src/main/python/model/parquet_dataset.py\", line 95, in worker_v2\n",
      "    args.queue.put(minibatch)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/multiprocessing/queues.py\", line 82, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <function BaseSession.__del__ at 0x7f3d782beef0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 770, in __del__\n",
      "    self.close()\n",
      "  File \"/home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 765, in close\n",
      "    tf_session.TF_CloseSession(self._session)\n",
      "KeyboardInterrupt: \n",
      "Process SpawnProcess-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/vedansh/code/persona-reco-core/offline/src/main/python/model/parquet_dataset.py\", line 94, in worker_v2\n",
      "    minibatch = session.run(nxt)\n",
      "  File \"/home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 968, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1191, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1369, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1375, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1360, in _run_fn\n",
      "    target_list, run_metadata)\n",
      "  File \"/home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1453, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/ubuntu/anaconda3/envs/tpfy_ranker_py37/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <function BaseSession.__del__ at 0x7feed792eef0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 770, in __del__\n",
      "    self.close()\n",
      "  File \"/home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 765, in close\n",
      "    tf_session.TF_CloseSession(self._session)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker start 0\n",
      "worker start 3\n",
      "worker start 1\n",
      "worker start 2\n"
     ]
    }
   ],
   "source": [
    "trainer = TpfyCustomTrainer(\n",
    "    tpfy_model,\n",
    "    session,\n",
    "    model_name,\n",
    "    plain_weights,\n",
    "    clear_nn=clear_nn,\n",
    "    weight_decay=True,\n",
    "    countries=countries,\n",
    ")\n",
    "trained_epochs = trainer.train(\n",
    "    train_tf_dataset,\n",
    "    epochs=hparams.train.max_step,\n",
    "    steps_per_epoch=hparams.train.step_unit,\n",
    "    validation_data_dict=validation_dataset_dict,\n",
    "    validation_steps=None,\n",
    "    validation_freq=hparams.train.eval_freq,\n",
    "    log_dir=\"train/logs/\" + model_name,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    early_stopping=None,\n",
    "    verbose=args.verbose,\n",
    "    validation_on_start=hparams.train.eval_freq > 0\n",
    "    and (args.reload_local_model or args.reload_s3_model),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67e121aa-d70b-4ef1-bcc1-0594d55bc595",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DEBUG MODE - Inspecting Training Data\n",
      "================================================================================\n",
      "WARNING:tensorflow:From /tmp/ipykernel_45858/2889699287.py:6: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This is a deprecated API that should only be used in TF 1 graph mode and legacy TF 2 graph mode available through `tf.compat.v1`. In all other situations -- namely, eager mode and inside `tf.function` -- you can consume dataset elements using `for elem in dataset: ...` or by explicitly creating iterator via `iterator = iter(dataset)` and fetching its elements via `values = next(iterator)`. Furthermore, this API is not available in TF 2. During the transition from TF 1 to TF 2 you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)` to create a TF 1 graph mode style iterator for a dataset created through TF 2 APIs. Note that this should be a transient state of your code base as there are in general no guarantees about the interoperability of TF 1 and TF 2 code.\n",
      "\n",
      "Fetching a batch from training dataset...\n",
      "start generator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 16:20:19.863347: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2026-02-03 16:20:19.863376: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2026-02-03 16:20:19.868369: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2026-02-03 16:20:19.868390: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2026-02-03 16:20:19.907707: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2026-02-03 16:20:19.907733: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2026-02-03 16:20:19.907834: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2026-02-03 16:20:19.907855: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From /home/ubuntu/vedansh/code/persona-reco-core/offline/src/main/python/model/parquet_dataset.py:52: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From /home/ubuntu/vedansh/code/persona-reco-core/offline/src/main/python/model/parquet_dataset.py:52: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From /home/ubuntu/vedansh/code/persona-reco-core/offline/src/main/python/model/parquet_dataset.py:52: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From /home/ubuntu/vedansh/code/persona-reco-core/offline/src/main/python/model/parquet_dataset.py:52: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "2026-02-03 16:20:21.057470: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2026-02-03 16:20:21.057496: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2026-02-03 16:20:21.057511: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-11-72-173): /proc/driver/nvidia/version does not exist\n",
      "2026-02-03 16:20:21.057705: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-02-03 16:20:21.078757: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2499995000 Hz\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From /home/ubuntu/vedansh/code/persona-reco-core/offline/src/main/python/model/parquet_dataset.py:52: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From /home/ubuntu/vedansh/code/persona-reco-core/offline/src/main/python/model/parquet_dataset.py:52: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "2026-02-03 16:20:21.100031: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2026-02-03 16:20:21.100069: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2026-02-03 16:20:21.100093: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-11-72-173): /proc/driver/nvidia/version does not exist\n",
      "2026-02-03 16:20:21.100288: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-02-03 16:20:21.103068: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2499995000 Hz\n",
      "2026-02-03 16:20:21.104269: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2026-02-03 16:20:21.127963: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2026-02-03 16:20:21.134940: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "2026-02-03 16:20:21.134963: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2026-02-03 16:20:21.134977: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-11-72-173): /proc/driver/nvidia/version does not exist\n",
      "2026-02-03 16:20:21.135169: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ubuntu/vedansh/code/persona-reco-core/offline/src/main/python/model/parquet_dataset.py:52: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From /home/ubuntu/vedansh/code/persona-reco-core/offline/src/main/python/model/parquet_dataset.py:52: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "2026-02-03 16:20:21.138886: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2499995000 Hz\n",
      "2026-02-03 16:20:21.164842: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2026-02-03 16:20:21.184871: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2026-02-03 16:20:21.184893: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2026-02-03 16:20:21.184906: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-11-72-173): /proc/driver/nvidia/version does not exist\n",
      "2026-02-03 16:20:21.185096: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-02-03 16:20:21.187091: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2499995000 Hz\n",
      "2026-02-03 16:20:21.212073: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- FEATURE SHAPES ---\n",
      "user_fids: (16, 26), dtype=int64, range=[0.0000, 1882504644240867328.0000]\n",
      "user_weighted_fids: (16, 168), dtype=int64, range=[0.0000, 311858832311094720.0000]\n",
      "user_weighted_fid_weights: (16, 168), dtype=float32, range=[0.0000, 1.0000]\n",
      "fids: (16, 12), dtype=int64, range=[0.0000, 522417556774977536.0000]\n",
      "weighted_fids: (16, 1), dtype=int64, range=[0.0000, 0.0000]\n",
      "weighted_fid_weights: (16, 1), dtype=float32, range=[0.0000, 0.0000]\n",
      "sparse_indices: (16, 13), dtype=int32, range=[1.0000, 14.0000]\n",
      "sparse_values: (16, 13), dtype=float32, range=[0.0000, 1.0000]\n",
      "task: (16, 1), dtype=int32, range=[0.0000, 1.0000]\n",
      "\n",
      "--- LABEL SHAPES ---\n",
      "click: (16, 1), valid=11/16, positive=6/11\n",
      "watch: (16, 1), valid=6/16, positive=1/6\n",
      "add_watchlist: (16, 1), valid=6/16, positive=2/6\n",
      "paywall_view: (16, 1), valid=6/16, positive=0/6\n",
      "random_watch: (16, 1), valid=5/16, positive=0/5\n",
      "\n",
      "--- FIRST EXAMPLE IN BATCH ---\n",
      "\n",
      "Features:\n",
      "  user_fids: [11868170659787972 25023955281098067 30473928018519015 40997501519105349\n",
      " 53282345950104215 60339255362303347 70085391391386307 75490802718027078\n",
      " 86474907716623441 90423943359601459] ... [26 elements]\n",
      "  user_weighted_fids: [186369897216400372 188307089044745414 182031313349290773\n",
      " 186782728854941634 183221725873380909 188271033920633964\n",
      " 188590379553095963 184732263315775324 185173105453044036\n",
      " 185528868921228717] ... [168 elements]\n",
      "  user_weighted_fid_weights: [0.06133445 0.04948286 0.04596028 0.04143861 0.03803853 0.02987953\n",
      " 0.02665653 0.0246652  0.02461822 0.02383784] ... [168 elements]\n",
      "  fids: [457601185147488637 470520451236763974 500659228808967457\n",
      " 462975135295994704 511082406522540095 478929900771607027\n",
      " 490811389240623404 517306921950591542 522417556774977539\n",
      "                  0                  0                  0]\n",
      "  weighted_fids: [0]\n",
      "  weighted_fid_weights: [0.]\n",
      "  sparse_indices: [ 1  3  4  2  6  7  8  9 10 11 12 13 14]\n",
      "  sparse_values: [0.         0.7909268  0.49280092 0.         0.13091503 0.1164637\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "  task: [1]\n",
      "\n",
      "Labels:\n",
      "  click: [-1.]\n",
      "  watch: [-1.]\n",
      "  add_watchlist: [-1.]\n",
      "  paywall_view: [-1.]\n",
      "  random_watch: [0.]\n",
      "\n",
      "Saved first example to: debug_example_tpfy-v3-mtl-r2.npz\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DEBUG MODE - Inspecting Training Data\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create debug iterator\n",
    "debug_it = train_tf_dataset.make_one_shot_iterator()\n",
    "debug_next = debug_it.get_next()\n",
    "\n",
    "# Get a batch\n",
    "print(\"\\nFetching a batch from training dataset...\")\n",
    "features, labels, metadata = session.run(debug_next)\n",
    "\n",
    "print(\"\\n--- FEATURE SHAPES ---\")\n",
    "for fname, fval in features.items():\n",
    "    print(f\"{fname}: {fval.shape}, dtype={fval.dtype}, \"\n",
    "          f\"range=[{np.min(fval):.4f}, {np.max(fval):.4f}]\")\n",
    "\n",
    "print(\"\\n--- LABEL SHAPES ---\")\n",
    "for lname, lval in labels.items():\n",
    "    valid_count = np.sum(lval != -1)\n",
    "    pos_count = np.sum(lval > 0)\n",
    "    print(f\"{lname}: {lval.shape}, valid={valid_count}/{lval.size}, \"\n",
    "          f\"positive={pos_count}/{valid_count if valid_count > 0 else 1}\")\n",
    "\n",
    "print(\"\\n--- FIRST EXAMPLE IN BATCH ---\")\n",
    "print(\"\\nFeatures:\")\n",
    "for fname, fval in features.items():\n",
    "    ex = fval[0]\n",
    "    if ex.size > 20:\n",
    "        print(f\"  {fname}: {ex[:10]} ... [{ex.size} elements]\")\n",
    "    else:\n",
    "        print(f\"  {fname}: {ex}\")\n",
    "\n",
    "print(\"\\nLabels:\")\n",
    "for lname, lval in labels.items():\n",
    "    print(f\"  {lname}: {lval[0]}\")\n",
    "\n",
    "# Save example for later use\n",
    "debug_example_path = f'debug_example_{model_name}.npz'\n",
    "np.savez(\n",
    "    debug_example_path,\n",
    "    # **{f\"feature_{k}\": v[0:1] for k, v in features.items()},\n",
    "    # **{f\"label_{k}\": v[0:1] for k, v in labels.items()},\n",
    "    # **{f\"metadata_{k}\": v[0:1] for k, v in metadata.items()},\n",
    "    **{f\"feature_{k}\": v for k, v in features.items()},\n",
    "    **{f\"label_{k}\": v for k, v in labels.items()},\n",
    "    **{f\"metadata_{k}\": v for k, v in metadata.items()},\n",
    ")\n",
    "print(f\"\\nSaved first example to: {debug_example_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b1130ec-1ec3-4816-8231-aea0608ce790",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 26)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['user_fids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a467a7a-4ea1-4b52-9205-72fdc45d8bbe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DEBUG MODE - Testing Model Predictions\n",
      "================================================================================\n",
      "\n",
      "Loading example from: debug_example_tpfy-v3-mtl-r2.npz\n",
      "\n",
      "Running model prediction...\n",
      "--------------\n",
      "q Tensor(\"tpfy_model_v3/feature_prep/strided_slice:0\", shape=(16, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3/feature_prep/watched_content_embedding_unpooled:0\", shape=(16, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3/feature_prep/GetSlotFids:1\", shape=(16, ?), dtype=float32)\n",
      "target embedding shape (16, 9, 32)\n",
      "user embedding shape (16, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3/feature_prep/target_feature/target_embeddings:0\", shape=(16, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3/feature_prep/user_feature/user_embeddings:0\", shape=(16, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(16, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3/deepfm/fwfm/concat:0\", shape=(16, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3/feature_prep/target_feature/target_embeddings:0\", shape=(16, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3/deepfm/fwfm/Reshape:0\", shape=(16, 252), dtype=float32)\n",
      "compress dense out (16, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'train/tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3/deepfm/sparse_nn/Squeeze:0\", shape=(16, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3/deepfm/Relu:0\", shape=(16, 128), dtype=float32)\n",
      "target_output shape (16, 2)\n",
      "\n",
      "--- PREDICTIONS ---\n",
      "\n",
      "random_watch: sample : 0\n",
      "  Prediction: [1.4794443e-05]\n",
      "  Ground truth: [0.]\n",
      "\n",
      "random_watch: sample : 1\n",
      "  Prediction: [0.49963456]\n",
      "  Ground truth: [0.]\n",
      "\n",
      "random_watch: sample : 2\n",
      "  Prediction: [0.27045304]\n",
      "  Ground truth: [0.]\n",
      "\n",
      "random_watch: sample : 3\n",
      "  Prediction: [8.664481e-06]\n",
      "  Ground truth: [0.]\n",
      "\n",
      "random_watch: sample : 4\n",
      "  Prediction: [0.00165778]\n",
      "  Ground truth: [0.]\n",
      "\n",
      "random_watch: sample : 5\n",
      "  Prediction: [0.3124354]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "random_watch: sample : 6\n",
      "  Prediction: [0.24451001]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "random_watch: sample : 7\n",
      "  Prediction: [0.11200228]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "random_watch: sample : 8\n",
      "  Prediction: [0.11844994]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "random_watch: sample : 9\n",
      "  Prediction: [0.08824085]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "random_watch: sample : 10\n",
      "  Prediction: [0.24625127]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "random_watch: sample : 11\n",
      "  Prediction: [0.20515773]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "random_watch: sample : 12\n",
      "  Prediction: [0.19095413]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "random_watch: sample : 13\n",
      "  Prediction: [0.12839974]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "random_watch: sample : 14\n",
      "  Prediction: [0.09050013]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "random_watch: sample : 15\n",
      "  Prediction: [0.11981328]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "click: sample : 0\n",
      "  Prediction: [-3.7573314]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "click: sample : 1\n",
      "  Prediction: [0.05756629]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "click: sample : 2\n",
      "  Prediction: [-0.9677216]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "click: sample : 3\n",
      "  Prediction: [-4.42958]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "click: sample : 4\n",
      "  Prediction: [-3.4903874]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "click: sample : 5\n",
      "  Prediction: [0.43552977]\n",
      "  Ground truth: [1.]\n",
      "\n",
      "click: sample : 6\n",
      "  Prediction: [0.01660162]\n",
      "  Ground truth: [1.]\n",
      "\n",
      "click: sample : 7\n",
      "  Prediction: [-0.86817867]\n",
      "  Ground truth: [1.]\n",
      "\n",
      "click: sample : 8\n",
      "  Prediction: [-0.4575747]\n",
      "  Ground truth: [1.]\n",
      "\n",
      "click: sample : 9\n",
      "  Prediction: [-0.6720172]\n",
      "  Ground truth: [1.]\n",
      "\n",
      "click: sample : 10\n",
      "  Prediction: [-0.21160021]\n",
      "  Ground truth: [0.]\n",
      "\n",
      "click: sample : 11\n",
      "  Prediction: [-0.11968899]\n",
      "  Ground truth: [0.]\n",
      "\n",
      "click: sample : 12\n",
      "  Prediction: [0.00341928]\n",
      "  Ground truth: [0.]\n",
      "\n",
      "click: sample : 13\n",
      "  Prediction: [-0.54020333]\n",
      "  Ground truth: [0.]\n",
      "\n",
      "click: sample : 14\n",
      "  Prediction: [-1.0684962]\n",
      "  Ground truth: [0.]\n",
      "\n",
      "click: sample : 15\n",
      "  Prediction: [1.5027719]\n",
      "  Ground truth: [1.]\n",
      "\n",
      "click_recab: sample : 0\n",
      "  Prediction: [-6.28306]\n",
      "\n",
      "click_recab: sample : 1\n",
      "  Prediction: [-2.4681625]\n",
      "\n",
      "click_recab: sample : 2\n",
      "  Prediction: [-3.4934502]\n",
      "\n",
      "click_recab: sample : 3\n",
      "  Prediction: [-6.955309]\n",
      "\n",
      "click_recab: sample : 4\n",
      "  Prediction: [-6.016116]\n",
      "\n",
      "click_recab: sample : 5\n",
      "  Prediction: [-2.090199]\n",
      "\n",
      "click_recab: sample : 6\n",
      "  Prediction: [-2.5091271]\n",
      "\n",
      "click_recab: sample : 7\n",
      "  Prediction: [-3.3939073]\n",
      "\n",
      "click_recab: sample : 8\n",
      "  Prediction: [-2.9833033]\n",
      "\n",
      "click_recab: sample : 9\n",
      "  Prediction: [-3.1977458]\n",
      "\n",
      "click_recab: sample : 10\n",
      "  Prediction: [-2.737329]\n",
      "\n",
      "click_recab: sample : 11\n",
      "  Prediction: [-2.6454177]\n",
      "\n",
      "click_recab: sample : 12\n",
      "  Prediction: [-2.5223093]\n",
      "\n",
      "click_recab: sample : 13\n",
      "  Prediction: [-3.065932]\n",
      "\n",
      "click_recab: sample : 14\n",
      "  Prediction: [-3.594225]\n",
      "\n",
      "click_recab: sample : 15\n",
      "  Prediction: [-1.0229568]\n",
      "\n",
      "watch: sample : 0\n",
      "  Prediction: [-7.3402615]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "watch: sample : 1\n",
      "  Prediction: [3.5224292]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "watch: sample : 2\n",
      "  Prediction: [4.0145755]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "watch: sample : 3\n",
      "  Prediction: [-7.214139]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "watch: sample : 4\n",
      "  Prediction: [-2.8241956]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "watch: sample : 5\n",
      "  Prediction: [0.05824316]\n",
      "  Ground truth: [1.]\n",
      "\n",
      "watch: sample : 6\n",
      "  Prediction: [-0.06004113]\n",
      "  Ground truth: [0.]\n",
      "\n",
      "watch: sample : 7\n",
      "  Prediction: [-0.49441004]\n",
      "  Ground truth: [0.]\n",
      "\n",
      "watch: sample : 8\n",
      "  Prediction: [-0.82063496]\n",
      "  Ground truth: [0.]\n",
      "\n",
      "watch: sample : 9\n",
      "  Prediction: [-1.0406082]\n",
      "  Ground truth: [0.]\n",
      "\n",
      "watch: sample : 10\n",
      "  Prediction: [0.20282269]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "watch: sample : 11\n",
      "  Prediction: [-0.2557836]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "watch: sample : 12\n",
      "  Prediction: [-0.48421848]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "watch: sample : 13\n",
      "  Prediction: [-0.62440896]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "watch: sample : 14\n",
      "  Prediction: [-0.60173905]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "watch: sample : 15\n",
      "  Prediction: [-1.762534]\n",
      "  Ground truth: [0.]\n",
      "\n",
      "paywall_view: sample : 0\n",
      "  Prediction: [-9.827281]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "paywall_view: sample : 1\n",
      "  Prediction: [-8.7593775]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "paywall_view: sample : 2\n",
      "  Prediction: [-8.323275]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "paywall_view: sample : 3\n",
      "  Prediction: [-9.671115]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "paywall_view: sample : 4\n",
      "  Prediction: [-9.886013]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "paywall_view: sample : 5\n",
      "  Prediction: [-11.418112]\n",
      "  Ground truth: [0.]\n",
      "\n",
      "paywall_view: sample : 6\n",
      "  Prediction: [-11.063245]\n",
      "  Ground truth: [0.]\n",
      "\n",
      "paywall_view: sample : 7\n",
      "  Prediction: [-11.166719]\n",
      "  Ground truth: [0.]\n",
      "\n",
      "paywall_view: sample : 8\n",
      "  Prediction: [-10.8757925]\n",
      "  Ground truth: [0.]\n",
      "\n",
      "paywall_view: sample : 9\n",
      "  Prediction: [-11.800408]\n",
      "  Ground truth: [0.]\n",
      "\n",
      "paywall_view: sample : 10\n",
      "  Prediction: [-11.549151]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "paywall_view: sample : 11\n",
      "  Prediction: [-10.668536]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "paywall_view: sample : 12\n",
      "  Prediction: [-11.33806]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "paywall_view: sample : 13\n",
      "  Prediction: [-11.972578]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "paywall_view: sample : 14\n",
      "  Prediction: [-11.123715]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "paywall_view: sample : 15\n",
      "  Prediction: [-5.308857]\n",
      "  Ground truth: [0.]\n",
      "\n",
      "add_watchlist: sample : 0\n",
      "  Prediction: [-4.554417]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "add_watchlist: sample : 1\n",
      "  Prediction: [-4.028332]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "add_watchlist: sample : 2\n",
      "  Prediction: [-3.579029]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "add_watchlist: sample : 3\n",
      "  Prediction: [-4.2510552]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "add_watchlist: sample : 4\n",
      "  Prediction: [-3.7871976]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "add_watchlist: sample : 5\n",
      "  Prediction: [-2.8719542]\n",
      "  Ground truth: [0.]\n",
      "\n",
      "add_watchlist: sample : 6\n",
      "  Prediction: [-2.6605794]\n",
      "  Ground truth: [1.]\n",
      "\n",
      "add_watchlist: sample : 7\n",
      "  Prediction: [-2.7455463]\n",
      "  Ground truth: [0.]\n",
      "\n",
      "add_watchlist: sample : 8\n",
      "  Prediction: [-2.9784114]\n",
      "  Ground truth: [1.]\n",
      "\n",
      "add_watchlist: sample : 9\n",
      "  Prediction: [-2.565832]\n",
      "  Ground truth: [0.]\n",
      "\n",
      "add_watchlist: sample : 10\n",
      "  Prediction: [-3.10338]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "add_watchlist: sample : 11\n",
      "  Prediction: [-3.0279856]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "add_watchlist: sample : 12\n",
      "  Prediction: [-2.7071936]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "add_watchlist: sample : 13\n",
      "  Prediction: [-2.4960337]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "add_watchlist: sample : 14\n",
      "  Prediction: [-2.903486]\n",
      "  Ground truth: [-1.]\n",
      "\n",
      "add_watchlist: sample : 15\n",
      "  Prediction: [-4.530161]\n",
      "  Ground truth: [0.]\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DEBUG MODE - Testing Model Predictions\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load the saved example\n",
    "debug_example_path = f'debug_example_{model_name}.npz'\n",
    "if os.path.exists(debug_example_path):\n",
    "    print(f\"\\nLoading example from: {debug_example_path}\")\n",
    "    data = np.load(debug_example_path)\n",
    "    test_features = {k.replace('feature_', ''): v for k, v in data.items() \n",
    "                    if k.startswith('feature_')}\n",
    "    test_labels = {k.replace('label_', ''): v for k, v in data.items() \n",
    "                  if k.startswith('label_')}\n",
    "\n",
    "    print(\"\\nRunning model prediction...\")\n",
    "    predictions = tpfy_model(test_features, training=False)\n",
    "    pred_values = session.run(predictions)\n",
    "\n",
    "    print(\"\\n--- PREDICTIONS ---\")\n",
    "    for task_name, pred in pred_values.items():\n",
    "        for index, prediction in enumerate(pred):\n",
    "            print(f\"\\n{task_name}: sample : {index}\")\n",
    "            print(f\"  Prediction: {prediction}\")\n",
    "            if task_name != 'click_recab':\n",
    "                print(f\"  Ground truth: {test_labels[task_name][index]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9271a207-9b02-49ff-84b0-1b13abb69685",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DEBUG MODE - Extracting Activations via Tensor Names\n",
      "================================================================================\n",
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_2/feature_prep/strided_slice:0\", shape=(16, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_2/feature_prep/watched_content_embedding_unpooled:0\", shape=(16, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_2/feature_prep/GetSlotFids:1\", shape=(16, ?), dtype=float32)\n",
      "target embedding shape (16, 9, 32)\n",
      "user embedding shape (16, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_2/feature_prep/target_feature/target_embeddings:0\", shape=(16, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_2/feature_prep/user_feature/user_embeddings:0\", shape=(16, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_2/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(16, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_2/deepfm/fwfm/concat:0\", shape=(16, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_2/feature_prep/target_feature/target_embeddings:0\", shape=(16, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_2/deepfm/fwfm/Reshape:0\", shape=(16, 252), dtype=float32)\n",
      "compress dense out (16, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_2/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'train/tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_2/deepfm/sparse_nn/Squeeze:0\", shape=(16, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_2/deepfm/Relu:0\", shape=(16, 128), dtype=float32)\n",
      "target_output shape (16, 2)\n",
      "\n",
      "--- LAST LAYER ACTIVATIONS ---\n",
      "Shape: (16, 128)\n",
      "First example activations:\n",
      "[0.08695749 0.         0.         0.         0.         0.\n",
      " 0.78716743 0.01773863 0.         0.449311   0.18746579 0.\n",
      " 0.         0.31603715 0.         0.20602731 0.78144383 0.06048387\n",
      " 0.         0.         0.26326728 0.         0.         0.\n",
      " 0.08943954 0.         0.4442915  0.         0.         0.01635639\n",
      " 0.12391361 0.         0.08880766 0.0822864  0.         0.\n",
      " 0.         0.3119455  0.         0.08248432 0.         0.16048622\n",
      " 0.         0.         0.         0.48351926 0.7710632  0.02109431\n",
      " 0.         0.         0.38850766 0.71469355 0.0494737  0.7755226\n",
      " 0.22736154 0.738459   0.6852269  0.18739124 0.         0.\n",
      " 0.76795065 0.78708273 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.79704624\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.5362563  0.04743327 0.         0.         1.1576066\n",
      " 1.2469144  0.         0.         0.26556736 0.         0.\n",
      " 0.67339504 0.         0.         0.         0.         0.28723362\n",
      " 0.00950024 0.         0.         0.8401183  0.3061657  0.\n",
      " 0.7791392  0.2916312  0.         0.         0.7758274  0.\n",
      " 0.         0.         0.3318346  0.         0.17853221 0.7153471\n",
      " 0.         0.49070883 0.         0.         0.6748913  0.\n",
      " 0.75149083 0.05950324 0.4071493  0.         0.         0.\n",
      " 0.36290652 0.16960958]\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DEBUG MODE - Extracting Activations via Tensor Names\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load example\n",
    "debug_example_path = f'debug_example_{model_name}.npz'\n",
    "if os.path.exists(debug_example_path):\n",
    "    data = np.load(debug_example_path)\n",
    "    test_features = {k.replace('feature_', ''): v for k, v in data.items() \n",
    "                    if k.startswith('feature_')}\n",
    "    test_labels = {k.replace('label_', ''): v for k, v in data.items() \n",
    "                  if k.startswith('label_')}\n",
    "\n",
    "    # Run model to build the graph\n",
    "    predictions = tpfy_model(test_features, training=False)\n",
    "\n",
    "    # Access the compression layer output by name\n",
    "    graph = tf.compat.v1.get_default_graph()\n",
    "\n",
    "    # Find the compress_out tensor (the name is set in the model)\n",
    "    compress_output_tensor = graph.get_tensor_by_name('train/tpfy_model_v3/deepfm/Relu:0')\n",
    "    \n",
    "    # Run both predictions and activations\n",
    "    pred_values, activation_values = session.run(\n",
    "        [predictions, compress_output_tensor]\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- LAST LAYER ACTIVATIONS ---\")\n",
    "    print(f\"Shape: {activation_values.shape}\")\n",
    "    print(f\"First example activations:\\n{activation_values[0]}\")\n",
    "\n",
    "    # Save for later use\n",
    "    np.save(f'debug_activations_{model_name}.npy', activation_values)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a834805-bda5-4dd7-8969-42eac31e17f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08695749, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.78716743, 0.01773863, 0.        , 0.449311  ,\n",
       "       0.18746579, 0.        , 0.        , 0.31603715, 0.        ,\n",
       "       0.20602731, 0.78144383, 0.06048387, 0.        , 0.        ,\n",
       "       0.26326728, 0.        , 0.        , 0.        , 0.08943954,\n",
       "       0.        , 0.4442915 , 0.        , 0.        , 0.01635639,\n",
       "       0.12391361, 0.        , 0.08880766, 0.0822864 , 0.        ,\n",
       "       0.        , 0.        , 0.3119455 , 0.        , 0.08248432,\n",
       "       0.        , 0.16048622, 0.        , 0.        , 0.        ,\n",
       "       0.48351926, 0.7710632 , 0.02109431, 0.        , 0.        ,\n",
       "       0.38850766, 0.71469355, 0.0494737 , 0.7755226 , 0.22736154,\n",
       "       0.738459  , 0.6852269 , 0.18739124, 0.        , 0.        ,\n",
       "       0.76795065, 0.78708273, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.79704624, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.5362563 ,\n",
       "       0.04743327, 0.        , 0.        , 1.1576066 , 1.2469144 ,\n",
       "       0.        , 0.        , 0.26556736, 0.        , 0.        ,\n",
       "       0.67339504, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.28723362, 0.00950024, 0.        , 0.        , 0.8401183 ,\n",
       "       0.3061657 , 0.        , 0.7791392 , 0.2916312 , 0.        ,\n",
       "       0.        , 0.7758274 , 0.        , 0.        , 0.        ,\n",
       "       0.3318346 , 0.        , 0.17853221, 0.7153471 , 0.        ,\n",
       "       0.49070883, 0.        , 0.        , 0.6748913 , 0.        ,\n",
       "       0.75149083, 0.05950324, 0.4071493 , 0.        , 0.        ,\n",
       "       0.        , 0.36290652, 0.16960958], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c84ada7e-92b0-46a4-86b7-0bdffefad1aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.7573314], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_values['click'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1f1083f-558d-4f42-8fa3-f4795d743737",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_weights['train/tpfy_model_v3/deepfm/linear/linear_bias:0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "93c80cb6-98f2-4996-b2b4-bd779b3f707d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "relu_output = activation_values[0]\n",
    "weights = plain_weights['train/tpfy_model_v3/deepfm/linear/linear_kernel:0']\n",
    "bias = plain_weights['train/tpfy_model_v3/deepfm/linear/linear_bias:0']\n",
    "\n",
    "relu_output_reshaped = tf.reshape(relu_output, (1, 128))\n",
    "bias_reshaped = tf.reshape(bias, (1, 2))\n",
    "activation = tf.matmul(relu_output_reshaped, weights)\n",
    "output = activation + bias_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "02ef389c-9bfc-40f7-a0ea-4f16fcc961e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0678123, -0.4755299]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "09a85007-d5fa-4348-a821-8ddcd403db86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_2:0' shape=(1, 128) dtype=float32>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2698444f-ce90-413f-a0c6-42a5b7edd34d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128,), (128, 2))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_values[0].shape, plain_weights['train/tpfy_model_v3/deepfm/linear/linear_kernel:0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9d41c0bd-dcc9-4fcf-acf9-4684b48ba643",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "activations = tf.matmul(activation_values[0].reshape(1, 128), plain_weights['train/tpfy_model_v3/deepfm/linear/linear_kernel:0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a5e6fd9d-6ecc-4f30-87c7-41664655b15f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MatMul_6:0' shape=(1, 2) dtype=float32>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb16ac8a-241d-4d12-991f-0268435d8d19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "\n        'Tensor' object has no attribute 'reshape'.\n        If you are looking for numpy-related methods, please run the following:\n        import tensorflow.python.ops.numpy_ops.np_config\n        np_config.enable_numpy_behavior()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_45858/3284913889.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplain_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train/tpfy_model_v3/deepfm/linear/linear_kernel:0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mplain_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train/tpfy_model_v3/deepfm/linear/linear_bias:0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0mIf\u001b[0m \u001b[0myou\u001b[0m \u001b[0mare\u001b[0m \u001b[0mlooking\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mrelated\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplease\u001b[0m \u001b[0mrun\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfollowing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         np_config.enable_numpy_behavior()\"\"\".format(type(self).__name__, name))\n\u001b[0m\u001b[1;32m    401\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: \n        'Tensor' object has no attribute 'reshape'.\n        If you are looking for numpy-related methods, please run the following:\n        import tensorflow.python.ops.numpy_ops.np_config\n        np_config.enable_numpy_behavior()"
     ]
    }
   ],
   "source": [
    "tf.matmul(activation_values[0].reshape(1, 128), plain_weights['train/tpfy_model_v3/deepfm/linear/linear_kernel:0']).reshape(2,) + plain_weights['train/tpfy_model_v3/deepfm/linear/linear_bias:0']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3989974-d6bc-4d28-8895-5eeb85f54dda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
