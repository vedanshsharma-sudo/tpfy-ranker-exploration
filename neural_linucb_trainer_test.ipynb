{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00ffa1ee-c674-47f6-90c7-90a482abf942",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-17 06:31:09.688980: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2026-02-17 06:31:09.689009: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:dynamic_embedding.GraphKeys has already been deprecated. The Variable will not be added to collections because it does not actully own any value, but only a holder of tables, which may lead to import_meta_graph failed since non-valued object has been added to collection. If you need to use `tf.compat.v1.train.Saver` and access all Variables from collection, you could manually add it to the collection by tf.compat.v1.add_to_collections(names, var) instead.\n",
      "WARNING: env TENANT is not set, use the default value apse1-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-17 06:31:10.706982: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2026-02-17 06:31:10.707008: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2026-02-17 06:31:10.707024: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-11-72-173): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "# %load neural_linucb_trainer.py\n",
    "# python3.7 -m 6_1-disjoint_NeuralLinUCB_trainer.py tpfy-v3-mtl-r2 2026-02-09 --checkpoint 1770723470\n",
    "import os\n",
    "os.environ['ENV'] = 'prod'\n",
    "os.environ['REGION'] = 'apse1'\n",
    "os.environ['TENANT'] =\"in\"\n",
    "os.environ['RECO_S3_BUCKET'] = \"p13n-reco-offline-prod\"\n",
    "os.environ['COUNTRY_KEY']= \"in\"\n",
    "os.environ['AWS_REGION']= \"ap-southeast-1\"\n",
    "os.environ['USE_REAL_CMS3']= \"True\"\n",
    "os.environ['RECO_CREDENTIAL']= \"-----BEGINRSAPRIVATEKEY-----\\nMGICAQACEQCdHOlGnxIMWCMzjK2JAg37AgMBAAECEGOIwGTEO9vd3X9+jyiF4NECCQnoqDakDgSm2QIID9sadWN0XvMCCQLiqPkgVKSuIQIIDCAsWM+pJB8CCQG0jbIGCNX9MA==\\n-----ENDRSAPRIVATEKEY-----\"\n",
    "\n",
    "import argparse, gc\n",
    "import os, time, shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tfv1 = tf.compat.v1\n",
    "tfv1.disable_v2_behavior()\n",
    "\n",
    "# Enable memory growth for GPUs to avoid memory fragmentation\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    for device in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_recommenders_addons as tfra\n",
    "from model.losses import masked_binary_entropy_loss\n",
    "from model.metrics import MaskedAUC\n",
    "\n",
    "from common.config.utils import data_path, model_path\n",
    "from common.config import TENANT\n",
    "from tpfy.tf_model.tpfy_model_v3_mtl import TpfyModelV3\n",
    "from omegaconf import OmegaConf\n",
    "from tpfy.train_v3_mtl import TpfyConfig\n",
    "from tpfy.helper import load_model_weights_from_s3, create_dataset, save_matrices, load_matrices_from_s3\n",
    "from common.s3_utils import upload_folder\n",
    "\n",
    "def load_and_compile_model(args, hparams):\n",
    "    # Build model\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"BUILDING MODEL\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    model = TpfyModelV3(\n",
    "        hparams.model,\n",
    "        click_ns=args.click_ns,\n",
    "        enable_random_watch=hparams.train.enable_random_watch,\n",
    "    )\n",
    "\n",
    "    # Create optimizer (needed for compilation, even though we won't train)\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        weight_decay=0.0,  # Not needed for inference\n",
    "        learning_rate=0.001,  # Not needed for inference\n",
    "        epsilon=1e-4,\n",
    "    )\n",
    "\n",
    "    loss_dict = {\n",
    "            \"click\": masked_binary_entropy_loss(from_logits=True),\n",
    "            \"watch\": masked_binary_entropy_loss(from_logits=True),\n",
    "            \"random_watch\": masked_binary_entropy_loss(from_logits=False),\n",
    "            \"paywall_view\": masked_binary_entropy_loss(from_logits=True),\n",
    "            \"add_watchlist\": masked_binary_entropy_loss(from_logits=True),\n",
    "    }\n",
    "    metric_dict = {\n",
    "            \"click\": MaskedAUC(from_logits=True),\n",
    "            \"watch\": MaskedAUC(from_logits=True),\n",
    "            \"random_watch\": MaskedAUC(from_logits=False),\n",
    "            \"paywall_view\": MaskedAUC(from_logits=True),\n",
    "            \"add_watchlist\": MaskedAUC(from_logits=True),\n",
    "    }\n",
    "\n",
    "    optimizer = tfra.dynamic_embedding.DynamicEmbeddingOptimizer(optimizer)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss_dict, metrics=metric_dict)\n",
    "    print(\"Model compiled\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def compute_A_b(A, b, next_batch, last_layer_tensor, session):\n",
    "    features, labels, _ = session.run(next_batch)\n",
    "    \n",
    "    activation_values = session.run(\n",
    "        last_layer_tensor,\n",
    "        feed_dict={} if not features else None  \n",
    "    )\n",
    "    y_batch = labels['click']\n",
    "    mask = (y_batch != -1)\n",
    "\n",
    "    if not np.any(mask):\n",
    "        del activation_values, labels, mask\n",
    "        return A, b\n",
    "\n",
    "    H = activation_values[mask.squeeze()].copy() \n",
    "    y_batch = y_batch[mask].reshape(sum(mask)[0], )\n",
    "    \n",
    "    del activation_values, mask  # Delete immediately\n",
    "    \n",
    "    H = H / (np.linalg.norm(H, axis=1, keepdims=True) + 1e-8)\n",
    "    A += H.T @ H\n",
    "    b += H.T @ y_batch\n",
    "\n",
    "    del H, labels, y_batch\n",
    "    return A, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5254344c-0e1c-4a8d-bc27-459fef9d2b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded config: tpfy/tpfy_config/mtl-in.yaml\n",
      "WARNING:tensorflow:From /tmp/ipykernel_12129/1459802943.py:47: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n",
      "\n",
      "Start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-17 06:31:11.335398: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    \"\"\"Simple class to hold training arguments (replaces argparse)\"\"\"\n",
    "    def __init__(self):\n",
    "        # Positional arguments\n",
    "        self.model_name = \"tpfy-v3-mtl-r2\"\n",
    "        self.date = \"2026-02-06\"  # Training date\n",
    "        self.click_ns = 0.08\n",
    "        self.lambda_reg = 0.08\n",
    "        self.variant = \"cms3\"\n",
    "        self.batch_size = 512\n",
    "        self.upload = False  # Set to False if you don't want to upload to S3\n",
    "        self.clear_nn = False\n",
    "        self.checkpoint = None\n",
    "        self.layer_name = 'Relu'\n",
    "        self.logging_steps = 1000\n",
    "        self.reset_matrix = False\n",
    "\n",
    "args = Args()\n",
    "\n",
    "#     parser = argparse.ArgumentParser(description=\"TPFY Exploration offline Training.\")\n",
    "#     parser.add_argument(\"model_name\", type=str)\n",
    "#     parser.add_argument(\"date\", type=str)\n",
    "#     parser.add_argument(\"--click_ns\", type=float, default=0.08)\n",
    "#     parser.add_argument(\"--lambda_reg\", type=float, default=1)\n",
    "#     parser.add_argument(\"--variant\", type=str, default=\"cms3\")\n",
    "#     parser.add_argument(\"--batch_size\", type=int, default=512)\n",
    "#     parser.add_argument(\"--clear_nn\", action=\"store_true\", default=False)\n",
    "#     parser.add_argument(\"--checkpoint\", default=None, type=str)\n",
    "#     parser.add_argument(\"--layer_name\", default='Relu', type=str)\n",
    "#     parser.add_argument(\"--upload\", action=\"store_true\", help=\"uploading model to s3\")\n",
    "#     parser.add_argument(\"--logging_steps\", default=1000, type=int)\n",
    "#     parser.add_argument(\"--reset_matrix\", action=\"store_true\", default=False)\n",
    "\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "# Load configuration\n",
    "config_name = f\"tpfy/tpfy_config/mtl-{TENANT}.yaml\"\n",
    "if not os.path.exists(config_name):\n",
    "    raise FileNotFoundError(f\"Config file {config_name} not found\")\n",
    "\n",
    "hparams: TpfyConfig = OmegaConf.merge(\n",
    "    OmegaConf.structured(TpfyConfig),\n",
    "    OmegaConf.load(config_name),\n",
    ")\n",
    "print(f\"\\nLoaded config: {config_name}\")\n",
    "\n",
    "session = tfv1.keras.backend.get_session()\n",
    "print(\"Start training\")\n",
    "# run(args, session, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a993d35-ce34-4daf-b023-08cfe2c8f0cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "validation_date = args.date\n",
    "validation_data_path = f's3://p13n-reco-offline-prod/upload_objects/test_vedansh/daily-mtl-extracted-cms3-minimum-5-contents/tmp/'\n",
    "\n",
    "tmp = pd.read_parquet(validation_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81d0a60b-8455-47db-a626-fb6f7aaf2dfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.765625"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.shape[0]/512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41715aa3-6bb3-4b91-ae5c-00e33463e70a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files s3://p13n-reco-offline-prod/upload_objects/test_vedansh/daily-mtl-extracted-cms3-minimum-5-contents/tmp/dummpy.parquet\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/model/parquet_dataset.py:52: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/model/parquet_dataset.py:52: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From /tmp/ipykernel_12129/3707189807.py:12: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This is a deprecated API that should only be used in TF 1 graph mode and legacy TF 2 graph mode available through `tf.compat.v1`. In all other situations -- namely, eager mode and inside `tf.function` -- you can consume dataset elements using `for elem in dataset: ...` or by explicitly creating iterator via `iterator = iter(dataset)` and fetching its elements via `values = next(iterator)`. Furthermore, this API is not available in TF 2. During the transition from TF 1 to TF 2 you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)` to create a TF 1 graph mode style iterator for a dataset created through TF 2 APIs. Note that this should be a transient state of your code base as there are in general no guarantees about the interoperability of TF 1 and TF 2 code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-17 06:31:14.967030: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2499995000 Hz\n",
      "2026-02-17 06:31:15.012856: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "BUILDING MODEL\n",
      "================================================================================\n",
      "Model compiled\n",
      "--------------\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "q Tensor(\"tpfy_model_v3/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n",
      "Reading checkpoint from: s3://p13n-reco-offline-models-prod/models/tpfy/tpfy-v3-mtl-r2/checkpoint\n",
      "Using checkpoint: 1771240377\n",
      "Loading weights from: s3://p13n-reco-offline-models-prod/models/tpfy/tpfy-v3-mtl-r2/1771240377/plain_weights.npz\n",
      "Loaded 18 weight tensors\n",
      "Weight keys: ['train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/kernel:0', 'train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/bias:0', 'train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/kernel:0', 'train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/bias:0', 'train/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_full_0:0', 'train/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_compact_0:0', 'train/tpfy_model_v3/deepfm/dnn/dnn_hyb/bias_0:0', 'train/tpfy_model_v3/deepfm/compress_dense/kernel:0', 'train/tpfy_model_v3/deepfm/compress_dense/bias:0', 'train/tpfy_model_v3/deepfm/linear/linear_bias:0']...\n",
      "reload source keys\n",
      "tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/kernel:0\n",
      "tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/bias:0\n",
      "tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/kernel:0\n",
      "tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/bias:0\n",
      "tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_full_0:0\n",
      "tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_compact_0:0\n",
      "tpfy_model_v3/deepfm/dnn/dnn_hyb/bias_0:0\n",
      "tpfy_model_v3/deepfm/compress_dense/kernel:0\n",
      "tpfy_model_v3/deepfm/compress_dense/bias:0\n",
      "tpfy_model_v3/deepfm/linear/linear_bias:0\n",
      "tpfy_model_v3/deepfm/linear/linear_kernel:0\n",
      "tpfy_model_v3/deepfm/mtl_linear/linear_bias:0\n",
      "tpfy_model_v3/deepfm/mtl_linear/linear_kernel:0\n",
      "tpfy_model_v3/sparse_layer:0\n",
      "tpfy_model_v3/click_biases:0\n",
      "tpfy_model_v3/watch_biases:0\n",
      "embedding_layer/fids\n",
      "embedding_layer/embeddings\n",
      "resolve dense parameters\n",
      "resolving tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/kernel:0\n",
      "hit tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/kernel:0\n",
      "restore savable variable tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/kernel:0 <tf.Variable 'tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/kernel:0' shape=(32, 32) dtype=float32>\n",
      "resolving tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/bias:0\n",
      "hit tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/bias:0\n",
      "restore savable variable tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/bias:0 <tf.Variable 'tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/bias:0' shape=(32,) dtype=float32>\n",
      "resolving tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/kernel:0\n",
      "hit tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/kernel:0\n",
      "restore savable variable tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/kernel:0 <tf.Variable 'tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/kernel:0' shape=(32, 32) dtype=float32>\n",
      "resolving tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/bias:0\n",
      "hit tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/bias:0\n",
      "restore savable variable tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/bias:0 <tf.Variable 'tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/bias:0' shape=(32,) dtype=float32>\n",
      "resolving tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_full_0:0\n",
      "hit tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_full_0:0\n",
      "restore savable variable tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_full_0:0 <tf.Variable 'tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_full_0:0' shape=(320, 256) dtype=float32>\n",
      "resolving tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_compact_0:0\n",
      "hit tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_compact_0:0\n",
      "restore savable variable tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_compact_0:0 <tf.Variable 'tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_compact_0:0' shape=(864, 256) dtype=float32>\n",
      "resolving tpfy_model_v3/deepfm/dnn/dnn_hyb/bias_0:0\n",
      "hit tpfy_model_v3/deepfm/dnn/dnn_hyb/bias_0:0\n",
      "restore savable variable tpfy_model_v3/deepfm/dnn/dnn_hyb/bias_0:0 <tf.Variable 'tpfy_model_v3/deepfm/dnn/dnn_hyb/bias_0:0' shape=(256,) dtype=float32>\n",
      "resolving tpfy_model_v3/deepfm/compress_dense/kernel:0\n",
      "hit tpfy_model_v3/deepfm/compress_dense/kernel:0\n",
      "restore savable variable tpfy_model_v3/deepfm/compress_dense/kernel:0 <tf.Variable 'tpfy_model_v3/deepfm/compress_dense/kernel:0' shape=(508, 128) dtype=float32>\n",
      "resolving tpfy_model_v3/deepfm/compress_dense/bias:0\n",
      "hit tpfy_model_v3/deepfm/compress_dense/bias:0\n",
      "restore savable variable tpfy_model_v3/deepfm/compress_dense/bias:0 <tf.Variable 'tpfy_model_v3/deepfm/compress_dense/bias:0' shape=(128,) dtype=float32>\n",
      "resolving tpfy_model_v3/deepfm/linear/linear_bias:0\n",
      "hit tpfy_model_v3/deepfm/linear/linear_bias:0\n",
      "restore savable variable tpfy_model_v3/deepfm/linear/linear_bias:0 <tf.Variable 'tpfy_model_v3/deepfm/linear/linear_bias:0' shape=(2,) dtype=float32>\n",
      "resolving tpfy_model_v3/deepfm/linear/linear_kernel:0\n",
      "hit tpfy_model_v3/deepfm/linear/linear_kernel:0\n",
      "restore savable variable tpfy_model_v3/deepfm/linear/linear_kernel:0 <tf.Variable 'tpfy_model_v3/deepfm/linear/linear_kernel:0' shape=(128, 2) dtype=float32>\n",
      "resolving tpfy_model_v3/deepfm/mtl_linear/linear_bias:0\n",
      "hit tpfy_model_v3/deepfm/mtl_linear/linear_bias:0\n",
      "restore savable variable tpfy_model_v3/deepfm/mtl_linear/linear_bias:0 <tf.Variable 'tpfy_model_v3/deepfm/mtl_linear/linear_bias:0' shape=(2,) dtype=float32>\n",
      "resolving tpfy_model_v3/deepfm/mtl_linear/linear_kernel:0\n",
      "hit tpfy_model_v3/deepfm/mtl_linear/linear_kernel:0\n",
      "restore savable variable tpfy_model_v3/deepfm/mtl_linear/linear_kernel:0 <tf.Variable 'tpfy_model_v3/deepfm/mtl_linear/linear_kernel:0' shape=(128, 2) dtype=float32>\n",
      "resolving tpfy_model_v3/sparse_layer:0\n",
      "hit tpfy_model_v3/sparse_layer:0\n",
      "restore savable variable tpfy_model_v3/sparse_layer:0 <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "resolving tpfy_model_v3/click_biases:0\n",
      "hit tpfy_model_v3/click_biases:0\n",
      "restore savable variable tpfy_model_v3/click_biases:0 <tf.Variable 'tpfy_model_v3/click_biases:0' shape=(2,) dtype=float32>\n",
      "resolving tpfy_model_v3/watch_biases:0\n",
      "hit tpfy_model_v3/watch_biases:0\n",
      "restore savable variable tpfy_model_v3/watch_biases:0 <tf.Variable 'tpfy_model_v3/watch_biases:0' shape=(2,) dtype=float32>\n",
      "resolving embedding embedding_layer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-17 06:31:18.381606: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:143] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=32, init_size=8192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading matrices from previous run\n",
      "Downloading: s3://p13n-reco-offline-models-prod/models/tpfy/tpfy-v3-neural-linucb/latest_matrices/A.npy -> temp/latest_matrices/A.npy\n",
      "Download complete. (File temp/latest_matrices/A.npy size 65,664)\n",
      "Downloading: s3://p13n-reco-offline-models-prod/models/tpfy/tpfy-v3-neural-linucb/latest_matrices/b.npy -> temp/latest_matrices/b.npy\n",
      "Download complete. (File temp/latest_matrices/b.npy size 640)\n",
      "Successfully loaded matrices from S3: s3://p13n-reco-offline-models-prod/models/tpfy/tpfy-v3-neural-linucb/latest_matrices/\n",
      "A shape: (128, 128), b shape: (128,)\n"
     ]
    }
   ],
   "source": [
    "# def run(args, session, hparams):\n",
    "validation_date = args.date\n",
    "validation_data_path = f's3://p13n-reco-offline-prod/upload_objects/test_vedansh/daily-mtl-extracted-cms3-minimum-5-contents/tmp/'\n",
    "\n",
    "variant = args.variant\n",
    "if variant and not variant.startswith(\"-\"):\n",
    "    variant = \"-\" + variant\n",
    "\n",
    "batch_size = args.batch_size or hparams.train.batch_size\n",
    "\n",
    "tf_dataset = create_dataset(args.date, variant=variant, batch_size=batch_size, path = validation_data_path)\n",
    "iterator = tf_dataset.make_one_shot_iterator()\n",
    "next_batch = iterator.get_next()\n",
    "sample_features, _, _ = session.run(next_batch)\n",
    "tpfy_model = load_and_compile_model(args=args, hparams=hparams)\n",
    "\n",
    "_ = tpfy_model(sample_features, training=False)\n",
    "session.run([\n",
    "    tfv1.global_variables_initializer(),\n",
    "    tfv1.local_variables_initializer(),\n",
    "    tfv1.tables_initializer()\n",
    "])\n",
    "\n",
    "plain_weights = load_model_weights_from_s3(\n",
    "    args.model_name,\n",
    "    use_s3=True,\n",
    "    checkpoint_name=args.checkpoint\n",
    ")\n",
    "plain_weights_modified = {k.replace('train/', ''): v for k, v in plain_weights.items()}\n",
    "restore_ops = tpfy_model.restore_plain_weights_ops(\n",
    "    plain_weights_modified,\n",
    "    clear_nn=args.clear_nn\n",
    ")\n",
    "session.run(restore_ops)\n",
    "\n",
    "# Create NEW iterator (reset to start of dataset)\n",
    "iterator = tf_dataset.make_one_shot_iterator()\n",
    "next_batch = iterator.get_next()\n",
    "\n",
    "# Get compress_output tensor (linear_input)\n",
    "graph = tf.compat.v1.get_default_graph()\n",
    "compress_output_tensor = graph.get_tensor_by_name(f'tpfy_model_v3/deepfm/{args.layer_name}:0')\n",
    "\n",
    "d = hparams.model.middle_dim\n",
    "lambda_ = args.lambda_reg\n",
    "\n",
    "base_path = f'export/neural_linUCB_offline_matrices_{args.date}'\n",
    "\n",
    "s3_base_path = model_path(\n",
    "f\"tpfy/tpfy-v3-neural-linucb\",\n",
    "TENANT\n",
    ")\n",
    "# s3_base_path = 's3://p13n-reco-offline-prod/upload_objects/test_vedansh'\n",
    "\n",
    "# Load or initialize matrices\n",
    "if args.reset_matrix:\n",
    "    print(\"Resetting matrices to default initialization\")\n",
    "    A = lambda_ * np.eye(d, dtype=np.float32)\n",
    "    b = np.zeros((d,), dtype=np.float32)\n",
    "else:\n",
    "    print(\"Loading matrices from previous run\")\n",
    "    s3_latest_path = f\"{s3_base_path}/latest_matrices/\"\n",
    "    temp_download_path = \"temp/latest_matrices\"\n",
    "    A, b = load_matrices_from_s3(s3_latest_path, temp_download_path, d)\n",
    "\n",
    "start = time.time()\n",
    "run_ = 0\n",
    "os.makedirs(base_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bf03aa2-23b2-468c-adf5-47034cd469bb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 27)\n",
      "(512, 27)\n",
      "(512, 28)\n",
      "(512, 27)\n",
      "(512, 28)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "iterator = tf_dataset.make_one_shot_iterator()\n",
    "next_batch = iterator.get_next()\n",
    "\n",
    "for i in (range(5)):\n",
    "    features, labels, _ = session.run(next_batch)\n",
    "    print(features['user_fids'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3747369d-4ef5-40e9-b976-d5e1585aa90d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 28)\n"
     ]
    }
   ],
   "source": [
    "features, labels, _ = session.run(next_batch)\n",
    "print(features['user_fids'].shape)\n",
    "activation_values = session.run(\n",
    "    compress_output_tensor,\n",
    "    feed_dict={} if not features else None  \n",
    ")\n",
    "y_batch = labels['click']\n",
    "mask = (y_batch != -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bb9874a-fb6f-4325-bdd4-94b1bd309e8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.51738203e-01, 2.92818457e-01, 4.20718938e-01, 9.93334889e-01,\n",
       "       0.00000000e+00, 3.67898524e-01, 9.47939873e-01, 3.54680866e-01,\n",
       "       8.32596421e-02, 0.00000000e+00, 0.00000000e+00, 2.53886245e-02,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.39405721e-01,\n",
       "       9.52565193e-01, 3.76139045e-01, 1.16811097e-01, 4.95102674e-01,\n",
       "       0.00000000e+00, 6.44484937e-01, 0.00000000e+00, 4.09733415e-01,\n",
       "       0.00000000e+00, 0.00000000e+00, 7.96281159e-01, 0.00000000e+00,\n",
       "       5.37964642e-01, 5.20399362e-02, 0.00000000e+00, 1.24382451e-01,\n",
       "       0.00000000e+00, 6.44160435e-02, 1.34461075e-01, 0.00000000e+00,\n",
       "       0.00000000e+00, 5.05183995e-01, 0.00000000e+00, 6.77130818e-01,\n",
       "       3.72403741e-01, 2.15819672e-01, 4.40259218e-01, 6.66216969e-01,\n",
       "       0.00000000e+00, 6.14998877e-01, 8.35623562e-01, 4.11739610e-02,\n",
       "       4.92595613e-01, 0.00000000e+00, 9.21842933e-01, 8.54505002e-01,\n",
       "       9.76083949e-02, 9.56190109e-01, 0.00000000e+00, 8.52130175e-01,\n",
       "       5.68933964e-01, 0.00000000e+00, 0.00000000e+00, 2.79638350e-01,\n",
       "       9.63049114e-01, 9.47832704e-01, 6.24985933e-01, 0.00000000e+00,\n",
       "       1.68635845e-01, 8.93846631e-01, 9.07328911e-04, 0.00000000e+00,\n",
       "       2.06676126e-03, 0.00000000e+00, 0.00000000e+00, 9.42598879e-01,\n",
       "       4.80446547e-01, 0.00000000e+00, 2.30356693e-01, 6.46456927e-02,\n",
       "       0.00000000e+00, 9.86367986e-02, 9.18629110e-01, 3.09886783e-01,\n",
       "       0.00000000e+00, 2.00477928e-01, 8.10306519e-02, 1.05331683e+00,\n",
       "       1.41779017e+00, 0.00000000e+00, 4.16136980e-01, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.61670685e-01, 8.62808228e-02, 0.00000000e+00,\n",
       "       1.14929944e-01, 0.00000000e+00, 7.96722770e-02, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.85676694e-01,\n",
       "       2.52947897e-01, 0.00000000e+00, 9.52446282e-01, 0.00000000e+00,\n",
       "       4.09416258e-01, 2.09388405e-01, 9.60619330e-01, 1.98816985e-01,\n",
       "       6.55010998e-01, 1.09561133e+00, 6.53934538e-01, 4.40397590e-01,\n",
       "       0.00000000e+00, 7.90394187e-01, 0.00000000e+00, 9.17304039e-01,\n",
       "       3.13075781e-01, 0.00000000e+00, 4.93956625e-01, 2.54508138e-01,\n",
       "       9.60233569e-01, 0.00000000e+00, 0.00000000e+00, 4.92712796e-01,\n",
       "       5.95260859e-01, 1.11214571e-01, 8.08400869e-01, 0.00000000e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_values[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fb3b59-a867-49b5-bb60-aa72f3d9cdf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c08b494c-d7c6-4637-bed5-e001f0e85bdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "H = activation_values[mask.squeeze()].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88cedd08-d409-4064-809f-36f7e6a4dcc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((512, 128), (512, 1), 424)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_values.shape, mask.shape, mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cf169ea-76fa-4e19-a565-8ba76f431b91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65ff9a97-3a3d-4ada-8ae9-80ab47f62e82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84ba38a8-6db0-4a9c-bc98-660688b6cea2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 512 but corresponding boolean dimension is 270",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9555/2244433263.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mactivation_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 512 but corresponding boolean dimension is 270"
     ]
    }
   ],
   "source": [
    "y_batch = y_batch[mask].reshape(sum(mask)[0], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ff7f7cd-8c74-4877-b2db-c79263f89a34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 128)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_values.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76e474ab-6819-4646-a6ec-f72767a87d74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270, (270, 1))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.sum(), mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7df7d8c8-ffea-405e-abc4-35c8fd6e2857",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(399, 512)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.sum(), len(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1f3e60-7d3b-420d-b864-62577ba32824",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    if (run_ % args.logging_steps == 0) and (run_):\n",
    "        save_matrices(base_path, A, b)\n",
    "\n",
    "        # Upload entire folder to S3 if enabled\n",
    "        if args.upload:\n",
    "            upload_folder(f\"{s3_base_path}/{args.date}/\", base_path, set_acl=False)\n",
    "            print(f\"Uploaded folder to S3: {s3_base_path}/{args.date}/\")\n",
    "\n",
    "        gc.collect()\n",
    "        print(f'Run {run_} completed in {time.time() - start} s!')\n",
    "        start = time.time()\n",
    "\n",
    "    try:\n",
    "        A, b = compute_A_b(A, b, next_batch, compress_output_tensor, session=session)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print(f\"\\nDataset ended at run {run_}. Ending training loop.\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError at run {run_}: {e}\")\n",
    "        break\n",
    "\n",
    "    run_ += 1\n",
    "\n",
    "# Final save\n",
    "print(\"\\nSaving final matrices...\")\n",
    "save_matrices(base_path, A, b)\n",
    "\n",
    "if args.upload:\n",
    "    upload_folder(f\"{s3_base_path}/{args.date}/\", base_path, set_acl=False)\n",
    "    upload_folder(f\"{s3_base_path}/latest_matrices/\", base_path, set_acl=False)\n",
    "    print(f\"Final upload to S3: {s3_base_path}\")\n",
    "\n",
    "    # Cleanup local folders after successful upload\n",
    "    print(\"\\nCleaning up local folders...\")\n",
    "    if os.path.exists(base_path):\n",
    "        shutil.rmtree(base_path)\n",
    "        print(f\"Deleted: {base_path}\")\n",
    "    if os.path.exists(\"temp\"):\n",
    "        shutil.rmtree(\"temp\")\n",
    "        print(f\"Deleted: temp/\")\n",
    "\n",
    "print(\"\\nTraining completed successfully!\")\n",
    "print(f\"Final A matrix shape: {A.shape}\")\n",
    "print(f\"Final b vector shape: {b.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb13636-f5bc-40ec-b943-0d8e075aff87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85f886e-69b2-4f26-9db2-9de3bcc22e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305ea5c9-6562-412b-90bc-b70488c8e722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2ad0c0-d7b7-458a-927a-7b2319d5f5cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34889ed3-6ea7-4aac-94e1-eec817cf81be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-17 12:24:49.973670: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2026-02-17 12:24:49.973699: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:dynamic_embedding.GraphKeys has already been deprecated. The Variable will not be added to collections because it does not actully own any value, but only a holder of tables, which may lead to import_meta_graph failed since non-valued object has been added to collection. If you need to use `tf.compat.v1.train.Saver` and access all Variables from collection, you could manually add it to the collection by tf.compat.v1.add_to_collections(names, var) instead.\n",
      "WARNING: env TENANT is not set, use the default value apse1-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-17 12:24:51.012858: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2026-02-17 12:24:51.012884: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2026-02-17 12:24:51.012898: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-11-72-173): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded config: tpfy/tpfy_config/mtl-in.yaml\n",
      "Batch size: 512\n",
      "WARNING:tensorflow:From /tmp/ipykernel_19101/1265645627.py:234: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n",
      "\n",
      "Start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-17 12:24:51.595269: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['ENV'] = 'prod'\n",
    "os.environ['REGION'] = 'apse1'\n",
    "os.environ['TENANT'] =\"in\"\n",
    "os.environ['RECO_S3_BUCKET'] = \"p13n-reco-offline-prod\"\n",
    "os.environ['COUNTRY_KEY']= \"in\"\n",
    "os.environ['AWS_REGION']= \"ap-southeast-1\"\n",
    "os.environ['USE_REAL_CMS3']= \"True\"\n",
    "os.environ['RECO_CREDENTIAL']= \"-----BEGINRSAPRIVATEKEY-----\\nMGICAQACEQCdHOlGnxIMWCMzjK2JAg37AgMBAAECEGOIwGTEO9vd3X9+jyiF4NECCQnoqDakDgSm2QIID9sadWN0XvMCCQLiqPkgVKSuIQIIDCAsWM+pJB8CCQG0jbIGCNX9MA==\\n-----ENDRSAPRIVATEKEY-----\"\n",
    "\n",
    "import argparse, gc\n",
    "import json\n",
    "import os, time\n",
    "import numpy as np\n",
    "import s3fs\n",
    "import pyarrow\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "tfv1 = tf.compat.v1\n",
    "tfv1.disable_v2_behavior()\n",
    "\n",
    "# Enable memory growth for GPUs to avoid memory fragmentation\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    for device in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_recommenders_addons as tfra\n",
    "from model.losses import masked_binary_entropy_loss\n",
    "from model.metrics import MaskedAUC\n",
    "\n",
    "from common.config.utils import data_path, model_path\n",
    "from common.config import TENANT\n",
    "from tpfy.tf_model.tpfy_model_v3_mtl import TpfyModelV3, TpfyMtlModelConfig\n",
    "from tpfy.etl.schema import TpfyMtlDatasetSchema\n",
    "from model.parquet_dataset import TFParquetDataset\n",
    "from tpfy.common import TpfyDataPath\n",
    "from omegaconf import OmegaConf\n",
    "from dataclasses import dataclass\n",
    "from tpfy.train_v3_mtl import make_example_mtl, TpfyTrainConfig, TpfyConfig\n",
    "from tpfy.helper import load_model_weights_from_s3\n",
    "\n",
    "def create_dataset(date, path = None):\n",
    "    if path:\n",
    "        data_path_str = path\n",
    "    else:\n",
    "        data_path_str = data_path(\n",
    "            TpfyDataPath.S3_TPFY_IMPR_V3_DAILY_MTL_EXTRACTED_EXAMPLES, TENANT\n",
    "        ) % (variant, date)\n",
    "\n",
    "    dataset = TFParquetDataset([data_path_str], TpfyMtlDatasetSchema, shuffle_files=True)\n",
    "    tf_dataset = dataset.create_tf_dataset(batch_size).map(make_example_mtl)\n",
    "    return tf_dataset\n",
    "\n",
    "def load_and_compile_model():\n",
    "    # Build model\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"BUILDING MODEL\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    model = TpfyModelV3(\n",
    "        hparams.model,\n",
    "        click_ns=args.click_ns,\n",
    "        enable_random_watch=hparams.train.enable_random_watch,\n",
    "    )\n",
    "\n",
    "    # Create optimizer (needed for compilation, even though we won't train)\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        weight_decay=0.0,  # Not needed for inference\n",
    "        learning_rate=0.001,  # Not needed for inference\n",
    "        epsilon=1e-4,\n",
    "    )\n",
    "\n",
    "    loss_dict = {\n",
    "            \"click\": masked_binary_entropy_loss(from_logits=True),\n",
    "            \"watch\": masked_binary_entropy_loss(from_logits=True),\n",
    "            \"random_watch\": masked_binary_entropy_loss(from_logits=False),\n",
    "            \"paywall_view\": masked_binary_entropy_loss(from_logits=True),\n",
    "            \"add_watchlist\": masked_binary_entropy_loss(from_logits=True),\n",
    "    }\n",
    "    metric_dict = {\n",
    "            \"click\": MaskedAUC(from_logits=True),\n",
    "            \"watch\": MaskedAUC(from_logits=True),\n",
    "            \"random_watch\": MaskedAUC(from_logits=False),\n",
    "            \"paywall_view\": MaskedAUC(from_logits=True),\n",
    "            \"add_watchlist\": MaskedAUC(from_logits=True),\n",
    "    }\n",
    "\n",
    "    optimizer = tfra.dynamic_embedding.DynamicEmbeddingOptimizer(optimizer)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss_dict, metrics=metric_dict)\n",
    "    print(\"Model compiled\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_activations_and_labels(next_batch, last_layer_tensor):\n",
    "    features, labels, metadata = session.run(next_batch)\n",
    "    \n",
    "    activation_values = session.run(last_layer_tensor)\n",
    "    \n",
    "    return activation_values, labels, metadata\n",
    "\n",
    "def compute_A(A, next_batch, last_layer_tensor):\n",
    "    activation_values, labels, metadata = get_activations_and_labels(next_batch, last_layer_tensor)\n",
    "    print(activation_values)\n",
    "    y_batch = labels['click']\n",
    "    mask = (y_batch != -1)\n",
    "\n",
    "    if not np.any(mask):\n",
    "        del activation_values, labels, metadata, mask\n",
    "        return A\n",
    "\n",
    "    H = activation_values[mask.squeeze()].copy() \n",
    "    del activation_values, mask  # Delete immediately\n",
    "    \n",
    "    H = H / (np.linalg.norm(H, axis=1, keepdims=True) + 1e-8)\n",
    "    A += H.T @ H\n",
    "\n",
    "    del H, labels, metadata \n",
    "    return A\n",
    "\n",
    "def run(args):\n",
    "    tf_dataset = create_dataset(args.date)\n",
    "    iterator = tf_dataset.make_one_shot_iterator()\n",
    "    next_batch = iterator.get_next()\n",
    "    sample_features, sample_labels, sample_metadata = session.run(next_batch)\n",
    "    tpfy_model = load_and_compile_model()\n",
    "\n",
    "    prediction = tpfy_model(sample_features, training=False)\n",
    "    session.run([\n",
    "        tfv1.global_variables_initializer(),\n",
    "        tfv1.local_variables_initializer(),\n",
    "        tfv1.tables_initializer()\n",
    "    ])\n",
    "\n",
    "    plain_weights = load_model_weights_from_s3(\n",
    "        args.model_name,\n",
    "        use_s3=True,\n",
    "        checkpoint_name=args.checkpoint\n",
    "    )\n",
    "    plain_weights_modified = {k.replace('train/', ''): v for k, v in plain_weights.items()}\n",
    "    restore_ops = tpfy_model.restore_plain_weights_ops(\n",
    "        plain_weights_modified,\n",
    "        clear_nn=args.clear_nn\n",
    "    )\n",
    "    session.run(restore_ops)\n",
    "\n",
    "    # Create NEW iterator (reset to start of dataset)\n",
    "    iterator = tf_dataset.make_one_shot_iterator()\n",
    "    next_batch = iterator.get_next()\n",
    "\n",
    "    # Get compress_output tensor (linear_input)\n",
    "    graph = tf.compat.v1.get_default_graph()\n",
    "    compress_output_tensor = graph.get_tensor_by_name(f'tpfy_model_v3/deepfm/{args.layer_name}:0')\n",
    "\n",
    "    #train feature matrix\n",
    "    # lambda_=1.0\n",
    "    d=128\n",
    "    # A = lambda_ * np.eye(d, dtype=np.float64)\n",
    "    A = np.zeros((d,d), dtype=np.float64)\n",
    "\n",
    "    start = time.time()\n",
    "    run_ = 0\n",
    "    os.makedirs(f'tpfy/neural_linUCB_offline_matrices_{args.date}_{args.checkpoint}', exist_ok=True)\n",
    "    while True:\n",
    "        if (run_ % 100 == 0) and (run_):\n",
    "            np.save(f'tpfy/neural_linUCB_offline_matrices_{args.date}_{args.checkpoint}/A_{run_}.npy', A)\n",
    "            gc.collect()\n",
    "            print(f'Run {run_} completed in {time.time() - start} s!')\n",
    "            start = time.time()\n",
    "        try:\n",
    "            A = compute_A(A, next_batch, compress_output_tensor)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"End of dataset reached\")\n",
    "            break\n",
    "        run_ += 1\n",
    "    \n",
    "class Args:\n",
    "    \"\"\"Simple class to hold training arguments (replaces argparse)\"\"\"\n",
    "    def __init__(self):\n",
    "        # Positional arguments\n",
    "        self.model_name = \"tpfy-v3-mtl-r2\"\n",
    "        self.date = \"2026-02-06\"  # Training date\n",
    "        self.click_ns = 0.08\n",
    "        self.lambda_reg = 0.08\n",
    "        self.variant = \"cms3\"\n",
    "        self.batch_size = 512\n",
    "        self.upload = False  # Set to False if you don't want to upload to S3\n",
    "        self.clear_nn = False\n",
    "        self.checkpoint = None\n",
    "        self.layer_name = 'Relu'\n",
    "        self.logging_steps = 1000\n",
    "        self.reset_matrix = False\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# parser = argparse.ArgumentParser(description=\"TPFY Exploration offline Training.\")\n",
    "# parser.add_argument(\"model_name\", type=str)\n",
    "# parser.add_argument(\"date\", type=str)\n",
    "# parser.add_argument(\"--click_ns\", type=float, default=0.08)\n",
    "# parser.add_argument(\"--variant\", type=str, default=\"cms3\")\n",
    "# parser.add_argument(\"--batch_size\", type=int, default=512)\n",
    "# parser.add_argument(\"--clear_nn\", action=\"store_true\", default=False)\n",
    "# parser.add_argument(\"--checkpoint\", default=None, type=str)\n",
    "# parser.add_argument(\"--layer_name\", default='Relu', type=str)\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# Load configuration\n",
    "config_name = f\"tpfy/tpfy_config/mtl-{TENANT}.yaml\"\n",
    "if not os.path.exists(config_name):\n",
    "    raise FileNotFoundError(f\"Config file {config_name} not found\")\n",
    "\n",
    "hparams: TpfyConfig = OmegaConf.merge(\n",
    "    OmegaConf.structured(TpfyConfig),\n",
    "    OmegaConf.load(config_name),\n",
    ")\n",
    "print(f\"\\nLoaded config: {config_name}\")\n",
    "\n",
    "# Override batch size if specified\n",
    "if args.batch_size:\n",
    "    hparams.train.batch_size = args.batch_size\n",
    "\n",
    "batch_size = hparams.train.batch_size\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "\n",
    "# Load dataset\n",
    "variant = args.variant\n",
    "if variant and not variant.startswith(\"-\"):\n",
    "    variant = \"-\" + variant\n",
    "\n",
    "session = tfv1.keras.backend.get_session()\n",
    "print(\"Start training\")\n",
    "# run(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef178fa0-6db6-457b-af4a-9d754d67257f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "BUILDING MODEL\n",
      "================================================================================\n",
      "Model compiled\n",
      "files s3://p13n-reco-offline-prod/upload_objects/test_vedansh/daily-mtl-extracted-cms3-minimum-5-contents/tmp/dummpy.parquet\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/model/parquet_dataset.py:52: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/model/parquet_dataset.py:52: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From /tmp/ipykernel_19101/2085506453.py:17: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This is a deprecated API that should only be used in TF 1 graph mode and legacy TF 2 graph mode available through `tf.compat.v1`. In all other situations -- namely, eager mode and inside `tf.function` -- you can consume dataset elements using `for elem in dataset: ...` or by explicitly creating iterator via `iterator = iter(dataset)` and fetching its elements via `values = next(iterator)`. Furthermore, this API is not available in TF 2. During the transition from TF 1 to TF 2 you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)` to create a TF 1 graph mode style iterator for a dataset created through TF 2 APIs. Note that this should be a transient state of your code base as there are in general no guarantees about the interoperability of TF 1 and TF 2 code.\n",
      "--------------\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "q Tensor(\"linucb_training/tpfy_model_v3/feature_prep/strided_slice:0\", shape=(?, 32), dtype=float32)\n",
      "k Tensor(\"linucb_training/tpfy_model_v3/feature_prep/watched_content_embedding_unpooled:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"linucb_training/tpfy_model_v3/feature_prep/GetSlotFids:1\", shape=(?, ?), dtype=float32)\n",
      "target embedding shape (?, 9, 32)\n",
      "user embedding shape (?, 27, 32)\n",
      "target: Tensor(\"linucb_training/tpfy_model_v3/feature_prep/target_feature/target_embeddings:0\", shape=(?, 9, 32), dtype=float32)\n",
      "user: Tensor(\"linucb_training/tpfy_model_v3/feature_prep/user_feature/user_embeddings:0\", shape=(?, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(?, 32), dtype=float32)\n",
      "fm_user Tensor(\"linucb_training/tpfy_model_v3/deepfm/fwfm/concat:0\", shape=(?, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"linucb_training/tpfy_model_v3/feature_prep/target_feature/target_embeddings:0\", shape=(?, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"linucb_training/tpfy_model_v3/deepfm/fwfm/Reshape:0\", shape=(?, 252), dtype=float32)\n",
      "compress dense out (?, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"linucb_training/tpfy_model_v3/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'linucb_training/tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"linucb_training/tpfy_model_v3/deepfm/sparse_nn/Squeeze:0\", shape=(?, 128), dtype=float32)\n",
      "compress_output Tensor(\"linucb_training/tpfy_model_v3/deepfm/Relu:0\", shape=(?, 128), dtype=float32)\n",
      "target_output shape (?, 2)\n",
      "\n",
      "Loading model weights: tpfy-v3-mtl-r2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-17 12:24:59.098852: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2499995000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading checkpoint from: s3://p13n-reco-offline-models-prod/models/tpfy/tpfy-v3-mtl-r2/checkpoint\n",
      "Using checkpoint: 1771324540\n",
      "Loading weights from: s3://p13n-reco-offline-models-prod/models/tpfy/tpfy-v3-mtl-r2/1771324540/plain_weights.npz\n",
      "Loaded 18 weight tensors\n",
      "Weight keys: ['train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/kernel:0', 'train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/bias:0', 'train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/kernel:0', 'train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/bias:0', 'train/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_full_0:0', 'train/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_compact_0:0', 'train/tpfy_model_v3/deepfm/dnn/dnn_hyb/bias_0:0', 'train/tpfy_model_v3/deepfm/compress_dense/kernel:0', 'train/tpfy_model_v3/deepfm/compress_dense/bias:0', 'train/tpfy_model_v3/deepfm/linear/linear_bias:0']...\n",
      "reload source keys\n",
      "linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/kernel:0\n",
      "linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/bias:0\n",
      "linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/kernel:0\n",
      "linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/bias:0\n",
      "linucb_training/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_full_0:0\n",
      "linucb_training/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_compact_0:0\n",
      "linucb_training/tpfy_model_v3/deepfm/dnn/dnn_hyb/bias_0:0\n",
      "linucb_training/tpfy_model_v3/deepfm/compress_dense/kernel:0\n",
      "linucb_training/tpfy_model_v3/deepfm/compress_dense/bias:0\n",
      "linucb_training/tpfy_model_v3/deepfm/linear/linear_bias:0\n",
      "linucb_training/tpfy_model_v3/deepfm/linear/linear_kernel:0\n",
      "linucb_training/tpfy_model_v3/deepfm/mtl_linear/linear_bias:0\n",
      "linucb_training/tpfy_model_v3/deepfm/mtl_linear/linear_kernel:0\n",
      "linucb_training/tpfy_model_v3/sparse_layer:0\n",
      "linucb_training/tpfy_model_v3/click_biases:0\n",
      "linucb_training/tpfy_model_v3/watch_biases:0\n",
      "embedding_layer/fids\n",
      "embedding_layer/embeddings\n",
      "resolve dense parameters\n",
      "resolving linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/kernel:0\n",
      "hit linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/kernel:0\n",
      "restore savable variable linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/kernel:0 <tf.Variable 'linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/kernel:0' shape=(32, 32) dtype=float32>\n",
      "resolving linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/bias:0\n",
      "hit linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/bias:0\n",
      "restore savable variable linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/bias:0 <tf.Variable 'linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/bias:0' shape=(32,) dtype=float32>\n",
      "resolving linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/kernel:0\n",
      "hit linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/kernel:0\n",
      "restore savable variable linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/kernel:0 <tf.Variable 'linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/kernel:0' shape=(32, 32) dtype=float32>\n",
      "resolving linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/bias:0\n",
      "hit linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/bias:0\n",
      "restore savable variable linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/bias:0 <tf.Variable 'linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/bias:0' shape=(32,) dtype=float32>\n",
      "resolving linucb_training/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_full_0:0\n",
      "hit linucb_training/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_full_0:0\n",
      "restore savable variable linucb_training/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_full_0:0 <tf.Variable 'linucb_training/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_full_0:0' shape=(320, 256) dtype=float32>\n",
      "resolving linucb_training/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_compact_0:0\n",
      "hit linucb_training/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_compact_0:0\n",
      "restore savable variable linucb_training/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_compact_0:0 <tf.Variable 'linucb_training/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_compact_0:0' shape=(864, 256) dtype=float32>\n",
      "resolving linucb_training/tpfy_model_v3/deepfm/dnn/dnn_hyb/bias_0:0\n",
      "hit linucb_training/tpfy_model_v3/deepfm/dnn/dnn_hyb/bias_0:0\n",
      "restore savable variable linucb_training/tpfy_model_v3/deepfm/dnn/dnn_hyb/bias_0:0 <tf.Variable 'linucb_training/tpfy_model_v3/deepfm/dnn/dnn_hyb/bias_0:0' shape=(256,) dtype=float32>\n",
      "resolving linucb_training/tpfy_model_v3/deepfm/compress_dense/kernel:0\n",
      "hit linucb_training/tpfy_model_v3/deepfm/compress_dense/kernel:0\n",
      "restore savable variable linucb_training/tpfy_model_v3/deepfm/compress_dense/kernel:0 <tf.Variable 'linucb_training/tpfy_model_v3/deepfm/compress_dense/kernel:0' shape=(508, 128) dtype=float32>\n",
      "resolving linucb_training/tpfy_model_v3/deepfm/compress_dense/bias:0\n",
      "hit linucb_training/tpfy_model_v3/deepfm/compress_dense/bias:0\n",
      "restore savable variable linucb_training/tpfy_model_v3/deepfm/compress_dense/bias:0 <tf.Variable 'linucb_training/tpfy_model_v3/deepfm/compress_dense/bias:0' shape=(128,) dtype=float32>\n",
      "resolving linucb_training/tpfy_model_v3/deepfm/linear/linear_bias:0\n",
      "hit linucb_training/tpfy_model_v3/deepfm/linear/linear_bias:0\n",
      "restore savable variable linucb_training/tpfy_model_v3/deepfm/linear/linear_bias:0 <tf.Variable 'linucb_training/tpfy_model_v3/deepfm/linear/linear_bias:0' shape=(2,) dtype=float32>\n",
      "resolving linucb_training/tpfy_model_v3/deepfm/linear/linear_kernel:0\n",
      "hit linucb_training/tpfy_model_v3/deepfm/linear/linear_kernel:0\n",
      "restore savable variable linucb_training/tpfy_model_v3/deepfm/linear/linear_kernel:0 <tf.Variable 'linucb_training/tpfy_model_v3/deepfm/linear/linear_kernel:0' shape=(128, 2) dtype=float32>\n",
      "resolving linucb_training/tpfy_model_v3/deepfm/mtl_linear/linear_bias:0\n",
      "hit linucb_training/tpfy_model_v3/deepfm/mtl_linear/linear_bias:0\n",
      "restore savable variable linucb_training/tpfy_model_v3/deepfm/mtl_linear/linear_bias:0 <tf.Variable 'linucb_training/tpfy_model_v3/deepfm/mtl_linear/linear_bias:0' shape=(2,) dtype=float32>\n",
      "resolving linucb_training/tpfy_model_v3/deepfm/mtl_linear/linear_kernel:0\n",
      "hit linucb_training/tpfy_model_v3/deepfm/mtl_linear/linear_kernel:0\n",
      "restore savable variable linucb_training/tpfy_model_v3/deepfm/mtl_linear/linear_kernel:0 <tf.Variable 'linucb_training/tpfy_model_v3/deepfm/mtl_linear/linear_kernel:0' shape=(128, 2) dtype=float32>\n",
      "resolving linucb_training/tpfy_model_v3/sparse_layer:0\n",
      "hit linucb_training/tpfy_model_v3/sparse_layer:0\n",
      "restore savable variable linucb_training/tpfy_model_v3/sparse_layer:0 <tf.Variable 'linucb_training/tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "resolving linucb_training/tpfy_model_v3/click_biases:0\n",
      "hit linucb_training/tpfy_model_v3/click_biases:0\n",
      "restore savable variable linucb_training/tpfy_model_v3/click_biases:0 <tf.Variable 'linucb_training/tpfy_model_v3/click_biases:0' shape=(2,) dtype=float32>\n",
      "resolving linucb_training/tpfy_model_v3/watch_biases:0\n",
      "hit linucb_training/tpfy_model_v3/watch_biases:0\n",
      "restore savable variable linucb_training/tpfy_model_v3/watch_biases:0 <tf.Variable 'linucb_training/tpfy_model_v3/watch_biases:0' shape=(2,) dtype=float32>\n",
      "resolving embedding embedding_layer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-17 12:25:00.047810: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:143] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=32, init_size=8192\n"
     ]
    }
   ],
   "source": [
    "validation_date = args.date\n",
    "validation_data_path = f's3://p13n-reco-offline-prod/upload_objects/test_vedansh/daily-mtl-extracted-cms3-minimum-5-contents/tmp/'\n",
    "\n",
    "variant = args.variant\n",
    "if variant and not variant.startswith(\"-\"):\n",
    "    variant = \"-\" + variant\n",
    "\n",
    "batch_size = args.batch_size or hparams.train.batch_size\n",
    "\n",
    "# Load and compile model FIRST\n",
    "tpfy_model = load_and_compile_model()\n",
    "\n",
    "tf_dataset = create_dataset(args.date, path = validation_data_path)\n",
    "\n",
    "# Build the graph - similar to trainer.py lines 366-375\n",
    "with tfv1.name_scope(\"linucb_training\"):\n",
    "    iterator = tf_dataset.make_one_shot_iterator()\n",
    "    next_batch = iterator.get_next()\n",
    "\n",
    "    # Unpack - this creates tensor placeholders\n",
    "    if len(next_batch) == 3:\n",
    "        x, y_true, metadata = next_batch\n",
    "    else:\n",
    "        x, y_true = next_batch\n",
    "        metadata = None\n",
    "\n",
    "    # Call model with TENSOR x (not numpy data) - this builds the forward pass in the graph\n",
    "    y_pred = tpfy_model(x, training=False)\n",
    "\n",
    "# Initialize all variables\n",
    "session.run([\n",
    "    tfv1.global_variables_initializer(),\n",
    "    tfv1.local_variables_initializer(),\n",
    "    tfv1.tables_initializer()\n",
    "])\n",
    "\n",
    "# Load weights\n",
    "print(f\"\\nLoading model weights: {args.model_name}\")\n",
    "plain_weights = load_model_weights_from_s3(\n",
    "    args.model_name,\n",
    "    use_s3=True,\n",
    "    checkpoint_name=args.checkpoint\n",
    ")\n",
    "plain_weights_modified = {k.replace('train/', 'linucb_training/'): v for k, v in plain_weights.items()}\n",
    "restore_ops = tpfy_model.restore_plain_weights_ops(\n",
    "    plain_weights_modified,\n",
    "    clear_nn=args.clear_nn\n",
    ")\n",
    "session.run(restore_ops)\n",
    "\n",
    "# NOW get the activation tensor from the graph (AFTER model is called in the graph)\n",
    "graph = tfv1.get_default_graph()\n",
    "compress_output_tensor = graph.get_tensor_by_name(\n",
    "    f'linucb_training/tpfy_model_v3/deepfm/{args.layer_name}:0'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbbf6396-0774-4f22-91b2-af37f4bcd0ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y_true, metadata = next_batch\n",
    "\n",
    "features_val, labels_val, metadata_val, pred_values, activation_val = session.run(\n",
    "    [x, y_true, metadata, y_pred, compress_output_tensor]\n",
    ")\n",
    "\n",
    "labels_val['click'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce29a103-a6af-4de7-a4fe-4a5f44d92283",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  18010442820927642,   26282751487100903,   30473928018519015,\n",
       "         38752548480567183,   52558572850079295,   60339255362303347,\n",
       "         71729434137426642,   75490802718027078,   86474907716623441,\n",
       "         94110082929227526,  105771320358320486,  112421516648451837,\n",
       "        117997908582961592, 1109496150758225693,  132396849400231283,\n",
       "       1800972323576723103,  135107988821114881, 1055810764324444956,\n",
       "       1051910021140670741, 1098878309078401029, 1124351450060244810,\n",
       "       1134497528617814517, 1873497444986126344, 1882504644240867331,\n",
       "        989639971461820696, 1817877897957910065,                   0,\n",
       "                         0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_val['user_fids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "653afdca-8aa7-4682-bf98-59ab6eaae44e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.802481  , 0.        , 0.        , 0.47637665],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_val[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89d56a45-98d5-4b7a-83fa-25453bc4d604",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.12409385,  0.13100815], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_output = activation_val @ plain_weights_modified['linucb_training/tpfy_model_v3/deepfm/linear/linear_kernel:0'] + plain_weights_modified['linucb_training/tpfy_model_v3/deepfm/mtl_linear/linear_bias:0']\n",
    "target_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5aafb230-940b-4e47-ae00-ce8001b497eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.21691632], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "click_biases = plain_weights_modified['linucb_training/tpfy_model_v3/click_biases:0'][0]\n",
    "target_output[0, 0:1] + click_biases - pred_values['click'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afe7c1c0-15f2-4833-ae6d-d7aba0e716ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.9888763], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "click_biases = plain_weights_modified['linucb_training/tpfy_model_v3/click_biases:0'][1]\n",
    "target_output[0, 0:1] + click_biases - pred_values['click'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9632fc5d-1ae2-4bc7-84b7-0083c9686c21",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('default_matrices/latest_matrices/A.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "054d87dc-0285-4f0f-8dcd-63586df1def6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import boto3\n",
    "\n",
    "def save_matrices_to_s3(s3_path, A, b):\n",
    "    \"\"\"Save matrices directly to S3 without local storage.\"\"\"\n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    # Parse S3 path\n",
    "    if s3_path.startswith('s3://'):\n",
    "        s3_path = s3_path[5:]\n",
    "    bucket_name = s3_path.split('/')[0]\n",
    "    prefix = '/'.join(s3_path.split('/')[1:])\n",
    "    \n",
    "    # Save A matrix\n",
    "    A_buffer = io.BytesIO()\n",
    "    np.save(A_buffer, A)\n",
    "    A_buffer.seek(0)\n",
    "    s3_client.upload_fileobj(A_buffer, bucket_name, f\"{prefix}/A.npy\")\n",
    "    print(f\"Uploaded A matrix to s3://{bucket_name}/{prefix}/A.npy\")\n",
    "    \n",
    "    # Save b vector\n",
    "    b_buffer = io.BytesIO()\n",
    "    np.save(b_buffer, b)\n",
    "    b_buffer.seek(0)\n",
    "    s3_client.upload_fileobj(b_buffer, bucket_name, f\"{prefix}/b.npy\")\n",
    "    print(f\"Uploaded b vector to s3://{bucket_name}/{prefix}/b.npy\")\n",
    "    \n",
    "    A_buffer.close()\n",
    "    b_buffer.close()\n",
    "\n",
    "def load_matrices_from_s3_direct(s3_path):\n",
    "    \"\"\"Load matrices directly from S3 without local download.\"\"\"\n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    # Parse S3 path\n",
    "    if s3_path.startswith('s3://'):\n",
    "        s3_path = s3_path[5:]\n",
    "    bucket_name = s3_path.split('/')[0]\n",
    "    prefix = '/'.join(s3_path.split('/')[1:])\n",
    "    \n",
    "    # try:\n",
    "        # Load A matrix\n",
    "    A_buffer = io.BytesIO()\n",
    "    s3_client.download_fileobj(bucket_name, f\"{prefix}/A.npy\", A_buffer)\n",
    "    A_buffer.seek(0)\n",
    "    A = np.load(A_buffer)\n",
    "    A_buffer.close()\n",
    "\n",
    "    # Load b vector\n",
    "    b_buffer = io.BytesIO()\n",
    "    s3_client.download_fileobj(bucket_name, f\"{prefix}/b.npy\", b_buffer)\n",
    "    b_buffer.seek(0)\n",
    "    b = np.load(b_buffer)\n",
    "    b_buffer.close()\n",
    "\n",
    "    print(f\"Loaded matrices from s3://{bucket_name}/{prefix}/\")\n",
    "    return A, b\n",
    "    # except Exception as e:\n",
    "    #     print(f\"Could not load matrices from S3: {e}\")\n",
    "    #     print(\"Initializing new matrices...\")\n",
    "    #     A = np.eye(d, dtype=np.float32)\n",
    "    #     b = np.zeros((d,), dtype=np.float32)\n",
    "    #     return A, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f8f365fd-7fb1-4ebe-9224-f5ef54590a41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "A = np.load('default_matrices/latest_matrices/A.npy')\n",
    "b = np.load('default_matrices/latest_matrices/b.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "53ff0463-475c-4e45-9677-d5231d97ab81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_base_path = 's3://p13n-reco-offline-prod/upload_objects/test_vedansh/latest_matrices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "16289b15-9566-4a47-816c-51f2be3fea25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded A matrix to s3://p13n-reco-offline-prod/upload_objects/test_vedansh/2025-02-16//A.npy\n",
      "Uploaded b vector to s3://p13n-reco-offline-prod/upload_objects/test_vedansh/2025-02-16//b.npy\n"
     ]
    }
   ],
   "source": [
    "save_matrices_to_s3(s3_base_path, A, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d3aa0181-d7fe-4e3c-918f-90f2bc39dff5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded matrices from s3://p13n-reco-offline-prod/upload_objects/test_vedansh/latest_matrices/\n"
     ]
    }
   ],
   "source": [
    "A_, b_ = load_matrices_from_s3_direct(s3_base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "23485928-7adb-49f6-93b9-12c1b7148033",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_base_path = model_path(\n",
    "f\"tpfy/tpfy-v3-neural-linucb\",\n",
    "TENANT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "62752678-542b-4faf-a20f-31f08e54d494",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://p13n-reco-offline-models-prod/models/tpfy/tpfy-v3-neural-linucb'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_base_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "24673368-c9e7-47ea-b110-c932e5908257",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://p13n-reco-offline-models-prod/models/tpfy/neural-linucb-matrices'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path(\"tpfy/neural-linucb-matrices\", TENANT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592e51f1-00de-420f-9235-6bf3e7a304f4",
   "metadata": {},
   "source": [
    "<h3>Debugging end of sequence error and handling it in code</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cb6184e-056f-4abe-80af-e25f574061b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-17 11:27:13.469663: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2026-02-17 11:27:13.469692: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:dynamic_embedding.GraphKeys has already been deprecated. The Variable will not be added to collections because it does not actully own any value, but only a holder of tables, which may lead to import_meta_graph failed since non-valued object has been added to collection. If you need to use `tf.compat.v1.train.Saver` and access all Variables from collection, you could manually add it to the collection by tf.compat.v1.add_to_collections(names, var) instead.\n",
      "WARNING: env TENANT is not set, use the default value apse1-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-17 11:27:14.678346: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2026-02-17 11:27:14.678374: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2026-02-17 11:27:14.678389: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-11-72-173): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "# python3.7 -m 6_1-disjoint_NeuralLinUCB_trainer.py tpfy-v3-mtl-r2 2026-02-09 --checkpoint 1770723470\n",
    "import os\n",
    "os.environ['ENV'] = 'prod'\n",
    "os.environ['REGION'] = 'apse1'\n",
    "os.environ['TENANT'] =\"in\"\n",
    "os.environ['RECO_S3_BUCKET'] = \"p13n-reco-offline-prod\"\n",
    "os.environ['COUNTRY_KEY']= \"in\"\n",
    "os.environ['AWS_REGION']= \"ap-southeast-1\"\n",
    "os.environ['USE_REAL_CMS3']= \"True\"\n",
    "os.environ['RECO_CREDENTIAL']= \"-----BEGINRSAPRIVATEKEY-----\\nMGICAQACEQCdHOlGnxIMWCMzjK2JAg37AgMBAAECEGOIwGTEO9vd3X9+jyiF4NECCQnoqDakDgSm2QIID9sadWN0XvMCCQLiqPkgVKSuIQIIDCAsWM+pJB8CCQG0jbIGCNX9MA==\\n-----ENDRSAPRIVATEKEY-----\"\n",
    "\n",
    "# python3.7 -m 6_1-disjoint_NeuralLinUCB_trainer.py tpfy-v3-mtl-r2 2026-02-09 --checkpoint 1770723470\n",
    "import argparse, gc\n",
    "import os, time, shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tfv1 = tf.compat.v1\n",
    "tfv1.disable_v2_behavior()\n",
    "\n",
    "# Enable memory growth for GPUs to avoid memory fragmentation\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    for device in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_recommenders_addons as tfra\n",
    "from model.losses import masked_binary_entropy_loss\n",
    "from model.metrics import MaskedAUC\n",
    "\n",
    "from common.config.utils import data_path, model_path\n",
    "from common.config import TENANT\n",
    "from tpfy.tf_model.tpfy_model_v3_mtl import TpfyModelV3\n",
    "from omegaconf import OmegaConf\n",
    "from tpfy.common import TpfyDataPath\n",
    "from tpfy.train_v3_mtl import TpfyConfig\n",
    "from tpfy.helper import load_model_weights_from_s3, create_dataset, save_matrices_to_s3, load_matrices_from_s3_direct\n",
    "\n",
    "S3_TPFY_NEURAL_LINUCB_MODEL_EXPORT = model_path(TpfyDataPath.S3_TPFY_NEURAL_LINUCB_MATRICES, TENANT)\n",
    "\n",
    "def load_and_compile_model(args, hparams):\n",
    "    \"\"\"\n",
    "    Docstring for load_and_compile_model\n",
    "    \n",
    "    :param args: hyperparameters and arguments for model loading and compilation\n",
    "    :param hparams: hyperparameters and arguments for model loading and compilation\n",
    "    \"\"\"\n",
    "    # Build model\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"BUILDING MODEL\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    model = TpfyModelV3(\n",
    "        hparams.model,\n",
    "        click_ns=args.click_ns,\n",
    "        enable_random_watch=hparams.train.enable_random_watch,\n",
    "    )\n",
    "\n",
    "    # Create optimizer (needed for compilation, even though we won't train)\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        weight_decay=0.0,  # Not needed for inference\n",
    "        learning_rate=0.001,  # Not needed for inference\n",
    "        epsilon=1e-4,\n",
    "    )\n",
    "\n",
    "    loss_dict = {\n",
    "            \"click\": masked_binary_entropy_loss(from_logits=True),\n",
    "            \"watch\": masked_binary_entropy_loss(from_logits=True),\n",
    "            \"random_watch\": masked_binary_entropy_loss(from_logits=False),\n",
    "            \"paywall_view\": masked_binary_entropy_loss(from_logits=True),\n",
    "            \"add_watchlist\": masked_binary_entropy_loss(from_logits=True),\n",
    "    }\n",
    "    metric_dict = {\n",
    "            \"click\": MaskedAUC(from_logits=True),\n",
    "            \"watch\": MaskedAUC(from_logits=True),\n",
    "            \"random_watch\": MaskedAUC(from_logits=False),\n",
    "            \"paywall_view\": MaskedAUC(from_logits=True),\n",
    "            \"add_watchlist\": MaskedAUC(from_logits=True),\n",
    "    }\n",
    "\n",
    "    optimizer = tfra.dynamic_embedding.DynamicEmbeddingOptimizer(optimizer)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss_dict, metrics=metric_dict)\n",
    "    print(\"Model compiled\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def compute_A_b(A, b, next_batch, last_layer_tensor, session):\n",
    "    \"\"\"\n",
    "    Docstring for compute_A_b\n",
    "    \n",
    "    :param A: Covariance matrix A to be updated : (B, d, d)\n",
    "    :param b: Response vector b to be updated : (B, d)\n",
    "    :param next_batch: iterator batch containing features, labels, and metadata tensors\n",
    "    :param last_layer_tensor: Activation tensor from the last layer of the neural network to be used as context features for LinUCB\n",
    "    :param session: TensorFlow session for running the computation\n",
    "    \"\"\"\n",
    "    features, labels, metadata = next_batch\n",
    "    \n",
    "    features, labels, _, activation_values = session.run(\n",
    "        [features, labels, metadata, last_layer_tensor]\n",
    "    )\n",
    "    y_batch = labels['click']\n",
    "    mask = (y_batch != -1)\n",
    "\n",
    "    if not np.any(mask):\n",
    "        del activation_values, labels, mask\n",
    "        return A, b\n",
    "\n",
    "    H = activation_values[mask.squeeze()].copy() \n",
    "    y_batch = y_batch[mask].reshape(sum(mask)[0], )\n",
    "    \n",
    "    del activation_values, mask  # Delete immediately\n",
    "    \n",
    "    H = H / (np.linalg.norm(H, axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "    # A is computed using the outer product of the features (H) and b is computed using the product of features \n",
    "    # and rewards (y_batch)\n",
    "    A += H.T @ H\n",
    "    b += H.T @ y_batch\n",
    "\n",
    "    del H, labels, y_batch, features, metadata\n",
    "    return A, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0579c08e-0fb9-4a16-9d69-4a4560ed1bef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded config: tpfy/tpfy_config/mtl-in.yaml\n",
      "WARNING:tensorflow:From /tmp/ipykernel_7536/3068496152.py:30: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n",
      "\n",
      "Start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-17 11:27:16.672671: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    \"\"\"Simple class to hold training arguments (replaces argparse)\"\"\"\n",
    "    def __init__(self):\n",
    "        # Positional arguments\n",
    "        self.model_name = \"tpfy-v3-mtl-r2\"\n",
    "        self.date = \"2026-02-06\"  # Training date\n",
    "        self.click_ns = 0.08\n",
    "        self.lambda_reg = 0.08\n",
    "        self.variant = \"cms3\"\n",
    "        self.batch_size = 512\n",
    "        self.upload = False  # Set to False if you don't want to upload to S3\n",
    "        self.clear_nn = False\n",
    "        self.checkpoint = None\n",
    "        self.layer_name = 'Relu'\n",
    "        self.logging_steps = 1000\n",
    "        self.reset_matrix = False\n",
    "\n",
    "args = Args()\n",
    "\n",
    "config_name = f\"tpfy/tpfy_config/mtl-{TENANT}.yaml\"\n",
    "if not os.path.exists(config_name):\n",
    "    raise FileNotFoundError(f\"Config file {config_name} not found\")\n",
    "\n",
    "hparams: TpfyConfig = OmegaConf.merge(\n",
    "    OmegaConf.structured(TpfyConfig),\n",
    "    OmegaConf.load(config_name),\n",
    ")\n",
    "print(f\"\\nLoaded config: {config_name}\")\n",
    "\n",
    "session = tfv1.keras.backend.get_session()\n",
    "print(\"Start training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4162ddf1-4a07-41ec-9606-7bdcd250b87d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files s3://p13n-reco-offline-prod/upload_objects/test_vedansh/daily-mtl-extracted-cms3-minimum-5-contents/tmp/dummpy.parquet\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/model/parquet_dataset.py:52: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/model/parquet_dataset.py:52: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "\n",
      "================================================================================\n",
      "BUILDING MODEL\n",
      "================================================================================\n",
      "Model compiled\n",
      "WARNING:tensorflow:From /tmp/ipykernel_7536/1608485354.py:13: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This is a deprecated API that should only be used in TF 1 graph mode and legacy TF 2 graph mode available through `tf.compat.v1`. In all other situations -- namely, eager mode and inside `tf.function` -- you can consume dataset elements using `for elem in dataset: ...` or by explicitly creating iterator via `iterator = iter(dataset)` and fetching its elements via `values = next(iterator)`. Furthermore, this API is not available in TF 2. During the transition from TF 1 to TF 2 you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)` to create a TF 1 graph mode style iterator for a dataset created through TF 2 APIs. Note that this should be a transient state of your code base as there are in general no guarantees about the interoperability of TF 1 and TF 2 code.\n",
      "--------------\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "q Tensor(\"linucb_training/tpfy_model_v3/feature_prep/strided_slice:0\", shape=(?, 32), dtype=float32)\n",
      "k Tensor(\"linucb_training/tpfy_model_v3/feature_prep/watched_content_embedding_unpooled:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"linucb_training/tpfy_model_v3/feature_prep/GetSlotFids:1\", shape=(?, ?), dtype=float32)\n",
      "target embedding shape (?, 9, 32)\n",
      "user embedding shape (?, 27, 32)\n",
      "target: Tensor(\"linucb_training/tpfy_model_v3/feature_prep/target_feature/target_embeddings:0\", shape=(?, 9, 32), dtype=float32)\n",
      "user: Tensor(\"linucb_training/tpfy_model_v3/feature_prep/user_feature/user_embeddings:0\", shape=(?, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(?, 32), dtype=float32)\n",
      "fm_user Tensor(\"linucb_training/tpfy_model_v3/deepfm/fwfm/concat:0\", shape=(?, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"linucb_training/tpfy_model_v3/feature_prep/target_feature/target_embeddings:0\", shape=(?, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"linucb_training/tpfy_model_v3/deepfm/fwfm/Reshape:0\", shape=(?, 252), dtype=float32)\n",
      "compress dense out (?, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"linucb_training/tpfy_model_v3/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'linucb_training/tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"linucb_training/tpfy_model_v3/deepfm/sparse_nn/Squeeze:0\", shape=(?, 128), dtype=float32)\n",
      "compress_output Tensor(\"linucb_training/tpfy_model_v3/deepfm/Relu:0\", shape=(?, 128), dtype=float32)\n",
      "target_output shape (?, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-17 11:27:21.590717: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2499995000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading checkpoint from: s3://p13n-reco-offline-models-prod/models/tpfy/tpfy-v3-mtl-r2/checkpoint\n",
      "Using checkpoint: 1771324540\n",
      "Loading weights from: s3://p13n-reco-offline-models-prod/models/tpfy/tpfy-v3-mtl-r2/1771324540/plain_weights.npz\n",
      "Loaded 18 weight tensors\n",
      "Weight keys: ['train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/kernel:0', 'train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/bias:0', 'train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/kernel:0', 'train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/bias:0', 'train/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_full_0:0', 'train/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_compact_0:0', 'train/tpfy_model_v3/deepfm/dnn/dnn_hyb/bias_0:0', 'train/tpfy_model_v3/deepfm/compress_dense/kernel:0', 'train/tpfy_model_v3/deepfm/compress_dense/bias:0', 'train/tpfy_model_v3/deepfm/linear/linear_bias:0']...\n",
      "reload source keys\n",
      "linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/kernel:0\n",
      "linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/bias:0\n",
      "linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/kernel:0\n",
      "linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/bias:0\n",
      "linucb_training/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_full_0:0\n",
      "linucb_training/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_compact_0:0\n",
      "linucb_training/tpfy_model_v3/deepfm/dnn/dnn_hyb/bias_0:0\n",
      "linucb_training/tpfy_model_v3/deepfm/compress_dense/kernel:0\n",
      "linucb_training/tpfy_model_v3/deepfm/compress_dense/bias:0\n",
      "linucb_training/tpfy_model_v3/deepfm/linear/linear_bias:0\n",
      "linucb_training/tpfy_model_v3/deepfm/linear/linear_kernel:0\n",
      "linucb_training/tpfy_model_v3/deepfm/mtl_linear/linear_bias:0\n",
      "linucb_training/tpfy_model_v3/deepfm/mtl_linear/linear_kernel:0\n",
      "linucb_training/tpfy_model_v3/sparse_layer:0\n",
      "linucb_training/tpfy_model_v3/click_biases:0\n",
      "linucb_training/tpfy_model_v3/watch_biases:0\n",
      "embedding_layer/fids\n",
      "embedding_layer/embeddings\n",
      "resolve dense parameters\n",
      "resolving linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/kernel:0\n",
      "hit linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/kernel:0\n",
      "restore savable variable linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/kernel:0 <tf.Variable 'linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/kernel:0' shape=(32, 32) dtype=float32>\n",
      "resolving linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/bias:0\n",
      "hit linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/bias:0\n",
      "restore savable variable linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/bias:0 <tf.Variable 'linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/bias:0' shape=(32,) dtype=float32>\n",
      "resolving linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/kernel:0\n",
      "hit linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/kernel:0\n",
      "restore savable variable linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/kernel:0 <tf.Variable 'linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/kernel:0' shape=(32, 32) dtype=float32>\n",
      "resolving linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/bias:0\n",
      "hit linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/bias:0\n",
      "restore savable variable linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/bias:0 <tf.Variable 'linucb_training/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/bias:0' shape=(32,) dtype=float32>\n",
      "resolving linucb_training/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_full_0:0\n",
      "hit linucb_training/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_full_0:0\n",
      "restore savable variable linucb_training/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_full_0:0 <tf.Variable 'linucb_training/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_full_0:0' shape=(320, 256) dtype=float32>\n",
      "resolving linucb_training/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_compact_0:0\n",
      "hit linucb_training/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_compact_0:0\n",
      "restore savable variable linucb_training/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_compact_0:0 <tf.Variable 'linucb_training/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_compact_0:0' shape=(864, 256) dtype=float32>\n",
      "resolving linucb_training/tpfy_model_v3/deepfm/dnn/dnn_hyb/bias_0:0\n",
      "hit linucb_training/tpfy_model_v3/deepfm/dnn/dnn_hyb/bias_0:0\n",
      "restore savable variable linucb_training/tpfy_model_v3/deepfm/dnn/dnn_hyb/bias_0:0 <tf.Variable 'linucb_training/tpfy_model_v3/deepfm/dnn/dnn_hyb/bias_0:0' shape=(256,) dtype=float32>\n",
      "resolving linucb_training/tpfy_model_v3/deepfm/compress_dense/kernel:0\n",
      "hit linucb_training/tpfy_model_v3/deepfm/compress_dense/kernel:0\n",
      "restore savable variable linucb_training/tpfy_model_v3/deepfm/compress_dense/kernel:0 <tf.Variable 'linucb_training/tpfy_model_v3/deepfm/compress_dense/kernel:0' shape=(508, 128) dtype=float32>\n",
      "resolving linucb_training/tpfy_model_v3/deepfm/compress_dense/bias:0\n",
      "hit linucb_training/tpfy_model_v3/deepfm/compress_dense/bias:0\n",
      "restore savable variable linucb_training/tpfy_model_v3/deepfm/compress_dense/bias:0 <tf.Variable 'linucb_training/tpfy_model_v3/deepfm/compress_dense/bias:0' shape=(128,) dtype=float32>\n",
      "resolving linucb_training/tpfy_model_v3/deepfm/linear/linear_bias:0\n",
      "hit linucb_training/tpfy_model_v3/deepfm/linear/linear_bias:0\n",
      "restore savable variable linucb_training/tpfy_model_v3/deepfm/linear/linear_bias:0 <tf.Variable 'linucb_training/tpfy_model_v3/deepfm/linear/linear_bias:0' shape=(2,) dtype=float32>\n",
      "resolving linucb_training/tpfy_model_v3/deepfm/linear/linear_kernel:0\n",
      "hit linucb_training/tpfy_model_v3/deepfm/linear/linear_kernel:0\n",
      "restore savable variable linucb_training/tpfy_model_v3/deepfm/linear/linear_kernel:0 <tf.Variable 'linucb_training/tpfy_model_v3/deepfm/linear/linear_kernel:0' shape=(128, 2) dtype=float32>\n",
      "resolving linucb_training/tpfy_model_v3/deepfm/mtl_linear/linear_bias:0\n",
      "hit linucb_training/tpfy_model_v3/deepfm/mtl_linear/linear_bias:0\n",
      "restore savable variable linucb_training/tpfy_model_v3/deepfm/mtl_linear/linear_bias:0 <tf.Variable 'linucb_training/tpfy_model_v3/deepfm/mtl_linear/linear_bias:0' shape=(2,) dtype=float32>\n",
      "resolving linucb_training/tpfy_model_v3/deepfm/mtl_linear/linear_kernel:0\n",
      "hit linucb_training/tpfy_model_v3/deepfm/mtl_linear/linear_kernel:0\n",
      "restore savable variable linucb_training/tpfy_model_v3/deepfm/mtl_linear/linear_kernel:0 <tf.Variable 'linucb_training/tpfy_model_v3/deepfm/mtl_linear/linear_kernel:0' shape=(128, 2) dtype=float32>\n",
      "resolving linucb_training/tpfy_model_v3/sparse_layer:0\n",
      "hit linucb_training/tpfy_model_v3/sparse_layer:0\n",
      "restore savable variable linucb_training/tpfy_model_v3/sparse_layer:0 <tf.Variable 'linucb_training/tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "resolving linucb_training/tpfy_model_v3/click_biases:0\n",
      "hit linucb_training/tpfy_model_v3/click_biases:0\n",
      "restore savable variable linucb_training/tpfy_model_v3/click_biases:0 <tf.Variable 'linucb_training/tpfy_model_v3/click_biases:0' shape=(2,) dtype=float32>\n",
      "resolving linucb_training/tpfy_model_v3/watch_biases:0\n",
      "hit linucb_training/tpfy_model_v3/watch_biases:0\n",
      "restore savable variable linucb_training/tpfy_model_v3/watch_biases:0 <tf.Variable 'linucb_training/tpfy_model_v3/watch_biases:0' shape=(2,) dtype=float32>\n",
      "resolving embedding embedding_layer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-17 11:27:22.651545: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:143] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=32, init_size=8192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading matrices from previous run\n",
      "Loaded matrices from s3://p13n-reco-offline-models-prod/models/tpfy/tpfy-v3-neural-linucb/latest_matrices/\n"
     ]
    }
   ],
   "source": [
    "# def run(args, session, hparams):\n",
    "variant = args.variant\n",
    "if variant and not variant.startswith(\"-\"):\n",
    "    variant = \"-\" + variant\n",
    "\n",
    "batch_size = args.batch_size or hparams.train.batch_size\n",
    "\n",
    "tf_dataset = create_dataset(args.date, variant=variant, batch_size=batch_size, \n",
    "                            path = f's3://p13n-reco-offline-prod/upload_objects/test_vedansh/daily-mtl-extracted-cms3-minimum-5-contents/tmp/')\n",
    "tpfy_model = load_and_compile_model(args=args, hparams=hparams)\n",
    "\n",
    "with tfv1.name_scope(\"linucb_training\"):\n",
    "    iterator = tf_dataset.make_one_shot_iterator()\n",
    "    next_batch = iterator.get_next()\n",
    "\n",
    "    # Unpack - this creates tensor placeholders\n",
    "    if len(next_batch) == 3:\n",
    "        x, y_true, metadata = next_batch\n",
    "    else:\n",
    "        x, y_true = next_batch\n",
    "        metadata = None\n",
    "\n",
    "    y_pred = tpfy_model(x, training=False)\n",
    "\n",
    "session.run([\n",
    "    tfv1.global_variables_initializer(),\n",
    "    tfv1.local_variables_initializer(),\n",
    "    tfv1.tables_initializer()\n",
    "])\n",
    "\n",
    "# last trained DeepFM model checkpoint is loaded here to extract last layer representations as features for LinUCB.\n",
    "plain_weights = load_model_weights_from_s3(\n",
    "    args.model_name,\n",
    "    use_s3=True,\n",
    "    checkpoint_name=args.checkpoint\n",
    ")\n",
    "\n",
    "# The keys in plain_weights have the format 'train/layer_name/weight_name'. \n",
    "# We need to modify them to match the current model's scope, which is 'linucb_training/tpfy_model_v3/deepfm/layer_name/weight_name'\n",
    "plain_weights_modified = {k.replace('train/', 'linucb_training/'): v for k, v in plain_weights.items()}\n",
    "restore_ops = tpfy_model.restore_plain_weights_ops(\n",
    "    plain_weights_modified,\n",
    "    clear_nn=args.clear_nn\n",
    ")\n",
    "session.run(restore_ops)\n",
    "\n",
    "# Create NEW iterator (reset to start of dataset)\n",
    "iterator = tf_dataset.make_one_shot_iterator()\n",
    "next_batch = iterator.get_next()\n",
    "\n",
    "# Getting the tensor for the specified layer's activations to be used as features for LinUCB\n",
    "# Here, extracting the output Relu(SparseFeaturesOutput + DenseFeaturesOutput). This is given to Linear layer(d, 2) to predict click and watch logits.\n",
    "graph = tfv1.get_default_graph()\n",
    "compress_output_tensor = graph.get_tensor_by_name(\n",
    "    f'linucb_training/tpfy_model_v3/deepfm/{args.layer_name}:0'\n",
    ")\n",
    "d = hparams.model.middle_dim\n",
    "lambda_ = args.lambda_reg\n",
    "\n",
    "s3_base_path = S3_TPFY_NEURAL_LINUCB_MODEL_EXPORT\n",
    "# s3_base_path = 's3://p13n-reco-offline-prod/upload_objects/test_vedansh'\n",
    "\n",
    "# Load or initialize matrices\n",
    "if args.reset_matrix:\n",
    "    print(\"Resetting matrices to default initialization\")\n",
    "    A = lambda_ * np.eye(d, dtype=np.float32)\n",
    "    b = np.zeros((d,), dtype=np.float32)\n",
    "else:\n",
    "    print(\"Loading matrices from previous run\")\n",
    "    s3_latest_path = f\"{s3_base_path}/latest_matrices\"\n",
    "    A, b = load_matrices_from_s3_direct(s3_latest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "707c6a2b-e2ac-43ac-8e76-19b88e3621c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.765625"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tmp = pd.read_parquet('dummpy.parquet')\n",
    "tmp.shape[0]/512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c1da3c7-cce9-4656-b149-c52392a4435c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "last_layer_tensor = compress_output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52d5583a-6131-4e56-87a8-1ad049768fbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset ended at run 10. Ending training loop.\n"
     ]
    }
   ],
   "source": [
    "run_ = 10\n",
    "try:\n",
    "    features, labels, metadata = next_batch\n",
    "\n",
    "    features, labels, _, activation_values = session.run(\n",
    "        [features, labels, metadata, last_layer_tensor]\n",
    "    )\n",
    "    y_batch = labels['click']\n",
    "    mask = (y_batch != -1)\n",
    "\n",
    "    H = activation_values[mask.squeeze()].copy() \n",
    "    y_batch = y_batch[mask].reshape(sum(mask)[0], )\n",
    "\n",
    "    # del activation_values, mask  # Delete immediately\n",
    "\n",
    "    H = H / (np.linalg.norm(H, axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "    # A is computed using the outer product of the features (H) and b is computed using the product of features \n",
    "    # and rewards (y_batch)\n",
    "    A += H.T @ H\n",
    "    b += H.T @ y_batch\n",
    "    print(y_batch.shape, mask.sum(), activation_values.shape, H.shape)\n",
    "except tf.errors.OutOfRangeError:\n",
    "    print(f\"\\nDataset ended at run {run_}. Ending training loop.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6aa50328-39a8-42e5-8ee7-86a37b9bd4f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((392, 1), 352)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch.shape, mask.sum(), activation_values.shape, H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f6eff1b4-b5a9-4847-9ad2-eacb8a68b0c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((392, 128), (352, 128))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0467c8e0-6f62-4599-92ba-d05f384a0691",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "x = pd.read_pickle('progressive_matrices/reseted/validation_dumping_dict_2026-02-05/validation_stats_run_100.pkl')\n",
    "# x = pd.read_pickle('corrected_validation/validation_dumping_dict_2026-02-11/validation_stats_run_0.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f49b9b7a-e126-499d-8fa8-5bce553d1fca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51170"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(x['deepFMpredictions']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "84a5dd96-5d51-4331-b1ed-a15fa6c63509",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0039353613"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['variances'][512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db5434b5-01fb-4a1b-8bae-b801746d74a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_dict = pd.read_pickle(f'corrected_validation//validation_dumping_dict_2026-02-09/validation_stats_run_0.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b71627e-f20a-40ff-858f-10e8fd47d0d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dw_p_ids', 'timestamps', 'content_ids', 'deepFMpredictions', 'labels', 'variances', 'means'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9db987e2-70ae-422f-a2a2-83dfe1532745",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'0'}>]], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(x['variances']).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0096030b-e44c-496c-9bbd-bcf8646b7808",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'0'}>]], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(x['means']).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f3f38b44-4e3c-4119-80b1-679a51a71e92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'0'}>]], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(x['deepFMpredictions']).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db82786e-fee5-4af1-9c72-c0b15fb15d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "A, b = compute_A_b(A, b, next_batch, compress_output_tensor, session=session)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
