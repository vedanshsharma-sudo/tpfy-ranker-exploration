{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba390e9b-1cb4-4252-9c21-d936e31cb255",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-09 14:17:27.679554: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2026-02-09 14:17:27.679584: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:dynamic_embedding.GraphKeys has already been deprecated. The Variable will not be added to collections because it does not actully own any value, but only a holder of tables, which may lead to import_meta_graph failed since non-valued object has been added to collection. If you need to use `tf.compat.v1.train.Saver` and access all Variables from collection, you could manually add it to the collection by tf.compat.v1.add_to_collections(names, var) instead.\n",
      "WARNING: env TENANT is not set, use the default value apse1-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-09 14:17:28.652843: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2026-02-09 14:17:28.652866: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2026-02-09 14:17:28.652880: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-11-72-173): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Configuration:\n",
      "  Model Name: tpfy-v3-mtl-r2\n",
      "  Training Date: 2026-02-06\n",
      "  Validation Date: 2026-02-06\n",
      "  Variant: cms3\n",
      "  Click NS: 0.08\n",
      "  Num Workers: 4\n",
      "  Reload Model: tpfy-v3-mtl-r2\n",
      "  Upload: False\n",
      "================================================================================\n",
      "TPFY MODEL INFERENCE FROM PLAIN WEIGHTS\n",
      "================================================================================\n",
      "\n",
      "Loaded config: tpfy/tpfy_config/mtl-in.yaml\n",
      "Batch size: 512\n",
      "\n",
      "Data path: s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06\n",
      "files s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00000-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2835-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00001-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2909-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00002-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3012-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00003-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2995-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00004-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2892-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00005-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3005-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00006-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2946-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00007-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2838-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00008-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2894-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00009-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2823-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00010-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2920-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00011-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3032-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00012-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2902-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00013-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2848-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00014-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2968-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00015-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3042-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00016-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2959-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00017-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2825-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00018-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2951-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00019-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3057-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00020-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2921-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00021-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3076-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00022-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2898-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00023-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3030-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00024-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2905-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00025-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2904-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00026-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3023-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00027-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3002-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00028-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3020-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00029-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2953-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00030-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2933-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00031-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3015-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00032-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2988-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00033-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3068-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00034-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3071-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00035-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2952-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00036-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3040-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00037-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2822-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00038-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3061-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00039-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3048-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00040-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2939-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00041-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3001-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00042-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2997-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00043-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2999-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00044-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2830-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00045-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3038-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00046-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3006-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00047-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2844-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00048-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2919-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00049-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3011-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00050-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3050-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00051-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2864-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00052-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2937-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00053-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3067-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00054-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2927-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00055-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2922-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00056-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2956-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00057-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2845-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00058-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2998-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00059-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2861-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00060-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2970-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00061-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3044-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00062-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2965-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00063-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3054-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00064-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3051-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00065-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2973-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00066-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3059-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00067-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2925-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00068-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2840-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00069-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2978-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00070-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2868-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00071-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2866-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00072-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2957-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00073-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2877-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00074-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2986-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00075-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2994-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00076-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2936-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00077-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3028-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00078-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2860-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00079-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3060-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00080-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2843-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00081-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3029-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00082-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2969-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00083-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3034-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00084-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2899-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00085-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2917-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00086-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3000-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00087-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2889-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00088-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2827-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00089-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2980-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00090-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2908-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00091-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2912-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00092-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2829-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00093-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3004-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00094-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2869-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00095-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3069-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00096-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2924-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00097-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2987-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00098-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2967-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00099-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2948-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00100-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2849-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00101-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2897-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00102-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2824-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00103-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2828-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00104-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2929-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00105-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3031-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00106-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2985-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00107-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3021-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00108-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2882-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00109-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2883-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00110-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2821-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00111-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2855-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00112-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2962-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00113-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2893-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00114-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2871-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00115-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2930-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00116-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3022-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00117-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2890-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00118-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2979-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00119-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2940-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00120-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3046-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00121-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3008-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00122-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2859-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00123-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3062-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00124-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2831-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00125-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2852-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00126-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2867-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00127-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2928-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00128-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2944-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00129-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3072-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00130-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3036-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00131-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3018-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00132-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3033-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00133-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2826-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00134-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2873-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00135-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2931-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00136-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2932-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00137-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2983-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00138-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2975-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00139-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2913-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00140-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2972-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00141-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2947-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00142-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2886-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00143-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2977-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00144-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2901-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00145-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2984-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00146-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2906-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00147-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3074-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00148-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3027-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00149-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2846-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00150-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2856-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00151-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2974-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00152-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2911-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00153-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2880-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00154-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2941-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00155-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2991-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00156-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2896-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00157-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2900-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00158-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2881-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00159-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3039-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00160-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3075-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00161-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2879-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00162-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2841-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00163-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2938-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00164-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3014-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00165-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3041-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00166-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2966-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00167-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2858-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00168-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2915-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00169-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2981-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00170-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3026-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00171-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2989-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00172-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2850-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00173-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2857-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00174-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2865-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00175-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2884-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00176-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2943-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00177-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2885-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00178-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3056-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00179-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2872-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00180-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2992-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00181-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2854-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00182-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2863-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00183-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2834-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00184-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3017-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00185-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2949-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00186-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2923-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00187-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3010-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00188-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2964-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00189-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3045-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00190-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3007-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00191-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3058-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00192-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2862-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00193-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2918-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00194-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2982-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00195-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2945-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00196-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3009-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00197-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2876-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00198-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2842-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00199-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3055-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00200-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2891-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00201-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2950-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00202-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3024-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00203-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2839-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00204-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2895-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00205-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3063-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00206-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3037-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00207-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2993-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00208-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2958-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00209-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3066-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00210-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2942-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00211-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2971-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00212-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2961-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00213-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2903-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00214-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2955-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00215-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2836-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00216-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2960-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00217-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2847-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00218-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2832-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00219-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3035-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00220-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2914-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00221-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2875-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00222-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2874-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00223-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2888-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00224-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2833-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00225-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3070-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00226-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2976-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00227-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3049-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00228-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2851-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00229-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3052-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00230-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3016-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00231-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3019-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00232-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2910-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00233-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3053-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00234-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3003-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00235-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2963-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00236-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2878-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00237-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2990-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00238-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3025-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00239-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3047-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00240-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3013-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00241-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2954-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00242-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3065-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00243-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2870-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00244-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2837-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00245-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3073-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00246-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2887-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00247-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3064-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00248-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2907-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00249-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2853-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00250-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2934-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00251-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-3043-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00252-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2996-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00253-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2935-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00254-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2926-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/agg-mtl-extracted-cms3/2026-02-06/part-00255-tid-7617731706831743383-d7b69ff7-441e-4659-95cb-8067a05f5f34-2916-1-c000.snappy.parquet\n",
      "WARNING:tensorflow:From /home/ubuntu/vedansh/code/persona-reco-core/offline/src/main/python/model/parquet_dataset.py:52: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From /home/ubuntu/vedansh/code/persona-reco-core/offline/src/main/python/model/parquet_dataset.py:52: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-09 14:17:29.290073: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_44271/4031436453.py:185: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n",
      "\n",
      "\n",
      "================================================================================\n",
      "BUILDING MODEL\n",
      "================================================================================\n",
      "Model compiled\n",
      "\n",
      "Fetching sample batch to build model...\n",
      "WARNING:tensorflow:From /tmp/ipykernel_44271/4031436453.py:230: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This is a deprecated API that should only be used in TF 1 graph mode and legacy TF 2 graph mode available through `tf.compat.v1`. In all other situations -- namely, eager mode and inside `tf.function` -- you can consume dataset elements using `for elem in dataset: ...` or by explicitly creating iterator via `iterator = iter(dataset)` and fetching its elements via `values = next(iterator)`. Furthermore, this API is not available in TF 2. During the transition from TF 1 to TF 2 you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)` to create a TF 1 graph mode style iterator for a dataset created through TF 2 APIs. Note that this should be a transient state of your code base as there are in general no guarantees about the interoperability of TF 1 and TF 2 code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-09 14:17:29.958984: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2499995000 Hz\n",
      "2026-02-09 14:17:30.004686: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample batch loaded: 9 features\n",
      "Running model forward pass to create weights...\n",
      "--------------\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "q Tensor(\"tpfy_model_v3/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n",
      "Model built successfully\n",
      "Total trainable variables: 16\n",
      "\n",
      "Initializing TensorFlow variables...\n",
      "\n",
      "================================================================================\n",
      "LOADING MODEL WEIGHTS\n",
      "================================================================================\n",
      "Reading checkpoint from: s3://p13n-reco-offline-models-prod/models/tpfy/tpfy-v3-mtl-r2/checkpoint\n",
      "Using checkpoint: 1770636411\n",
      "Loading weights from: s3://p13n-reco-offline-models-prod/models/tpfy/tpfy-v3-mtl-r2/1770636411/plain_weights.npz\n",
      "Loaded 18 weight tensors\n",
      "Weight keys: ['train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/kernel:0', 'train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/bias:0', 'train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/kernel:0', 'train/tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/bias:0', 'train/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_full_0:0', 'train/tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_compact_0:0', 'train/tpfy_model_v3/deepfm/dnn/dnn_hyb/bias_0:0', 'train/tpfy_model_v3/deepfm/compress_dense/kernel:0', 'train/tpfy_model_v3/deepfm/compress_dense/bias:0', 'train/tpfy_model_v3/deepfm/linear/linear_bias:0']...\n",
      "\n",
      "Restoring model weights...\n",
      "reload source keys\n",
      "tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/kernel:0\n",
      "tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/bias:0\n",
      "tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/kernel:0\n",
      "tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/bias:0\n",
      "tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_full_0:0\n",
      "tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_compact_0:0\n",
      "tpfy_model_v3/deepfm/dnn/dnn_hyb/bias_0:0\n",
      "tpfy_model_v3/deepfm/compress_dense/kernel:0\n",
      "tpfy_model_v3/deepfm/compress_dense/bias:0\n",
      "tpfy_model_v3/deepfm/linear/linear_bias:0\n",
      "tpfy_model_v3/deepfm/linear/linear_kernel:0\n",
      "tpfy_model_v3/deepfm/mtl_linear/linear_bias:0\n",
      "tpfy_model_v3/deepfm/mtl_linear/linear_kernel:0\n",
      "tpfy_model_v3/sparse_layer:0\n",
      "tpfy_model_v3/click_biases:0\n",
      "tpfy_model_v3/watch_biases:0\n",
      "embedding_layer/fids\n",
      "embedding_layer/embeddings\n",
      "resolve dense parameters\n",
      "resolving tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/kernel:0\n",
      "hit tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/kernel:0\n",
      "restore savable variable tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/kernel:0 <tf.Variable 'tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/kernel:0' shape=(32, 32) dtype=float32>\n",
      "resolving tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/bias:0\n",
      "hit tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/bias:0\n",
      "restore savable variable tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/bias:0 <tf.Variable 'tpfy_model_v3/feature_prep/dot_prod_attention_pooling/query_dense/bias:0' shape=(32,) dtype=float32>\n",
      "resolving tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/kernel:0\n",
      "hit tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/kernel:0\n",
      "restore savable variable tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/kernel:0 <tf.Variable 'tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/kernel:0' shape=(32, 32) dtype=float32>\n",
      "resolving tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/bias:0\n",
      "hit tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/bias:0\n",
      "restore savable variable tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/bias:0 <tf.Variable 'tpfy_model_v3/feature_prep/dot_prod_attention_pooling/key_dense/bias:0' shape=(32,) dtype=float32>\n",
      "resolving tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_full_0:0\n",
      "hit tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_full_0:0\n",
      "restore savable variable tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_full_0:0 <tf.Variable 'tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_full_0:0' shape=(320, 256) dtype=float32>\n",
      "resolving tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_compact_0:0\n",
      "hit tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_compact_0:0\n",
      "restore savable variable tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_compact_0:0 <tf.Variable 'tpfy_model_v3/deepfm/dnn/dnn_hyb/kernel_compact_0:0' shape=(864, 256) dtype=float32>\n",
      "resolving tpfy_model_v3/deepfm/dnn/dnn_hyb/bias_0:0\n",
      "hit tpfy_model_v3/deepfm/dnn/dnn_hyb/bias_0:0\n",
      "restore savable variable tpfy_model_v3/deepfm/dnn/dnn_hyb/bias_0:0 <tf.Variable 'tpfy_model_v3/deepfm/dnn/dnn_hyb/bias_0:0' shape=(256,) dtype=float32>\n",
      "resolving tpfy_model_v3/deepfm/compress_dense/kernel:0\n",
      "hit tpfy_model_v3/deepfm/compress_dense/kernel:0\n",
      "restore savable variable tpfy_model_v3/deepfm/compress_dense/kernel:0 <tf.Variable 'tpfy_model_v3/deepfm/compress_dense/kernel:0' shape=(508, 128) dtype=float32>\n",
      "resolving tpfy_model_v3/deepfm/compress_dense/bias:0\n",
      "hit tpfy_model_v3/deepfm/compress_dense/bias:0\n",
      "restore savable variable tpfy_model_v3/deepfm/compress_dense/bias:0 <tf.Variable 'tpfy_model_v3/deepfm/compress_dense/bias:0' shape=(128,) dtype=float32>\n",
      "resolving tpfy_model_v3/deepfm/linear/linear_bias:0\n",
      "hit tpfy_model_v3/deepfm/linear/linear_bias:0\n",
      "restore savable variable tpfy_model_v3/deepfm/linear/linear_bias:0 <tf.Variable 'tpfy_model_v3/deepfm/linear/linear_bias:0' shape=(2,) dtype=float32>\n",
      "resolving tpfy_model_v3/deepfm/linear/linear_kernel:0\n",
      "hit tpfy_model_v3/deepfm/linear/linear_kernel:0\n",
      "restore savable variable tpfy_model_v3/deepfm/linear/linear_kernel:0 <tf.Variable 'tpfy_model_v3/deepfm/linear/linear_kernel:0' shape=(128, 2) dtype=float32>\n",
      "resolving tpfy_model_v3/deepfm/mtl_linear/linear_bias:0\n",
      "hit tpfy_model_v3/deepfm/mtl_linear/linear_bias:0\n",
      "restore savable variable tpfy_model_v3/deepfm/mtl_linear/linear_bias:0 <tf.Variable 'tpfy_model_v3/deepfm/mtl_linear/linear_bias:0' shape=(2,) dtype=float32>\n",
      "resolving tpfy_model_v3/deepfm/mtl_linear/linear_kernel:0\n",
      "hit tpfy_model_v3/deepfm/mtl_linear/linear_kernel:0\n",
      "restore savable variable tpfy_model_v3/deepfm/mtl_linear/linear_kernel:0 <tf.Variable 'tpfy_model_v3/deepfm/mtl_linear/linear_kernel:0' shape=(128, 2) dtype=float32>\n",
      "resolving tpfy_model_v3/sparse_layer:0\n",
      "hit tpfy_model_v3/sparse_layer:0\n",
      "restore savable variable tpfy_model_v3/sparse_layer:0 <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "resolving tpfy_model_v3/click_biases:0\n",
      "hit tpfy_model_v3/click_biases:0\n",
      "restore savable variable tpfy_model_v3/click_biases:0 <tf.Variable 'tpfy_model_v3/click_biases:0' shape=(2,) dtype=float32>\n",
      "resolving tpfy_model_v3/watch_biases:0\n",
      "hit tpfy_model_v3/watch_biases:0\n",
      "restore savable variable tpfy_model_v3/watch_biases:0 <tf.Variable 'tpfy_model_v3/watch_biases:0' shape=(2,) dtype=float32>\n",
      "resolving embedding embedding_layer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-09 14:17:37.347750: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:143] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=32, init_size=8192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights restored successfully\n",
      "\n",
      "================================================================================\n",
      "RUNNING INFERENCE\n",
      "================================================================================\n",
      "files s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-02-06/part-00000-tid-8936393865993636468-60b9814b-9912-4a53-ab0a-96b98d2823b7-21905-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-02-06/part-00001-tid-8936393865993636468-60b9814b-9912-4a53-ab0a-96b98d2823b7-21902-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-02-06/part-00002-tid-8936393865993636468-60b9814b-9912-4a53-ab0a-96b98d2823b7-21917-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-02-06/part-00003-tid-8936393865993636468-60b9814b-9912-4a53-ab0a-96b98d2823b7-21911-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-02-06/part-00004-tid-8936393865993636468-60b9814b-9912-4a53-ab0a-96b98d2823b7-21925-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-02-06/part-00005-tid-8936393865993636468-60b9814b-9912-4a53-ab0a-96b98d2823b7-21918-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-02-06/part-00006-tid-8936393865993636468-60b9814b-9912-4a53-ab0a-96b98d2823b7-21921-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-02-06/part-00007-tid-8936393865993636468-60b9814b-9912-4a53-ab0a-96b98d2823b7-21907-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-02-06/part-00008-tid-8936393865993636468-60b9814b-9912-4a53-ab0a-96b98d2823b7-21913-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-02-06/part-00009-tid-8936393865993636468-60b9814b-9912-4a53-ab0a-96b98d2823b7-21910-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-02-06/part-00010-tid-8936393865993636468-60b9814b-9912-4a53-ab0a-96b98d2823b7-21908-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-02-06/part-00011-tid-8936393865993636468-60b9814b-9912-4a53-ab0a-96b98d2823b7-21906-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-02-06/part-00012-tid-8936393865993636468-60b9814b-9912-4a53-ab0a-96b98d2823b7-21919-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-02-06/part-00013-tid-8936393865993636468-60b9814b-9912-4a53-ab0a-96b98d2823b7-21914-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-02-06/part-00014-tid-8936393865993636468-60b9814b-9912-4a53-ab0a-96b98d2823b7-21900-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-02-06/part-00015-tid-8936393865993636468-60b9814b-9912-4a53-ab0a-96b98d2823b7-21920-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-02-06/part-00016-tid-8936393865993636468-60b9814b-9912-4a53-ab0a-96b98d2823b7-21899-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-02-06/part-00017-tid-8936393865993636468-60b9814b-9912-4a53-ab0a-96b98d2823b7-21901-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-02-06/part-00018-tid-8936393865993636468-60b9814b-9912-4a53-ab0a-96b98d2823b7-21924-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-02-06/part-00019-tid-8936393865993636468-60b9814b-9912-4a53-ab0a-96b98d2823b7-21915-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-02-06/part-00020-tid-8936393865993636468-60b9814b-9912-4a53-ab0a-96b98d2823b7-21923-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-02-06/part-00021-tid-8936393865993636468-60b9814b-9912-4a53-ab0a-96b98d2823b7-21922-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-02-06/part-00022-tid-8936393865993636468-60b9814b-9912-4a53-ab0a-96b98d2823b7-21926-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-02-06/part-00023-tid-8936393865993636468-60b9814b-9912-4a53-ab0a-96b98d2823b7-21927-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-02-06/part-00024-tid-8936393865993636468-60b9814b-9912-4a53-ab0a-96b98d2823b7-21912-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-02-06/part-00025-tid-8936393865993636468-60b9814b-9912-4a53-ab0a-96b98d2823b7-21903-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-02-06/part-00026-tid-8936393865993636468-60b9814b-9912-4a53-ab0a-96b98d2823b7-21916-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-02-06/part-00027-tid-8936393865993636468-60b9814b-9912-4a53-ab0a-96b98d2823b7-21909-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-02-06/part-00028-tid-8936393865993636468-60b9814b-9912-4a53-ab0a-96b98d2823b7-21898-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-02-06/part-00029-tid-8936393865993636468-60b9814b-9912-4a53-ab0a-96b98d2823b7-21904-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-02-06/part-00030-tid-8936393865993636468-60b9814b-9912-4a53-ab0a-96b98d2823b7-21897-1-c000.snappy.parquet,s3://p13n-reco-offline-prod/dataset_v5/tpfy-impr-v3/daily-mtl-extracted-cms3/cd=2026-02-06/part-00031-tid-8936393865993636468-60b9814b-9912-4a53-ab0a-96b98d2823b7-21928-1-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['ENV'] = 'prod'\n",
    "os.environ['REGION'] = 'apse1'\n",
    "os.environ['TENANT'] =\"in\"\n",
    "os.environ['RECO_S3_BUCKET'] = \"p13n-reco-offline-prod\"\n",
    "os.environ['COUNTRY_KEY']= \"in\"\n",
    "os.environ['AWS_REGION']= \"ap-southeast-1\"\n",
    "os.environ['USE_REAL_CMS3']= \"True\"\n",
    "os.environ['RECO_CREDENTIAL']= \"-----BEGINRSAPRIVATEKEY-----\\nMGICAQACEQCdHOlGnxIMWCMzjK2JAg37AgMBAAECEGOIwGTEO9vd3X9+jyiF4NECCQnoqDakDgSm2QIID9sadWN0XvMCCQLiqPkgVKSuIQIIDCAsWM+pJB8CCQG0jbIGCNX9MA==\\n-----ENDRSAPRIVATEKEY-----\"\n",
    "\n",
    "\n",
    "import argparse, gc\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import s3fs\n",
    "import pyarrow\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "tfv1 = tf.compat.v1\n",
    "tfv1.disable_v2_behavior()\n",
    "\n",
    "# Enable memory growth for GPUs to avoid memory fragmentation\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    for device in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_recommenders_addons as tfra\n",
    "\n",
    "from common.config.utils import data_path, model_path\n",
    "from common.config import TENANT\n",
    "from tpfy.tf_model.tpfy_model_v3_mtl import TpfyModelV3, TpfyMtlModelConfig\n",
    "from tpfy.etl.schema import TpfyMtlDatasetSchema\n",
    "from model.parquet_dataset import TFParquetDataset\n",
    "from tpfy.common import TpfyDataPath\n",
    "from omegaconf import OmegaConf\n",
    "from dataclasses import dataclass\n",
    "from tpfy.train_v3_mtl import make_example_mtl, TpfyTrainConfig, TpfyConfig\n",
    "\n",
    "S3_TPFY_MODEL_EXPORT = model_path(TpfyDataPath.S3_TPFY_MODEL_EXPORT, TENANT)\n",
    "\n",
    "def load_model_weights_from_s3(model_name, use_s3=True):\n",
    "    \"\"\"\n",
    "    Load plain weights from S3 or local filesystem\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name of the model (e.g., \"my_model/12345678\")\n",
    "        checkpoint: Specific checkpoint to load (None = read from checkpoint file)\n",
    "        use_s3: If True, load from S3; if False, load from local export/\n",
    "    \n",
    "    Returns:\n",
    "        dict: Plain weights dictionary\n",
    "    \"\"\"\n",
    "    if use_s3:\n",
    "        filesystem = s3fs.S3FileSystem(use_ssl=False)\n",
    "        model_path = S3_TPFY_MODEL_EXPORT % model_name\n",
    "    else:\n",
    "        filesystem = pyarrow.LocalFileSystem()\n",
    "        model_path = os.path.join(\"export\", model_name)\n",
    "    \n",
    "    # Read checkpoint if not specified\n",
    "    checkpoint_path = os.path.join(model_path, \"checkpoint\")\n",
    "    print(f\"Reading checkpoint from: {checkpoint_path}\")\n",
    "\n",
    "    if not filesystem.exists(checkpoint_path):\n",
    "        raise FileNotFoundError(f\"Checkpoint file not found: {checkpoint_path}\")\n",
    "\n",
    "    with filesystem.open(checkpoint_path, \"r\") as f:\n",
    "        checkpoint = f.read().strip()\n",
    "    print(f\"Using checkpoint: {checkpoint}\")\n",
    "    \n",
    "    # Load weights\n",
    "    weights_path = os.path.join(model_path, checkpoint, \"plain_weights.npz\")\n",
    "    print(f\"Loading weights from: {weights_path}\")\n",
    "    \n",
    "    if not filesystem.exists(weights_path):\n",
    "        raise FileNotFoundError(f\"Weights file not found: {weights_path}\")\n",
    "    \n",
    "    with filesystem.open(weights_path, \"rb\") as f:\n",
    "        plain_weights = {}\n",
    "        npz_data = np.load(f)\n",
    "        for k, v in npz_data.items():\n",
    "            plain_weights[k] = v\n",
    "    \n",
    "    print(f\"Loaded {len(plain_weights)} weight tensors\")\n",
    "    print(f\"Weight keys: {list(plain_weights.keys())[:10]}...\")  # Show first 10\n",
    "    \n",
    "    return plain_weights\n",
    "\n",
    "class Args:\n",
    "    \"\"\"Simple class to hold training arguments (replaces argparse)\"\"\"\n",
    "    def __init__(self):\n",
    "        # Positional arguments\n",
    "        self.model_name = \"tpfy-v3-mtl-r2\"\n",
    "        self.date = \"2026-02-06\"  # Training date\n",
    "        self.val_date = \"2026-02-06\"  # Validation date\n",
    "        \n",
    "        # Optional arguments\n",
    "        self.conf = None\n",
    "        self.max_epoch = None\n",
    "        self.val_days = 1\n",
    "        self.click_ns = 0.08\n",
    "        self.variant = \"cms3\"\n",
    "        self.num_workers = 4\n",
    "        self.repeat = 1\n",
    "        self.eval_freq = None\n",
    "        self.lr = 1e-4\n",
    "        self.batch_size = 512\n",
    "        self.click_weight = 1.0\n",
    "        self.watch_weight = 1.0\n",
    "        self.upload = False  # Set to False if you don't want to upload to S3\n",
    "        self.reload_local_model = None\n",
    "        self.reload_s3_model = \"tpfy-v3-mtl-r2\"  # Set to None if starting fresh\n",
    "        self.extract_activations = True\n",
    "        self.output = None\n",
    "        self.clear_nn = False\n",
    "        self.ckpt = None\n",
    "        self.verbose = False\n",
    "        self.countries = None\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# Display configuration\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"  Model Name: {args.model_name}\")\n",
    "print(f\"  Training Date: {args.date}\")\n",
    "print(f\"  Validation Date: {args.val_date}\")\n",
    "print(f\"  Variant: {args.variant}\")\n",
    "print(f\"  Click NS: {args.click_ns}\")\n",
    "print(f\"  Num Workers: {args.num_workers}\")\n",
    "print(f\"  Reload Model: {args.reload_s3_model}\")\n",
    "print(f\"  Upload: {args.upload}\")\n",
    "\n",
    "import pandas as pd\n",
    "content_popularity_tag = pd.read_csv('/home/ubuntu/vedansh/code/tpfy-ranker-exploration/content_id_popularity_tag.csv')\n",
    "content_popularity_tag.drop_duplicates(subset=['sub_title_id'], inplace = True)\n",
    "content_popularity_tag.reset_index(drop = True, inplace = True)\n",
    "content_popularity_dict = content_popularity_tag.set_index('sub_title_id')['popularity_tag'].to_dict()\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle\n",
    "    \n",
    "# def run():\n",
    "print(\"=\"*80)\n",
    "print(\"TPFY MODEL INFERENCE FROM PLAIN WEIGHTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load configuration\n",
    "config_name = f\"tpfy/tpfy_config/mtl-{TENANT}.yaml\"\n",
    "if not os.path.exists(config_name):\n",
    "    raise FileNotFoundError(f\"Config file {config_name} not found\")\n",
    "\n",
    "hparams: TpfyConfig = OmegaConf.merge(\n",
    "    OmegaConf.structured(TpfyConfig),\n",
    "    OmegaConf.load(config_name),\n",
    ")\n",
    "print(f\"\\nLoaded config: {config_name}\")\n",
    "\n",
    "# Override batch size if specified\n",
    "if args.batch_size:\n",
    "    hparams.train.batch_size = args.batch_size\n",
    "\n",
    "batch_size = hparams.train.batch_size\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "\n",
    "# Load dataset\n",
    "variant = args.variant\n",
    "if variant and not variant.startswith(\"-\"):\n",
    "    variant = \"-\" + variant\n",
    "\n",
    "data_date = args.date\n",
    "data_path_str = data_path(\n",
    "    TpfyDataPath.S3_TPFY_IMPR_V3_AGG_MTL_EXTRACTED_EXAMPLES_VAR, TENANT\n",
    ") % (variant, data_date)\n",
    "\n",
    "print(f\"\\nData path: {data_path_str}\")\n",
    "\n",
    "dataset = TFParquetDataset([data_path_str], TpfyMtlDatasetSchema, shuffle_files=False)\n",
    "tf_dataset = dataset.create_tf_dataset(batch_size).map(make_example_mtl)\n",
    "\n",
    "# Create TensorFlow session\n",
    "session = tfv1.keras.backend.get_session()\n",
    "\n",
    "# Build model\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"BUILDING MODEL\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "tpfy_model = TpfyModelV3(\n",
    "    hparams.model,\n",
    "    click_ns=args.click_ns,\n",
    "    enable_random_watch=hparams.train.enable_random_watch,\n",
    ")\n",
    "\n",
    "# Create optimizer (needed for compilation, even though we won't train)\n",
    "optimizer = tfa.optimizers.AdamW(\n",
    "    weight_decay=0.0,  # Not needed for inference\n",
    "    learning_rate=0.001,  # Not needed for inference\n",
    "    epsilon=1e-4,\n",
    ")\n",
    "optimizer = tfra.dynamic_embedding.DynamicEmbeddingOptimizer(optimizer)\n",
    "\n",
    "# Compile model (required to initialize variables)\n",
    "from model.losses import masked_binary_entropy_loss\n",
    "from model.metrics import MaskedAUC\n",
    "\n",
    "loss_dict = {\n",
    "    \"click\": masked_binary_entropy_loss(from_logits=True),\n",
    "    \"watch\": masked_binary_entropy_loss(from_logits=True),\n",
    "    \"random_watch\": masked_binary_entropy_loss(from_logits=False),\n",
    "    \"paywall_view\": masked_binary_entropy_loss(from_logits=True),\n",
    "    \"add_watchlist\": masked_binary_entropy_loss(from_logits=True),\n",
    "}\n",
    "metric_dict = {\n",
    "    \"click\": MaskedAUC(from_logits=True),\n",
    "    \"watch\": MaskedAUC(from_logits=True),\n",
    "    \"random_watch\": MaskedAUC(from_logits=False),\n",
    "    \"paywall_view\": MaskedAUC(from_logits=True),\n",
    "    \"add_watchlist\": MaskedAUC(from_logits=True),\n",
    "}\n",
    "\n",
    "tpfy_model.compile(optimizer=optimizer, loss=loss_dict, metrics=metric_dict)\n",
    "print(\"Model compiled\")\n",
    "\n",
    "# ========== BUILD MODEL WITH SAMPLE DATA ==========\n",
    "print(\"\\nFetching sample batch to build model...\")\n",
    "iterator = tf_dataset.make_one_shot_iterator()\n",
    "next_batch = iterator.get_next()\n",
    "\n",
    "sample_features, sample_labels, sample_metadata = session.run(next_batch)\n",
    "print(f\"Sample batch loaded: {len(sample_features)} features\")\n",
    "\n",
    "print(\"Running model forward pass to create weights...\")\n",
    "_ = tpfy_model(sample_features, training=False)\n",
    "\n",
    "print(f\"Model built successfully\")\n",
    "print(f\"Total trainable variables: {len(tpfy_model.trainable_variables)}\")\n",
    "\n",
    "# Initialize all variables\n",
    "print(\"\\nInitializing TensorFlow variables...\")\n",
    "session.run([\n",
    "    tfv1.global_variables_initializer(),\n",
    "    tfv1.local_variables_initializer(),\n",
    "    tfv1.tables_initializer(),\n",
    "])\n",
    "# ==================================================\n",
    "\n",
    "# Load plain weights from S3\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"LOADING MODEL WEIGHTS\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "plain_weights = load_model_weights_from_s3(\n",
    "    args.model_name,\n",
    "    use_s3=True\n",
    ")\n",
    "plain_weights_modified = {k.replace('train/', ''): v for k, v in plain_weights.items()}\n",
    "\n",
    "# Restore weights (NOW the model is built, so this will work)\n",
    "print(\"\\nRestoring model weights...\")\n",
    "restore_ops = tpfy_model.restore_plain_weights_ops(\n",
    "    plain_weights_modified,\n",
    "    clear_nn=args.clear_nn\n",
    ")\n",
    "session.run(restore_ops)\n",
    "print(\"Weights restored successfully\")\n",
    "\n",
    "# Create NEW iterator (reset to start of dataset)\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"RUNNING INFERENCE\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "iterator = tf_dataset.make_one_shot_iterator()\n",
    "next_batch = iterator.get_next()\n",
    "\n",
    "# Get compress_output tensor (linear_input)\n",
    "graph = tf.compat.v1.get_default_graph()\n",
    "\n",
    "# Find the compress_out tensor that is fed to output layer that predicts click / watch\n",
    "compress_output_tensor = graph.get_tensor_by_name('tpfy_model_v3/deepfm/Relu:0')\n",
    "\n",
    "from common.time_utils import get_dates_list_forwards\n",
    "from model.trainer import Trainer, ValData, LearningRateScheduler\n",
    "\n",
    "validation_dataset_dict = {}\n",
    "dataset_schema = TpfyMtlDatasetSchema\n",
    "val_tenant_or_countries = [TENANT]\n",
    "for country in val_tenant_or_countries:\n",
    "    for dt in get_dates_list_forwards(args.val_date, args.val_days):\n",
    "        val_dataset = TFParquetDataset(\n",
    "            [\n",
    "                data_path(\n",
    "                    TpfyDataPath.S3_TPFY_IMPR_V3_DAILY_MTL_EXTRACTED_EXAMPLES,\n",
    "                    country,\n",
    "                )\n",
    "                % (variant, dt)\n",
    "            ],\n",
    "            dataset_schema,\n",
    "            shuffle_files=False,\n",
    "        )\n",
    "        validation_dataset_dict[f\"{country}-{dt}\"] = ValData(\n",
    "            val_dataset.create_tf_dataset(batch_size)\n",
    "            .take(hparams.train.eval_steps)\n",
    "            .cache(f\"val_mtl_{country}_{dt}\")\n",
    "            .map(make_example_mtl),\n",
    "            active_objectives=[\n",
    "                \"click\",\n",
    "                \"watch\",\n",
    "                \"random_watch\",\n",
    "                \"paywall_view\",\n",
    "                \"add_watchlist\",\n",
    "            ],\n",
    "        )\n",
    "\n",
    "val_it = tfv1.data.make_initializable_iterator(validation_dataset_dict['in-2026-02-06'].tf_dataset)\n",
    "session.run(val_it.initializer)\n",
    "val_next = val_it.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81370d15-abf2-4dad-8be8-0cc215adbc66",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                              | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_1/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_1/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_1/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_1/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_1/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_1/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_1/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_1/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_1/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_1/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_1/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_1/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|                                                                                                                                                    | 1/100 [00:08<13:13,  8.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_2/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_2/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_2/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_2/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_2/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_2/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_2/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_2/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_2/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_2/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_2/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_2/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|                                                                                                                                                   | 2/100 [00:08<06:00,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_3/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_3/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_3/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_3/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_3/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_3/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_3/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_3/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_3/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_3/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_3/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_3/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|                                                                                                                                                 | 3/100 [00:09<03:41,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_4/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_4/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_4/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_4/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_4/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_4/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_4/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_4/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_4/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_4/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_4/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_4/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                                                                                                | 4/100 [00:09<02:36,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_5/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_5/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_5/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_5/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_5/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_5/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_5/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_5/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_5/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_5/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_5/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_5/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|                                                                                                                                              | 5/100 [00:10<02:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_6/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_6/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_6/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_6/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_6/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_6/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_6/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_6/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_6/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_6/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_6/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_6/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|                                                                                                                                             | 6/100 [00:11<01:39,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_7/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_7/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_7/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_7/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_7/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_7/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_7/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_7/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_7/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_7/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_7/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_7/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|                                                                                                                                           | 7/100 [00:11<01:26,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_8/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_8/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_8/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_8/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_8/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_8/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_8/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_8/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_8/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_8/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_8/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_8/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|                                                                                                                                          | 8/100 [00:12<01:19,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_9/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_9/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_9/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_9/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_9/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_9/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_9/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_9/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_9/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_9/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_9/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_9/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|                                                                                                                                        | 9/100 [00:13<01:16,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_10/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_10/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_10/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_10/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_10/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_10/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_10/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_10/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_10/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_10/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_10/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_10/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|                                                                                                                                      | 10/100 [00:14<01:11,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_11/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_11/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_11/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_11/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_11/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_11/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_11/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_11/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_11/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_11/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_11/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_11/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|                                                                                                                                    | 11/100 [00:14<01:07,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_12/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_12/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_12/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_12/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_12/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_12/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_12/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_12/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_12/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_12/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_12/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_12/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|                                                                                                                                   | 12/100 [00:15<01:05,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_13/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_13/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_13/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_13/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_13/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_13/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_13/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_13/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_13/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_13/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_13/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_13/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|                                                                                                                                 | 13/100 [00:16<01:04,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_14/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_14/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_14/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_14/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_14/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_14/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_14/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_14/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_14/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_14/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_14/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_14/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|                                                                                                                                | 14/100 [00:16<01:01,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_15/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_15/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_15/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_15/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_15/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_15/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_15/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_15/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_15/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_15/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_15/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_15/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|                                                                                                                              | 15/100 [00:17<01:01,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_16/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_16/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_16/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_16/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_16/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_16/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_16/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_16/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_16/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_16/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_16/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_16/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|                                                                                                                             | 16/100 [00:18<01:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_17/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_17/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_17/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_17/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_17/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_17/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_17/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_17/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_17/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_17/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_17/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_17/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|                                                                                                                           | 17/100 [00:19<01:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_18/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_18/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_18/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_18/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_18/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_18/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_18/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_18/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_18/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_18/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_18/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_18/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|                                                                                                                          | 18/100 [00:19<00:59,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_19/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_19/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_19/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_19/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_19/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_19/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_19/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_19/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_19/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_19/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_19/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_19/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|                                                                                                                        | 19/100 [00:20<00:59,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_20/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_20/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_20/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_20/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_20/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_20/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_20/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_20/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_20/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_20/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_20/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_20/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|                                                                                                                       | 20/100 [00:21<00:59,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_21/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_21/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_21/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_21/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_21/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_21/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_21/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_21/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_21/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_21/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_21/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_21/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|                                                                                                                     | 21/100 [00:22<00:59,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_22/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_22/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_22/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_22/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_22/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_22/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_22/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_22/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_22/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_22/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_22/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_22/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|                                                                                                                    | 22/100 [00:22<00:59,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_23/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_23/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_23/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_23/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_23/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_23/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_23/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_23/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_23/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_23/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_23/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_23/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|                                                                                                                  | 23/100 [00:23<00:55,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_24/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_24/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_24/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_24/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_24/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_24/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_24/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_24/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_24/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_24/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_24/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_24/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|                                                                                                                 | 24/100 [00:24<00:52,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_25/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_25/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_25/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_25/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_25/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_25/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_25/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_25/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_25/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_25/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_25/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_25/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|                                                                                                               | 25/100 [00:24<00:53,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_26/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_26/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_26/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_26/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_26/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_26/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_26/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_26/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_26/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_26/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_26/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_26/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|                                                                                                              | 26/100 [00:25<00:51,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_27/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_27/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_27/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_27/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_27/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_27/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_27/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_27/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_27/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_27/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_27/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_27/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|                                                                                                            | 27/100 [00:26<00:49,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_28/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_28/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_28/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_28/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_28/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_28/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_28/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_28/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_28/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_28/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_28/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_28/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|                                                                                                           | 28/100 [00:26<00:48,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_29/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_29/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_29/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_29/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_29/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_29/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_29/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_29/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_29/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_29/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_29/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_29/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|                                                                                                         | 29/100 [00:27<00:48,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_30/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_30/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_30/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_30/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_30/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_30/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_30/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_30/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_30/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_30/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_30/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_30/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|                                                                                                        | 30/100 [00:28<00:47,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_31/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_31/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_31/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_31/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_31/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_31/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_31/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_31/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_31/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_31/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_31/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_31/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|                                                                                                      | 31/100 [00:28<00:47,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_32/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_32/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_32/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_32/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_32/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_32/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_32/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_32/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_32/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_32/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_32/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_32/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|                                                                                                     | 32/100 [00:29<00:46,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_33/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_33/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_33/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_33/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_33/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_33/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_33/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_33/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_33/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_33/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_33/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_33/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|                                                                                                   | 33/100 [00:30<00:46,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_34/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_34/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_34/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_34/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_34/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_34/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_34/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_34/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_34/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_34/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_34/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_34/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|                                                                                                  | 34/100 [00:31<00:46,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_35/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_35/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_35/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_35/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_35/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_35/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_35/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_35/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_35/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_35/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_35/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_35/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|                                                                                                | 35/100 [00:31<00:46,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_36/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_36/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_36/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_36/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_36/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_36/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_36/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_36/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_36/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_36/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_36/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_36/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|                                                                                               | 36/100 [00:32<00:46,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_37/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_37/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_37/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_37/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_37/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_37/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_37/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_37/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_37/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_37/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_37/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_37/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|                                                                                             | 37/100 [00:33<00:46,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_38/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_38/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_38/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_38/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_38/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_38/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_38/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_38/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_38/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_38/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_38/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_38/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|                                                                                            | 38/100 [00:34<00:45,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_39/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_39/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_39/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_39/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_39/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_39/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_39/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_39/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_39/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_39/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_39/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_39/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|                                                                                           | 39/100 [00:34<00:45,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_40/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_40/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_40/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_40/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_40/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_40/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_40/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_40/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_40/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_40/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_40/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_40/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|                                                                                         | 40/100 [00:35<00:46,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_41/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_41/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_41/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_41/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_41/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_41/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_41/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_41/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_41/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_41/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_41/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_41/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|                                                                                        | 41/100 [00:36<00:45,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_42/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_42/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_42/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_42/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_42/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_42/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_42/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_42/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_42/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_42/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_42/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_42/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|                                                                                      | 42/100 [00:37<00:45,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_43/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_43/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_43/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_43/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_43/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_43/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_43/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_43/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_43/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_43/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_43/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_43/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|                                                                                     | 43/100 [00:38<00:45,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_44/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_44/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_44/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_44/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_44/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_44/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_44/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_44/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_44/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_44/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_44/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_44/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|                                                                                   | 44/100 [00:38<00:45,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_45/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_45/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_45/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_45/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_45/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_45/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_45/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_45/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_45/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_45/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_45/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_45/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|                                                                                  | 45/100 [00:39<00:44,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_46/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_46/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_46/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_46/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_46/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_46/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_46/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_46/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_46/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_46/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_46/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_46/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|                                                                                | 46/100 [00:40<00:43,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_47/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_47/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_47/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_47/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_47/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_47/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_47/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_47/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_47/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_47/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_47/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_47/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|                                                                               | 47/100 [00:41<00:43,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_48/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_48/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_48/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_48/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_48/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_48/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_48/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_48/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_48/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_48/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_48/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_48/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|                                                                             | 48/100 [00:42<00:45,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_49/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_49/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_49/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_49/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_49/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_49/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_49/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_49/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_49/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_49/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_49/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_49/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|                                                                            | 49/100 [00:43<00:44,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_50/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_50/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_50/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_50/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_50/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_50/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_50/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_50/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_50/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_50/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_50/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_50/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|                                                                          | 50/100 [00:44<00:43,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_51/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_51/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_51/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_51/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_51/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_51/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_51/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_51/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_51/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_51/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_51/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_51/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|                                                                         | 51/100 [00:44<00:42,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_52/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_52/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_52/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_52/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_52/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_52/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_52/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_52/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_52/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_52/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_52/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_52/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|                                                                       | 52/100 [00:45<00:42,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_53/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_53/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_53/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_53/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_53/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_53/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_53/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_53/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_53/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_53/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_53/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_53/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|                                                                      | 53/100 [00:46<00:41,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_54/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_54/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_54/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_54/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_54/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_54/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_54/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_54/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_54/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_54/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_54/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_54/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|                                                                    | 54/100 [00:47<00:41,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_55/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_55/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_55/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_55/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_55/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_55/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_55/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_55/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_55/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_55/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_55/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_55/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|                                                                   | 55/100 [00:48<00:40,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_56/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_56/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_56/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_56/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_56/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_56/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_56/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_56/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_56/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_56/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_56/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_56/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|                                                                 | 56/100 [00:49<00:40,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_57/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_57/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_57/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_57/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_57/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_57/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_57/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_57/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_57/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_57/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_57/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_57/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|                                                                | 57/100 [00:50<00:39,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_58/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_58/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_58/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_58/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_58/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_58/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_58/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_58/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_58/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_58/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_58/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_58/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|                                                              | 58/100 [00:51<00:39,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_59/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_59/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_59/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_59/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_59/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_59/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_59/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_59/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_59/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_59/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_59/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_59/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|                                                             | 59/100 [00:52<00:38,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_60/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_60/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_60/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_60/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_60/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_60/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_60/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_60/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_60/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_60/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_60/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_60/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|                                                           | 60/100 [00:53<00:38,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_61/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_61/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_61/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_61/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_61/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_61/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_61/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_61/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_61/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_61/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_61/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_61/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|                                                          | 61/100 [00:54<00:37,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_62/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_62/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_62/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_62/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_62/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_62/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_62/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_62/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_62/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_62/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_62/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_62/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|                                                        | 62/100 [00:55<00:36,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_63/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_63/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_63/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_63/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_63/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_63/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_63/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_63/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_63/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_63/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_63/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_63/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|                                                       | 63/100 [00:56<00:36,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_64/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_64/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_64/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_64/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_64/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_64/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_64/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_64/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_64/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_64/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_64/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_64/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|                                                     | 64/100 [00:57<00:35,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_65/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_65/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_65/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_65/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_65/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_65/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_65/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_65/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_65/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_65/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_65/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_65/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|                                                    | 65/100 [00:58<00:34,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_66/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_66/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_66/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_66/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_66/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_66/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_66/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_66/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_66/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_66/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_66/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_66/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|                                                  | 66/100 [00:59<00:34,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_67/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_67/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_67/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_67/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_67/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_67/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_67/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_67/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_67/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_67/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_67/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_67/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|                                                 | 67/100 [01:00<00:34,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_68/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_68/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_68/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_68/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_68/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_68/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_68/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_68/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_68/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_68/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_68/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_68/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|                                               | 68/100 [01:01<00:33,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_69/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_69/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_69/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_69/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_69/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_69/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_69/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_69/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_69/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_69/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_69/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_69/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|                                              | 69/100 [01:02<00:32,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_70/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_70/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_70/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_70/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_70/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_70/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_70/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_70/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_70/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_70/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_70/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_70/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|                                            | 70/100 [01:03<00:31,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_71/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_71/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_71/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_71/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_71/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_71/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_71/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_71/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_71/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_71/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_71/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_71/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|                                           | 71/100 [01:04<00:30,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_72/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_72/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_72/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_72/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_72/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_72/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_72/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_72/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_72/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_72/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_72/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_72/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|                                         | 72/100 [01:05<00:30,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_73/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_73/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_73/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_73/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_73/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_73/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_73/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_73/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_73/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_73/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_73/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_73/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|                                        | 73/100 [01:06<00:29,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_74/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_74/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_74/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_74/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_74/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_74/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_74/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_74/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_74/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_74/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_74/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_74/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|                                      | 74/100 [01:08<00:28,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_75/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_75/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_75/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_75/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_75/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_75/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_75/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_75/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_75/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_75/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_75/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_75/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|                                     | 75/100 [01:09<00:27,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_76/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_76/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_76/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_76/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_76/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_76/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_76/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_76/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_76/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_76/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_76/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_76/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|                                   | 76/100 [01:10<00:27,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_77/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_77/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_77/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_77/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_77/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_77/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_77/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_77/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_77/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_77/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_77/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_77/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|                                  | 77/100 [01:11<00:26,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_78/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_78/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_78/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_78/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_78/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_78/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_78/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_78/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_78/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_78/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_78/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_78/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|                                | 78/100 [01:12<00:25,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_79/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_79/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_79/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_79/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_79/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_79/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_79/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_79/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_79/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_79/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_79/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_79/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|                               | 79/100 [01:14<00:24,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_80/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_80/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_80/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_80/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_80/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_80/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_80/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_80/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_80/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_80/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_80/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_80/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|                             | 80/100 [01:15<00:23,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_81/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_81/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_81/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_81/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_81/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_81/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_81/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_81/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_81/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_81/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_81/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_81/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|                            | 81/100 [01:16<00:22,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_82/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_82/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_82/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_82/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_82/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_82/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_82/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_82/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_82/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_82/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_82/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_82/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|                          | 82/100 [01:17<00:21,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_83/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_83/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_83/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_83/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_83/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_83/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_83/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_83/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_83/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_83/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_83/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_83/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|                         | 83/100 [01:18<00:20,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_84/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_84/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_84/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_84/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_84/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_84/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_84/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_84/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_84/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_84/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_84/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_84/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|                       | 84/100 [01:20<00:19,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_85/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_85/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_85/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_85/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_85/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_85/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_85/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_85/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_85/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_85/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_85/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_85/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|                      | 85/100 [01:21<00:18,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_86/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_86/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_86/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_86/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_86/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_86/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_86/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_86/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_86/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_86/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_86/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_86/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|                    | 86/100 [01:22<00:17,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_87/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_87/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_87/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_87/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_87/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_87/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_87/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_87/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_87/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_87/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_87/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_87/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|                   | 87/100 [01:23<00:16,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_88/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_88/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_88/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_88/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_88/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_88/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_88/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_88/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_88/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_88/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_88/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_88/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|                  | 88/100 [01:25<00:14,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_89/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_89/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_89/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_89/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_89/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_89/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_89/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_89/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_89/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_89/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_89/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_89/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|                | 89/100 [01:26<00:13,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_90/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_90/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_90/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_90/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_90/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_90/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_90/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_90/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_90/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_90/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_90/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_90/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|               | 90/100 [01:27<00:12,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_91/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_91/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_91/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_91/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_91/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_91/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_91/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_91/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_91/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_91/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_91/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_91/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|             | 91/100 [01:28<00:11,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_92/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_92/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_92/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_92/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_92/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_92/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_92/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_92/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_92/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_92/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_92/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_92/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|            | 92/100 [01:30<00:10,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_93/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_93/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_93/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_93/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_93/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_93/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_93/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_93/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_93/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_93/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_93/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_93/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|          | 93/100 [01:31<00:09,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_94/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_94/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_94/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_94/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_94/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_94/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_94/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_94/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_94/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_94/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_94/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_94/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|         | 94/100 [01:32<00:07,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_95/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_95/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_95/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_95/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_95/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_95/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_95/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_95/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_95/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_95/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_95/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_95/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|       | 95/100 [01:34<00:06,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_96/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_96/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_96/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_96/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_96/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_96/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_96/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_96/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_96/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_96/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_96/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_96/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|      | 96/100 [01:35<00:05,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_97/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_97/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_97/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_97/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_97/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_97/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_97/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_97/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_97/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_97/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_97/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_97/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|    | 97/100 [01:36<00:04,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_98/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_98/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_98/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_98/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_98/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_98/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_98/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_98/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_98/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_98/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_98/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_98/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|   | 98/100 [01:38<00:02,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_99/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_99/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_99/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_99/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_99/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_99/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_99/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_99/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_99/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_99/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_99/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_99/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%| | 99/100 [01:39<00:01,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "q Tensor(\"tpfy_model_v3_100/feature_prep/strided_slice:0\", shape=(512, 32), dtype=float32)\n",
      "k Tensor(\"tpfy_model_v3_100/feature_prep/watched_content_embedding_unpooled:0\", shape=(512, ?, 32), dtype=float32)\n",
      "Kw Tensor(\"tpfy_model_v3_100/feature_prep/GetSlotFids:1\", shape=(512, ?), dtype=float32)\n",
      "target embedding shape (512, 9, 32)\n",
      "user embedding shape (512, 27, 32)\n",
      "target: Tensor(\"tpfy_model_v3_100/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "user: Tensor(\"tpfy_model_v3_100/feature_prep/user_feature/user_embeddings:0\", shape=(512, 27, 32), dtype=float32)\n",
      "watched: Tensor(\"tpfy_model_v3_100/feature_prep/dot_prod_attention_pooling/cond/Merge:0\", shape=(512, 32), dtype=float32)\n",
      "fm_user Tensor(\"tpfy_model_v3_100/deepfm/fwfm/concat:0\", shape=(512, 28, 32), dtype=float32)\n",
      "fm_item Tensor(\"tpfy_model_v3_100/feature_prep/target_feature/target_embeddings:0\", shape=(512, 9, 32), dtype=float32)\n",
      "fwfm out Tensor(\"tpfy_model_v3_100/deepfm/fwfm/Reshape:0\", shape=(512, 252), dtype=float32)\n",
      "compress dense out (512, 128)\n",
      "masked_compression_sparse_kernel Tensor(\"tpfy_model_v3_100/deepfm/sparse_nn/concat:0\", shape=(11, 128), dtype=float32)\n",
      "compression_sparse_kernel <tf.Variable 'tpfy_model_v3/sparse_layer:0' shape=(11, 128) dtype=float32>\n",
      "compress sparse out Tensor(\"tpfy_model_v3_100/deepfm/sparse_nn/Squeeze:0\", shape=(512, 128), dtype=float32)\n",
      "compress_output Tensor(\"tpfy_model_v3_100/deepfm/Relu:0\", shape=(512, 128), dtype=float32)\n",
      "target_output shape (512, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [01:41<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "def get_activations_and_labels(iterator, model, last_layer_tensor):\n",
    "    features, labels, metadata = session.run(iterator)\n",
    "\n",
    "    # Run model\n",
    "    predictions = model(features, training=False)\n",
    "\n",
    "    # Execute\n",
    "    pred_values, activation_values = session.run(\n",
    "        [predictions, last_layer_tensor]\n",
    "    )\n",
    "\n",
    "    return activation_values, labels, pred_values, metadata\n",
    "\n",
    "all_deepFMpredictions = []\n",
    "all_content_ids = []\n",
    "all_labels = []\n",
    "for i in tqdm(range(100)):\n",
    "    H, y_batch_all_labels, pred_values, metadata = get_activations_and_labels(val_next, tpfy_model, compress_output_tensor)\n",
    "    y_batch = y_batch_all_labels['click']\n",
    "    pred_values = pred_values['click']\n",
    "\n",
    "    mask = (y_batch != -1)\n",
    "\n",
    "    if not np.any(mask):\n",
    "        continue\n",
    "\n",
    "    # H = H[mask.squeeze()]\n",
    "    y_batch = y_batch[mask].reshape(sum(mask)[0], 1)\n",
    "    pred_values = pred_values[mask].reshape(sum(mask)[0], 1)\n",
    "\n",
    "    # H = H / (np.linalg.norm(H, axis=1, keepdims=True) + 1e-8)\n",
    "    # variance = np.sqrt(np.diag(H @ A_inv @ H.T))\n",
    "    # mean = H@theta\n",
    "\n",
    "    # Append to lists (will concatenate once at the end)\n",
    "    # all_predictions.append(mean)\n",
    "    all_deepFMpredictions.append(pred_values)\n",
    "    all_labels.append(y_batch)\n",
    "    # all_variances.append(variance)\n",
    "    all_content_ids.extend([int(content_id) for content_id, mask_bool in zip(metadata['content_id'], mask) if mask_bool])\n",
    "    # mse_sum += mean_squared_error(y_batch, mean)\n",
    "    # valid_runs += 1\n",
    "\n",
    "    # Clean up intermediate variables\n",
    "    # del H, y_batch, pred_values, mask, variance, mean, y_batch_all_labels, metadata\n",
    "\n",
    "# if valid_runs == 0:\n",
    "    # return None, None, None, None, None, None, None\n",
    "\n",
    "# Concatenate once at the end (more memory efficient)\n",
    "# predictions = np.concatenate(all_predictions, axis=0) if all_predictions else np.array([])\n",
    "deepFMpredictions = np.concatenate(all_deepFMpredictions, axis=0)\n",
    "labels = np.concatenate(all_labels, axis=0) if all_labels else np.array([])\n",
    "# variances = np.concatenate(all_variances, axis=0) if all_variances else np.array([])\n",
    "\n",
    "# Clean up lists\n",
    "# del all_predictions, all_labels, all_variances, all_deepFMpredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5575ba4-e35f-4e6f-8b46-51c5914f666d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "content_variances_df = pd.DataFrame({\n",
    "    'content_id': all_content_ids,\n",
    "    'deepFMpredictions': deepFMpredictions.flatten()\n",
    "})\n",
    "content_variances_df['popularity_tag'] = content_variances_df['content_id'].map(content_popularity_dict)\n",
    "popularity_deepFMpredictions_dist_stats = content_variances_df.groupby('popularity_tag')['deepFMpredictions'].describe().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5602328f-0352-47d9-bbac-0e5e8308f7b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Medium': 12467, 'Low': 12047, None: 7741, 'High': 3297, 'Negligible': 2870})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter([content_popularity_dict.get(x) for x in all_content_ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e08ddde1-431d-440f-a2c1-793be910fb45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1.0: 15509, 0.0: 22913})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(labels.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29c6c38a-4878-4f5c-8b51-a10afc94dfae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40364895112175314"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "15509/(15509+22913)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "101cdfef-68a8-4d34-8e0c-8a97dccfbdac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Medium': 0.3076923076923077, None: 0.2695854020246309, 'Low': 0.2655232445676704, 'High': 0.0939454510284351, 'Negligible': 0.06325359468695596}\n"
     ]
    }
   ],
   "source": [
    "label_1_dist = dict(Counter([content_popularity_dict.get(x) for x, y in zip(all_content_ids, list(labels.flatten())) if y == 1]))\n",
    "print(dict(sorted({k: v/sum(label_1_dist.values()) for k, v in label_1_dist.items()}.items(), key=lambda x: x[1], reverse=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2cfb5103-8677-44cd-9b11-dfc4ad34f055",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Low': 0.34604809496792216, 'Medium': 0.3358355518701174, None: 0.15537031379566185, 'Negligible': 0.08244228167415878, 'High': 0.08030375769213983}\n"
     ]
    }
   ],
   "source": [
    "label_1_dist = dict(Counter([content_popularity_dict.get(x) for x, y in zip(all_content_ids, list(labels.flatten())) if y == 0]))\n",
    "print(dict(sorted({k: v/sum(label_1_dist.values()) for k, v in label_1_dist.items()}.items(), key=lambda x: x[1], reverse=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1dc08f5-2804-4c62-bc77-1eead95b53ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38422, 38422)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(labels.flatten())), len(all_content_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73548326-9cfc-4d68-adfb-bfed17ada5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b707650b-3117-491c-8ea2-3c004fe5b1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_A_b_tf(A, b, iterator, model, last_layer_tensor, logging = False):\n",
    "    H, y_batch_all_labels, predictions, metadata = get_activations_and_labels(iterator, model, last_layer_tensor)\n",
    "    y_batch = y_batch_all_labels['click']\n",
    "\n",
    "    mask = (y_batch != -1)\n",
    "\n",
    "    if not np.any(mask):\n",
    "        return A, b\n",
    "\n",
    "    H = H[mask.squeeze()]\n",
    "    y_batch = y_batch[mask].reshape(sum(mask)[0], 1)\n",
    "\n",
    "    H = H / (np.linalg.norm(H, axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "    # Accumulate\n",
    "    A += H.T @ H\n",
    "    b += H.T @ y_batch\n",
    "\n",
    "    assert A.shape == (d, d)\n",
    "    assert b.shape == (d,1)\n",
    "    assert np.allclose(A, A.T, atol=1e-6)\n",
    "    assert np.linalg.eigvalsh(A).min() > 0\n",
    "\n",
    "    if logging:\n",
    "        A_inv = np.linalg.inv(A)\n",
    "        theta = A_inv @ b\n",
    "        mean = H@theta\n",
    "        mse_value = mean_squared_error(y_batch, mean)\n",
    "        return A, b, mse_value\n",
    "\n",
    "    return A, b, 0\n",
    "\n",
    "def validation(iterator, model, last_layer_tensor, d=128, runs=10):\n",
    "    # Use numpy arrays with preallocated size to avoid dynamic list growth\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_variances = []\n",
    "    all_content_ids = []\n",
    "    all_deepFMpredictions = []\n",
    "    mse_sum = 0.0\n",
    "    valid_runs = 0\n",
    "\n",
    "    for i in tqdm(range(runs)):\n",
    "        try:\n",
    "            H, y_batch_all_labels, pred_values, metadata = get_activations_and_labels(iterator, model, last_layer_tensor)\n",
    "            y_batch = y_batch_all_labels['click']\n",
    "            pred_values = pred_values['click']\n",
    "\n",
    "            mask = (y_batch != -1)\n",
    "\n",
    "            if not np.any(mask):\n",
    "                continue\n",
    "\n",
    "            H = H[mask.squeeze()]\n",
    "            y_batch = y_batch[mask].reshape(sum(mask)[0], 1)\n",
    "            pred_values = pred_values[mask].reshape(sum(mask)[0], 1)\n",
    "\n",
    "            H = H / (np.linalg.norm(H, axis=1, keepdims=True) + 1e-8)\n",
    "            variance = np.sqrt(np.diag(H @ A_inv @ H.T))\n",
    "            mean = H@theta\n",
    "\n",
    "            # Append to lists (will concatenate once at the end)\n",
    "            all_predictions.append(mean)\n",
    "            all_deepFMpredictions.append(pred_values)\n",
    "            all_labels.append(y_batch)\n",
    "            all_variances.append(variance)\n",
    "            all_content_ids.extend([int(content_id) for content_id, mask_bool in zip(metadata['content_id'], mask) if mask_bool])\n",
    "            mse_sum += mean_squared_error(y_batch, mean)\n",
    "            valid_runs += 1\n",
    "\n",
    "            # Clean up intermediate variables\n",
    "            del H, y_batch, pred_values, mask, variance, mean, y_batch_all_labels, metadata\n",
    "\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(f\"Iterator exhausted at run {i}\")\n",
    "            break\n",
    "\n",
    "    if valid_runs == 0:\n",
    "        return None, None, None, None, None, None, None\n",
    "\n",
    "    # Concatenate once at the end (more memory efficient)\n",
    "    predictions = np.concatenate(all_predictions, axis=0) if all_predictions else np.array([])\n",
    "    deepFMpredictions = np.concatenate(all_deepFMpredictions, axis=0) if all_predictions else np.array([])\n",
    "    labels = np.concatenate(all_labels, axis=0) if all_labels else np.array([])\n",
    "    variances = np.concatenate(all_variances, axis=0) if all_variances else np.array([])\n",
    "\n",
    "    # Clean up lists\n",
    "    del all_predictions, all_labels, all_variances, all_deepFMpredictions\n",
    "\n",
    "    return predictions, deepFMpredictions, labels, variances, all_content_ids, mse_sum / valid_runs\n",
    "\n",
    "lambda_=1.0\n",
    "d=128\n",
    "A = lambda_ * np.eye(d, dtype=np.float64)\n",
    "b = np.zeros((d, 1), dtype=np.float64)\n",
    "\n",
    "run = 0\n",
    "while True:\n",
    "    try:\n",
    "        if (run % 10 == 0) and (run):\n",
    "            # Find the training loss for the current batch\n",
    "            A, b, mse_value = compute_A_b_tf(A, b, next_batch, tpfy_model, compress_output_tensor, logging=True)\n",
    "\n",
    "            # Compute A_inv and theta\n",
    "            A_inv = np.linalg.inv(A)\n",
    "            theta = A_inv @ b\n",
    "\n",
    "            # Find the validation evals for 10 runs\n",
    "            val_results = validation(val_next, tpfy_model, compress_output_tensor, runs=10)\n",
    "\n",
    "            if val_results[0] is None:\n",
    "                print(f\"Validation failed at run {run}, skipping metrics\")\n",
    "                run += 1\n",
    "                continue\n",
    "\n",
    "            predictions, deepFMpredictions, labels, variances, content_ids, val_mse = val_results\n",
    "\n",
    "            # Create content variance DataFrame (optimized)\n",
    "            content_variances_df = pd.DataFrame({\n",
    "                'content_id': content_ids,\n",
    "                'variances': variances\n",
    "            })\n",
    "            content_variances_df['popularity_tag'] = content_variances_df['content_id'].map(content_popularity_dict)\n",
    "            popularity_variance_dist_stats = content_variances_df.groupby('popularity_tag')['variances'].describe().to_dict()\n",
    "\n",
    "            # Create content predictions DataFrame (optimized)\n",
    "            content_predictions_df = pd.DataFrame({\n",
    "                'content_id': content_ids,\n",
    "                'predictions': predictions.flatten()\n",
    "            })\n",
    "            content_predictions_df['popularity_tag'] = content_predictions_df['content_id'].map(content_popularity_dict)\n",
    "            popularity_mean_dist_stats = content_predictions_df.groupby('popularity_tag')['predictions'].describe().to_dict()\n",
    "\n",
    "            # Create content variance DataFrame (optimized)\n",
    "            content_variances_df = pd.DataFrame({\n",
    "                'content_id': content_ids,\n",
    "                'deepFMpredictions': deepFMpredictions.flatten()\n",
    "            })\n",
    "            content_variances_df['popularity_tag'] = content_variances_df['content_id'].map(content_popularity_dict)\n",
    "            popularity_deepFMpredictions_dist_stats = content_variances_df.groupby('popularity_tag')['deepFMpredictions'].describe().to_dict()\n",
    "\n",
    "            # Save results\n",
    "            dumping_dict = {\n",
    "                'train_mse': float(mse_value),\n",
    "                'valid_mse': float(val_mse),\n",
    "                'valid_popularity_variance_dist_stats': popularity_variance_dist_stats,\n",
    "                'valid_popularity_mean_dist_stats': popularity_mean_dist_stats,\n",
    "                'popularity_deepFMpredictions_dist_stats': popularity_deepFMpredictions_dist_stats\n",
    "            }\n",
    "\n",
    "            with open(f'tpfy/neural_linUCB_training_data/training_stats_run_{run}.pkl', 'wb') as handle:\n",
    "                pickle.dump(dumping_dict, handle)\n",
    "\n",
    "            np.save(f'tpfy/neural_linUCB_training_data/A_inv_{run}.npy', A_inv)\n",
    "            np.save(f'tpfy/neural_linUCB_training_data/b_{run}.npy', b)\n",
    "\n",
    "            print(f'Run {run} completed! Train MSE: {mse_value:.6f}, Val MSE: {val_mse:.6f}')\n",
    "\n",
    "            # Clean up large objects explicitly\n",
    "            del predictions, labels, variances, content_ids\n",
    "            del content_variances_df, content_predictions_df\n",
    "            del dumping_dict, popularity_variance_dist_stats, popularity_mean_dist_stats\n",
    "            del A_inv, theta\n",
    "\n",
    "            # Force garbage collection and clear TF cache\n",
    "            gc.collect()\n",
    "\n",
    "        else:\n",
    "            A, b, _ = compute_A_b_tf(A, b, next_batch, tpfy_model, compress_output_tensor)\n",
    "\n",
    "        run += 1\n",
    "        if run % 10 == 0:\n",
    "            print(f\"Completed run {run}\")\n",
    "\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print(\"Training iterator exhausted. Creating new iterator...\")\n",
    "        # Recreate iterator when dataset is exhausted\n",
    "        iterator = tf_dataset.make_one_shot_iterator()\n",
    "        next_batch = iterator.get_next()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nTraining interrupted by user\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"Error at run {run}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217e8ad9-aa7f-4676-b7dd-a9f6cbdec3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "     \n",
    "if __name__ == '__main__':\n",
    "    # Create args instance\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fb7907-b972-4b76-82e5-0a9ac4fa5a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3db772-9210-48b9-b83b-f431f79e9700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350d9a24-e16f-4b30-9444-be3d2789a70e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fa18d617-e0b4-4600-89ea-45bbffad5a19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>popularity_tag</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>High</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0.378092</td>\n",
       "      <td>0.049085</td>\n",
       "      <td>0.276541</td>\n",
       "      <td>0.346531</td>\n",
       "      <td>0.377811</td>\n",
       "      <td>0.412695</td>\n",
       "      <td>0.479660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Low</th>\n",
       "      <td>712.0</td>\n",
       "      <td>0.390327</td>\n",
       "      <td>0.057551</td>\n",
       "      <td>0.246480</td>\n",
       "      <td>0.351011</td>\n",
       "      <td>0.393396</td>\n",
       "      <td>0.428532</td>\n",
       "      <td>0.556614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medium</th>\n",
       "      <td>301.0</td>\n",
       "      <td>0.386819</td>\n",
       "      <td>0.051024</td>\n",
       "      <td>0.259666</td>\n",
       "      <td>0.352387</td>\n",
       "      <td>0.385491</td>\n",
       "      <td>0.420138</td>\n",
       "      <td>0.544572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negligible</th>\n",
       "      <td>251.0</td>\n",
       "      <td>0.390756</td>\n",
       "      <td>0.058150</td>\n",
       "      <td>0.249008</td>\n",
       "      <td>0.351673</td>\n",
       "      <td>0.388007</td>\n",
       "      <td>0.424368</td>\n",
       "      <td>0.549068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                count      mean       std       min       25%       50%  \\\n",
       "popularity_tag                                                            \n",
       "High             42.0  0.378092  0.049085  0.276541  0.346531  0.377811   \n",
       "Low             712.0  0.390327  0.057551  0.246480  0.351011  0.393396   \n",
       "Medium          301.0  0.386819  0.051024  0.259666  0.352387  0.385491   \n",
       "Negligible      251.0  0.390756  0.058150  0.249008  0.351673  0.388007   \n",
       "\n",
       "                     75%       max  \n",
       "popularity_tag                      \n",
       "High            0.412695  0.479660  \n",
       "Low             0.428532  0.556614  \n",
       "Medium          0.420138  0.544572  \n",
       "Negligible      0.424368  0.549068  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d3b4b68f-30e7-4c34-b2c0-2d2351e992f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24194492760854844"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d0efbd36-2aa3-4e73-9f4d-de2af4d1e125",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24175814473413207"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(np.concatenate(labels, axis=None), np.concatenate(predictions, axis=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d4985f61-374e-45aa-b740-ccfc517bd3bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.375\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "y_true = np.array([3, -0.5, 2, 7])\n",
    "y_pred = np.array([2.5, 0.0, 2, 8])\n",
    "\n",
    "# Calculate the MSE\n",
    "\n",
    "\n",
    "print(f\"Mean Squared Error: {mse_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "97089189-5143-4ed9-bdfa-31cb709b6a50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca4b067d-26b6-46ca-a32d-3104b48334b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14b7a6c5-55dc-4615-9ceb-56b76385364b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07202021],\n",
       "       [ 0.06932132],\n",
       "       [ 0.06605678],\n",
       "       [ 0.04273625],\n",
       "       [ 0.01857434],\n",
       "       [ 0.01353311],\n",
       "       [ 0.07517509],\n",
       "       [ 0.02552674],\n",
       "       [ 0.09584415],\n",
       "       [ 0.01353119],\n",
       "       [ 0.01489523],\n",
       "       [-0.03840626],\n",
       "       [-0.09159726],\n",
       "       [-0.01769249],\n",
       "       [-0.11187943],\n",
       "       [-0.02859642],\n",
       "       [ 0.0712055 ],\n",
       "       [ 0.07160617],\n",
       "       [-0.06165904],\n",
       "       [-0.03124967],\n",
       "       [-0.0606535 ],\n",
       "       [ 0.0891514 ],\n",
       "       [-0.01896497],\n",
       "       [ 0.11578616],\n",
       "       [ 0.06996752],\n",
       "       [ 0.12549896],\n",
       "       [ 0.06299783],\n",
       "       [ 0.09214726],\n",
       "       [-0.03598163],\n",
       "       [ 0.0917244 ],\n",
       "       [ 0.12542057],\n",
       "       [ 0.03854472],\n",
       "       [-0.07002611],\n",
       "       [-0.00474441],\n",
       "       [ 0.01925241],\n",
       "       [ 0.11237033],\n",
       "       [ 0.07385657],\n",
       "       [ 0.02147351],\n",
       "       [-0.00997246],\n",
       "       [ 0.01729478],\n",
       "       [ 0.02717852],\n",
       "       [-0.00103129],\n",
       "       [ 0.08630608],\n",
       "       [ 0.0509666 ],\n",
       "       [-0.01879738],\n",
       "       [ 0.12581335],\n",
       "       [ 0.08727145],\n",
       "       [ 0.01379975],\n",
       "       [ 0.08546332],\n",
       "       [ 0.06843343],\n",
       "       [ 0.08980128],\n",
       "       [ 0.04830846],\n",
       "       [-0.0048012 ],\n",
       "       [ 0.06660046],\n",
       "       [ 0.05635413],\n",
       "       [ 0.01626154],\n",
       "       [-0.0228522 ],\n",
       "       [ 0.07061678],\n",
       "       [-0.05930683],\n",
       "       [ 0.10505792],\n",
       "       [ 0.06161607],\n",
       "       [ 0.07524035],\n",
       "       [-0.02346994],\n",
       "       [ 0.0203764 ],\n",
       "       [-0.06259713],\n",
       "       [ 0.00194085],\n",
       "       [ 0.05164746],\n",
       "       [ 0.1679538 ],\n",
       "       [ 0.10631156],\n",
       "       [-0.04675588],\n",
       "       [-0.0400247 ],\n",
       "       [ 0.08133517],\n",
       "       [-0.03168905],\n",
       "       [ 0.00030308],\n",
       "       [ 0.09076888],\n",
       "       [ 0.0151258 ],\n",
       "       [ 0.        ],\n",
       "       [ 0.0787595 ],\n",
       "       [ 0.01095884],\n",
       "       [ 0.15934541],\n",
       "       [-0.03710971],\n",
       "       [ 0.07863806],\n",
       "       [ 0.01660169],\n",
       "       [ 0.1387952 ],\n",
       "       [ 0.15102338],\n",
       "       [-0.02298723],\n",
       "       [-0.02368982],\n",
       "       [ 0.0550819 ],\n",
       "       [ 0.03114197],\n",
       "       [-0.04273118],\n",
       "       [-0.13789861],\n",
       "       [ 0.12032836],\n",
       "       [ 0.02117033],\n",
       "       [ 0.15488147],\n",
       "       [-0.02654469],\n",
       "       [-0.08987565],\n",
       "       [-0.02222966],\n",
       "       [ 0.18858461],\n",
       "       [ 0.0301893 ],\n",
       "       [ 0.00839824],\n",
       "       [ 0.06915361],\n",
       "       [ 0.        ],\n",
       "       [ 0.06983203],\n",
       "       [ 0.18958569],\n",
       "       [ 0.00022038],\n",
       "       [ 0.05065242],\n",
       "       [ 0.06723561],\n",
       "       [ 0.05401849],\n",
       "       [ 0.0806949 ],\n",
       "       [ 0.10124138],\n",
       "       [-0.00446176],\n",
       "       [ 0.14861703],\n",
       "       [-0.08264781],\n",
       "       [-0.06185919],\n",
       "       [ 0.07420027],\n",
       "       [ 0.21010753],\n",
       "       [ 0.03403828],\n",
       "       [ 0.        ],\n",
       "       [ 0.12656125],\n",
       "       [ 0.07379268],\n",
       "       [ 0.05574435],\n",
       "       [ 0.08360867],\n",
       "       [ 0.21101114],\n",
       "       [-0.00375027],\n",
       "       [-0.06853266],\n",
       "       [ 0.09555264],\n",
       "       [-0.0807407 ],\n",
       "       [-0.07659005]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2f67c3e7-4ed0-4805-9966-272aa552efa3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11892611540538990"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features, labels, metadata = session.run(next_batch)\n",
    "features['user_fids'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "aafc3ff4-ac43-418e-9c9d-5f5b547bbc06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  17651761265984672,   20733872968112417,   27978570257013384,\n",
       "         44850312792901376,   52558572850079295,   60339255362303347,\n",
       "         67810805381673758,   77428472052053367,   83764923086163489,\n",
       "         98762764258981703,  103230611244960763,  112421516648451837,\n",
       "        117997908582961592, 1109496150758225693,  132396849400231283,\n",
       "       1799955228269831743,  135107988821114881, 1060853087865824522,\n",
       "       1048914622717034607, 1123084414477362740, 1128995006060486592,\n",
       "       1873497444986126345, 1882504644240867332,  988721239631675904,\n",
       "       1817877897957910065,                   0,                   0])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eda8ecad-5a8b-49d6-819d-b73fc161993c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  AUC: 0.5145\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "auc = roc_auc_score(np.concatenate(labels, axis=None), np.concatenate(predictions, axis=None))\n",
    "print(f\"  AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fba559e1-8200-45cb-8cf5-2f5a33ee563a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  AUC: 0.7170\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "auc = roc_auc_score(np.concatenate(labels, axis=None), np.concatenate(deepFM_predictions, axis=None))\n",
    "print(f\"  AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63a3ef78-9956-4c03-94c9-565908c9acbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'0'}>]], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(np.concatenate(predictions, axis=None)).hist(bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8520b47c-b758-49e3-b193-83b9cddb047a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'0'}>]], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(np.concatenate(deepFM_predictions, axis=None)).hist(bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc7dfa51-bda8-421c-ac57-8e6ce3f54d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'0'}>]], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(np.concatenate([np.diag(x) for x in variances], axis = None)).hist(bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4601c6f9-6f76-42c2-83b2-6c630a5cac0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'0'}>]], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(np.concatenate([np.diag(x) for x in variances], axis = None) + np.concatenate(predictions, axis=None)).hist(bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59abf060-8f9a-4432-80a1-81bb1bb116eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.012703900893928855"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(np.concatenate(predictions, axis=None), np.concatenate(deepFM_predictions, axis=None))[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f4c6ee2-58d4-4888-ac39-6df871eb5984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1abb9c7-5946-465d-a48e-1206f778a6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23898169370567088\n",
      "0.23709349966764157\n",
      "0.23444925086636084\n",
      "0.22646808379927647\n",
      "0.23383521524608175\n",
      "0.22658178462055198\n",
      "0.2371701751503118\n",
      "0.237906270683524\n",
      "0.23558745882504456\n",
      "0.24445420089695585\n",
      "0.23804186899661298\n",
      "0.23625438058798545\n",
      "0.24410002832340916\n",
      "0.24711590631818936\n",
      "0.23696560200154523\n",
      "0.23378922485588832\n",
      "0.22574646728543074\n",
      "0.24277938017458622\n",
      "0.23789392505591198\n",
      "0.23552834614778412\n",
      "0.2633851542433758\n",
      "0.23925557617634047\n"
     ]
    }
   ],
   "source": [
    "for i in range(100, 2300, 100):\n",
    "    print(pd.read_pickle(f'tpfy/neural_linUCB_training_data/training_stats_run_{i}.pkl')['train_mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67253fdb-de7e-4fb1-8017-67236b7661ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24493517165606482\n",
      "0.2450395123453056\n",
      "0.24475984719008365\n",
      "0.24489745517232953\n",
      "0.2449365674083451\n",
      "0.24498153530610556\n",
      "0.24508710268901052\n",
      "0.2449246948854109\n",
      "0.24496002531821257\n",
      "0.2449603853533311\n",
      "0.24492125487570346\n",
      "0.2448765493068669\n",
      "0.24485356510577477\n",
      "0.24481115878506837\n",
      "0.2448261638399419\n",
      "0.2448585451427107\n",
      "0.2448551102365321\n",
      "0.2448243880552142\n",
      "0.24485088206363775\n",
      "0.24484065848837927\n",
      "0.24484839916274778\n",
      "0.2448119601242797\n"
     ]
    }
   ],
   "source": [
    "for i in range(100, 2300, 100):\n",
    "    print(pd.read_pickle(f'tpfy/neural_linUCB_training_data/training_stats_run_{i}.pkl')['valid_mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df7062c4-3c7b-4e98-8b9b-d0cf9f2bcbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'High': 0.047843091948421845, 'Low': 0.04898439550691642, 'Medium': 0.048414392656629605, 'Negligible': 0.05000129936189246}\n",
      "{'High': 0.03493125407651411, 'Low': 0.03573349069158888, 'Medium': 0.03531196240948344, 'Negligible': 0.03644837494830821}\n",
      "{'High': 0.028821502227898973, 'Low': 0.029467134127463376, 'Medium': 0.02911365790755281, 'Negligible': 0.030040777274258083}\n",
      "{'High': 0.02509647733447536, 'Low': 0.02566344773288622, 'Medium': 0.025349685610372638, 'Negligible': 0.026151858519584282}\n",
      "{'High': 0.022529582812692416, 'Low': 0.023038253277625622, 'Medium': 0.022754821311478476, 'Negligible': 0.023474977363143485}\n",
      "{'High': 0.020621063691193892, 'Low': 0.02108418823896634, 'Medium': 0.02082385753835124, 'Negligible': 0.0214807860703627}\n",
      "{'High': 0.019175837962544708, 'Low': 0.019606242723999, 'Medium': 0.019363829349380513, 'Negligible': 0.01997154552849689}\n",
      "{'High': 0.018036285701460014, 'Low': 0.018439786305205503, 'Medium': 0.01821242048912859, 'Negligible': 0.01878218788890298}\n",
      "{'High': 0.017053013659243912, 'Low': 0.017432968282153283, 'Medium': 0.017218591630960556, 'Negligible': 0.01775393180241091}\n",
      "{'High': 0.016240218267204214, 'Low': 0.016604911609467265, 'Medium': 0.01639917345326664, 'Negligible': 0.016908466450908155}\n",
      "{'High': 0.015556246658554177, 'Low': 0.01590437833565968, 'Medium': 0.015707380224115726, 'Negligible': 0.01619547196742115}\n",
      "{'High': 0.014909096977610056, 'Low': 0.01524343744744281, 'Medium': 0.015054335027772248, 'Negligible': 0.015522097846991148}\n",
      "{'High': 0.014334608704579125, 'Low': 0.014658075753863587, 'Medium': 0.01447610443525885, 'Negligible': 0.014925204518317152}\n",
      "{'High': 0.013818788293351198, 'Low': 0.01413047413147751, 'Medium': 0.01395449298129716, 'Negligible': 0.014386989651498398}\n",
      "{'High': 0.013352019534681561, 'Low': 0.01365454297379093, 'Medium': 0.013483786636656673, 'Negligible': 0.013901985516149918}\n",
      "{'High': 0.012928060588635533, 'Low': 0.013220798920558583, 'Medium': 0.013055225280594199, 'Negligible': 0.013459352627326254}\n",
      "{'High': 0.012536809077603185, 'Low': 0.012820777800465755, 'Medium': 0.012660102615413983, 'Negligible': 0.013051929556942798}\n",
      "{'High': 0.012187624705256769, 'Low': 0.01246372828861621, 'Medium': 0.012307539703882748, 'Negligible': 0.012688429834892486}\n",
      "{'High': 0.011880121259023232, 'Low': 0.01214894302550469, 'Medium': 0.011996773721186684, 'Negligible': 0.012367701013864467}\n",
      "{'High': 0.011593646112029949, 'Low': 0.011855853728219902, 'Medium': 0.011707400204448326, 'Negligible': 0.012069341321325608}\n",
      "{'High': 0.011328755564080641, 'Low': 0.011585790133811873, 'Medium': 0.011440267812511146, 'Negligible': 0.011794600036785622}\n",
      "{'High': 0.01107302660976402, 'Low': 0.011324246330311405, 'Medium': 0.011182145956015318, 'Negligible': 0.01152900261760506}\n"
     ]
    }
   ],
   "source": [
    "for i in range(100, 2300, 100):\n",
    "    print(pd.read_pickle(f'tpfy/neural_linUCB_training_data/training_stats_run_{i}.pkl')['valid_popularity_variance_dist_stats']['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30639c06-3421-4ed6-9423-9bbee656d906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'High': 0.3884407916948841, 'Low': 0.3918883958008224, 'Medium': 0.3916854178794672, 'Negligible': 0.39092838758938886}\n",
      "{'High': 0.3913461223847903, 'Low': 0.3901352282488649, 'Medium': 0.391915682618682, 'Negligible': 0.38953263137204536}\n",
      "{'High': 0.3900972250210165, 'Low': 0.3915910650654012, 'Medium': 0.39344453736740564, 'Negligible': 0.3910111949844584}\n",
      "{'High': 0.3910732822868451, 'Low': 0.3894146570024646, 'Medium': 0.3911451032837473, 'Negligible': 0.3885547028127606}\n",
      "{'High': 0.3899596556312705, 'Low': 0.3890585315514594, 'Medium': 0.3890484831740729, 'Negligible': 0.3897382765667077}\n",
      "{'High': 0.3889445049648792, 'Low': 0.3881011561560218, 'Medium': 0.38833840732054087, 'Negligible': 0.39084555581947106}\n",
      "{'High': 0.3886632228106242, 'Low': 0.3881393799330605, 'Medium': 0.3876952704044692, 'Negligible': 0.38733816741188043}\n",
      "{'High': 0.38915039931662515, 'Low': 0.3883928879874633, 'Medium': 0.38910460169588246, 'Negligible': 0.38838055560201334}\n",
      "{'High': 0.3886248912984544, 'Low': 0.38909868201083686, 'Medium': 0.38802545162727087, 'Negligible': 0.38781663579172326}\n",
      "{'High': 0.3865451812836178, 'Low': 0.38837288540211756, 'Medium': 0.3890505298577495, 'Negligible': 0.389720273449814}\n",
      "{'High': 0.39176245300885687, 'Low': 0.38983041924334366, 'Medium': 0.38963966737036526, 'Negligible': 0.38929743602884165}\n",
      "{'High': 0.3923426321774971, 'Low': 0.3908653793558296, 'Medium': 0.3917336314938034, 'Negligible': 0.3905529747228915}\n",
      "{'High': 0.3874601220610127, 'Low': 0.39001842135308185, 'Medium': 0.39070438804015445, 'Negligible': 0.3917820589004354}\n"
     ]
    }
   ],
   "source": [
    "for i in range(100, 1400, 100):\n",
    "    print(pd.read_pickle(f'tpfy/neural_linUCB_training_data/training_stats_run_{i}.pkl')['valid_popularity_mean_dist_stats']['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2494b265-d195-4ce4-be9c-5ad4de7d3798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'High': 0.3884407916948841, 'Low': 0.3918883958008224, 'Medium': 0.3916854178794672, 'Negligible': 0.39092838758938886}\n",
      "{'High': 0.3913461223847903, 'Low': 0.3901352282488649, 'Medium': 0.391915682618682, 'Negligible': 0.38953263137204536}\n",
      "{'High': 0.3900972250210165, 'Low': 0.3915910650654012, 'Medium': 0.39344453736740564, 'Negligible': 0.3910111949844584}\n",
      "{'High': 0.3910732822868451, 'Low': 0.3894146570024646, 'Medium': 0.3911451032837473, 'Negligible': 0.3885547028127606}\n",
      "{'High': 0.3899596556312705, 'Low': 0.3890585315514594, 'Medium': 0.3890484831740729, 'Negligible': 0.3897382765667077}\n",
      "{'High': 0.3889445049648792, 'Low': 0.3881011561560218, 'Medium': 0.38833840732054087, 'Negligible': 0.39084555581947106}\n",
      "{'High': 0.3886632228106242, 'Low': 0.3881393799330605, 'Medium': 0.3876952704044692, 'Negligible': 0.38733816741188043}\n",
      "{'High': 0.38915039931662515, 'Low': 0.3883928879874633, 'Medium': 0.38910460169588246, 'Negligible': 0.38838055560201334}\n",
      "{'High': 0.3886248912984544, 'Low': 0.38909868201083686, 'Medium': 0.38802545162727087, 'Negligible': 0.38781663579172326}\n",
      "{'High': 0.3865451812836178, 'Low': 0.38837288540211756, 'Medium': 0.3890505298577495, 'Negligible': 0.389720273449814}\n",
      "{'High': 0.39176245300885687, 'Low': 0.38983041924334366, 'Medium': 0.38963966737036526, 'Negligible': 0.38929743602884165}\n",
      "{'High': 0.3923426321774971, 'Low': 0.3908653793558296, 'Medium': 0.3917336314938034, 'Negligible': 0.3905529747228915}\n",
      "{'High': 0.3874601220610127, 'Low': 0.39001842135308185, 'Medium': 0.39070438804015445, 'Negligible': 0.3917820589004354}\n"
     ]
    }
   ],
   "source": [
    "for i in range(100, 1400, 100):\n",
    "    print(pd.read_pickle(f'tpfy/neural_linUCB_training_data/training_stats_run_{i}.pkl')['valid_popularity_mean_dist_stats']['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a2e008-e191-40f0-b7f5-5702856dff4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f94fa0e-c7d6-4113-a932-bacf72362f79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f2aba5-03d0-4bff-99e3-52e5113d2f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b03f5e0-466f-4ff1-830b-1dd2cecf0602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e35159b-42f0-494f-bd44-f58249b7bc00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
